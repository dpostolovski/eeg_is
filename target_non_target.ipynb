{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Faza4.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dpostolovski/eeg_is/blob/train_compare_full_data/target_non_target.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2UDle2I8OMUa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 129
        },
        "outputId": "f13d7e4c-023d-4915-8677-abdfb7d48571"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7qm05RkaOpZW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 257
        },
        "outputId": "1179208f-e838-4833-9387-646939fd82a7"
      },
      "source": [
        "#@title Инсталирање и вчитување на потребните библиотеки\n",
        "!pip install mne \n",
        "!pip install termcolor\n",
        "\n",
        "%tensorflow_version 1.12.0\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import mne\n",
        "\n",
        "from sklearn import metrics \n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint \n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras import backend as K\n",
        "\n",
        "from scipy.io import loadmat\n",
        "from collections import Counter\n",
        "\n",
        "K.set_image_data_format('channels_first')\n",
        "\n",
        "import sys\n",
        "sys.path.append('drive/My Drive/Интелигентни Системи')\n",
        "from EEGModels import DeepConvNet, EEGNet\n",
        "\n",
        "!mkdir saved_models"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting mne\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/92/ab/9b79f927b599da515335afb4b666a7bb336930a6d8345e7b483a9980a9c1/mne-0.20.7-py3-none-any.whl (6.6MB)\n",
            "\u001b[K     |████████████████████████████████| 6.6MB 6.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.6/dist-packages (from mne) (1.18.5)\n",
            "Requirement already satisfied: scipy>=0.17.1 in /usr/local/lib/python3.6/dist-packages (from mne) (1.4.1)\n",
            "Installing collected packages: mne\n",
            "Successfully installed mne-0.20.7\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.6/dist-packages (1.1.0)\n",
            "`%tensorflow_version` only switches the major version: 1.x or 2.x.\n",
            "You set: `1.12.0`. This will be interpreted as: `1.x`.\n",
            "\n",
            "\n",
            "TensorFlow 1.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y2CpCSd15Hvv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def reshape(data, labels, events, targets):\n",
        "  mne_array = np.swapaxes(data, 0, 2) # (епохa, канал, настан). \n",
        "  mne_array = np.swapaxes(mne_array, 1, 2) # (епохa, канал, настан). \n",
        "  mne_array = mne_array.reshape(mne_array.shape[0], 1, 8, 350)\n",
        "\n",
        "  labels_arr = labels.astype(np.int)\n",
        "  events_arr = events.astype(np.int)\n",
        "  targets_arr = targets.astype(np.int)\n",
        "  return mne_array, labels_arr-1, events_arr-1,targets_arr"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0wIxcjNywN0a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def reshape_data_to_mne_format(data):\n",
        "  mne_array = np.swapaxes(data, 0, 2) # (епохa, канал, настан). \n",
        "  mne_array = np.swapaxes(mne_array, 1, 2) # (епохa, канал, настан). \n",
        "  mne_array = mne_array.reshape(mne_array.shape[0], 1, 8, 350)\n",
        "\n",
        "  return mne_array"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tU0YDj0OO4jD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "fc36533b-6230-48d7-b58b-4dead46425db"
      },
      "source": [
        "# Иницијализација на променливите каде ќе бидат вчитани податоците\n",
        "train_data = []\n",
        "train_labels = []\n",
        "train_events = []\n",
        "train_targets = []\n",
        "models = []\n",
        "\n",
        "start_i = 7\n",
        "for i in range(7, 8): # Итерација низ секој испитен примерок\n",
        "  print(\"Вчитување тест податоци од испитниот примерок \" + str(i) + \"...\")\n",
        "\n",
        "  file_name = 'SBJ' + format(i, '02')\n",
        "  \n",
        "  # Иницијализација на помошни променливи\n",
        "  temp_train_data = np.empty(0)\n",
        "  temp_train_labels = np.empty(0)\n",
        "  temp_train_events = np.empty(0)\n",
        "  temp_train_targets = np.empty(0)\n",
        "\n",
        "  for j in range(1, 4): # Итерација низ секоја сесија\n",
        "    file_train_set = 'S' + format(j, '02') + '/Train'\n",
        "\n",
        "    # Вчитување на податоците\n",
        "    full_path = 'drive/My Drive/Интелигентни Системи/Data/' + file_name + \"/\" + file_train_set + \"/trainData.mat\"\n",
        "    temp = loadmat(full_path)['trainData']\n",
        "    if temp_train_data.size != 0:\n",
        "      temp_train_data = np.concatenate((temp_train_data, temp), axis=2)\n",
        "    else: \n",
        "      temp_train_data = np.array(temp)\n",
        "\n",
        "    # Вчитување на label-ите\n",
        "    full_path = 'drive/My Drive/Интелигентни Системи/Data/' + file_name + \"/\" + file_train_set + \"/trainLabels.txt\"\n",
        "    with open(full_path, \"r\") as file_labels:\n",
        "      temp = file_labels.read().splitlines()\n",
        "      temp = np.repeat(temp, 8*10)\n",
        "      if temp_train_labels.size != 0:\n",
        "        temp_train_labels = np.concatenate((temp_train_labels, temp))\n",
        "      else:\n",
        "        temp_train_labels = np.array(temp)\n",
        "\n",
        "    # Вчитување на редоследот на светкање\n",
        "    full_path = 'drive/My Drive/Интелигентни Системи/Data/' + file_name + \"/\" + file_train_set + \"/trainEvents.txt\"\n",
        "    with open(full_path, \"r\") as file_events:\n",
        "      temp = file_events.read().splitlines()\n",
        "      if temp_train_events.size != 0:\n",
        "        temp_train_events = np.append(temp_train_events, temp)\n",
        "      else:\n",
        "        temp_train_events = np.array(temp)\n",
        "      \n",
        "\n",
        "    # Вчитување на редоследот на објекти кои се target\n",
        "    full_path = 'drive/My Drive/Интелигентни Системи/Data/' + file_name + \"/\" + file_train_set + \"/trainTargets.txt\"\n",
        "    with open(full_path, \"r\") as file_targets:\n",
        "      temp = file_targets.read().splitlines()\n",
        "      if temp_train_targets.size != 0:\n",
        "        temp_train_targets = np.concatenate((temp_train_targets, temp))\n",
        "      else:\n",
        "        temp_train_targets = np.array(temp)\n",
        "\n",
        "    print(\"\\t - Податоците од сесија \" + str(j) + \" се вчитани.\")\n",
        "  # Зачувај ги податоците вчитани од испитниот примерок во низа\n",
        "  train_data.append(temp_train_data)\n",
        "  train_labels.append(temp_train_labels)\n",
        "  train_events.append(temp_train_events)\n",
        "  train_targets.append(temp_train_targets)\n",
        "  print(\"Податоците од испитниот примерок \" + str(i) + \" се вчитани.\\n\")\n",
        "\n",
        "  array_i = i - start_i\n",
        "      \n",
        "\n",
        "  data, labels, events, targets = reshape(train_data[array_i], train_labels[array_i], train_events[array_i], train_targets[array_i])\n",
        "  neg, pos = np.bincount(targets)\n",
        "  total = neg + pos\n",
        "\n",
        "  weight_for_0 = (1 / neg)*(total)/2.0 \n",
        "  weight_for_1 = (1 / pos)*(total)/2.0\n",
        "\n",
        "  class_weight = {0: weight_for_0, 1: weight_for_1}\n",
        "\n",
        "\n",
        "\n",
        "  X_train = data[0:3600]\n",
        "  y_train = targets[0:3600]\n",
        "\n",
        "  X_test = data[3600:]\n",
        "  y_test = targets[3600:]\n",
        "\n",
        "  model = DeepConvNet(nb_classes = 2, Chans = 8, Samples = 350)\n",
        "  model.compile(loss = 'categorical_crossentropy', metrics=['accuracy', 'Recall'],optimizer = Adam())\n",
        "  checkpointer = ModelCheckpoint(filepath='saved_models/weights.best.basic_mlp.hdf5', \n",
        "                                verbose=1, save_best_only=True)\n",
        "\n",
        "\n",
        "  y_train = to_categorical(y_train)\n",
        "  y_test = to_categorical(y_test)\n",
        "\n",
        "  num_batch_size=100\n",
        "  num_epochs=150\n",
        "  model.fit(X_train, y_train, batch_size=num_batch_size, epochs=num_epochs, \\\n",
        "            validation_data=(X_test, y_test), \\\n",
        "            callbacks=[checkpointer], \\\n",
        "            class_weight=class_weight, \\\n",
        "            verbose=1)\n",
        "\n",
        "  score = model.evaluate(X_test, y_test, verbose=1)\n",
        "  print(score)\n",
        "\n",
        "  models.append(model) # Ke imame 15 modeli neli, pa vo niza se staveni\n",
        "                       # pristap do niv model[i]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Вчитување тест податоци од испитниот примерок 7...\n",
            "\t - Податоците од сесија 1 се вчитани.\n",
            "\t - Податоците од сесија 2 се вчитани.\n",
            "\t - Податоците од сесија 3 се вчитани.\n",
            "Податоците од испитниот примерок 7 се вчитани.\n",
            "\n",
            "Version 10\n",
            "Version 10\n",
            "Version 10\n",
            "Version 10\n",
            "Version 10\n",
            "Version 10\n",
            "Version 10\n",
            "Train on 3600 samples, validate on 1200 samples\n",
            "Epoch 1/150\n",
            "3500/3600 [============================>.] - ETA: 0s - loss: 0.8066 - acc: 0.5977 - recall_6: 0.5977\n",
            "Epoch 00001: val_loss improved from inf to 0.48387, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
            "3600/3600 [==============================] - 8s 2ms/sample - loss: 0.7980 - acc: 0.6031 - recall_6: 0.6031 - val_loss: 0.4839 - val_acc: 0.7717 - val_recall_6: 0.7717\n",
            "Epoch 2/150\n",
            "3500/3600 [============================>.] - ETA: 0s - loss: 0.7468 - acc: 0.6649 - recall_6: 0.6649\n",
            "Epoch 00002: val_loss did not improve from 0.48387\n",
            "3600/3600 [==============================] - 3s 749us/sample - loss: 0.7605 - acc: 0.6636 - recall_6: 0.6636 - val_loss: 1.1921 - val_acc: 0.3725 - val_recall_6: 0.3725\n",
            "Epoch 3/150\n",
            "3500/3600 [============================>.] - ETA: 0s - loss: 0.7591 - acc: 0.6663 - recall_6: 0.6663\n",
            "Epoch 00003: val_loss improved from 0.48387 to 0.41103, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
            "3600/3600 [==============================] - 3s 778us/sample - loss: 0.7554 - acc: 0.6639 - recall_6: 0.6639 - val_loss: 0.4110 - val_acc: 0.8200 - val_recall_6: 0.8200\n",
            "Epoch 4/150\n",
            "3500/3600 [============================>.] - ETA: 0s - loss: 0.7024 - acc: 0.6951 - recall_6: 0.6951\n",
            "Epoch 00004: val_loss did not improve from 0.41103\n",
            "3600/3600 [==============================] - 3s 758us/sample - loss: 0.7041 - acc: 0.6933 - recall_6: 0.6933 - val_loss: 0.4330 - val_acc: 0.8050 - val_recall_6: 0.8050\n",
            "Epoch 5/150\n",
            "3500/3600 [============================>.] - ETA: 0s - loss: 0.6176 - acc: 0.7211 - recall_6: 0.7211\n",
            "Epoch 00005: val_loss improved from 0.41103 to 0.35260, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
            "3600/3600 [==============================] - 3s 782us/sample - loss: 0.6237 - acc: 0.7233 - recall_6: 0.7233 - val_loss: 0.3526 - val_acc: 0.8633 - val_recall_6: 0.8633\n",
            "Epoch 6/150\n",
            "3500/3600 [============================>.] - ETA: 0s - loss: 0.6593 - acc: 0.7131 - recall_6: 0.7131\n",
            "Epoch 00006: val_loss did not improve from 0.35260\n",
            "3600/3600 [==============================] - 3s 747us/sample - loss: 0.6573 - acc: 0.7139 - recall_6: 0.7139 - val_loss: 0.5618 - val_acc: 0.7275 - val_recall_6: 0.7275\n",
            "Epoch 7/150\n",
            "3500/3600 [============================>.] - ETA: 0s - loss: 0.5607 - acc: 0.7397 - recall_6: 0.7397\n",
            "Epoch 00007: val_loss did not improve from 0.35260\n",
            "3600/3600 [==============================] - 3s 743us/sample - loss: 0.5638 - acc: 0.7419 - recall_6: 0.7419 - val_loss: 0.4678 - val_acc: 0.7833 - val_recall_6: 0.7833\n",
            "Epoch 8/150\n",
            "3500/3600 [============================>.] - ETA: 0s - loss: 0.5672 - acc: 0.7534 - recall_6: 0.7534\n",
            "Epoch 00008: val_loss did not improve from 0.35260\n",
            "3600/3600 [==============================] - 3s 768us/sample - loss: 0.5659 - acc: 0.7508 - recall_6: 0.7508 - val_loss: 0.5382 - val_acc: 0.7533 - val_recall_6: 0.7533\n",
            "Epoch 9/150\n",
            "3500/3600 [============================>.] - ETA: 0s - loss: 0.5754 - acc: 0.7431 - recall_6: 0.7431\n",
            "Epoch 00009: val_loss did not improve from 0.35260\n",
            "3600/3600 [==============================] - 3s 741us/sample - loss: 0.5732 - acc: 0.7428 - recall_6: 0.7428 - val_loss: 0.3756 - val_acc: 0.8225 - val_recall_6: 0.8225\n",
            "Epoch 10/150\n",
            "3500/3600 [============================>.] - ETA: 0s - loss: 0.5355 - acc: 0.7609 - recall_6: 0.7609\n",
            "Epoch 00010: val_loss improved from 0.35260 to 0.33422, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
            "3600/3600 [==============================] - 3s 801us/sample - loss: 0.5369 - acc: 0.7619 - recall_6: 0.7619 - val_loss: 0.3342 - val_acc: 0.8650 - val_recall_6: 0.8650\n",
            "Epoch 11/150\n",
            "3500/3600 [============================>.] - ETA: 0s - loss: 0.5210 - acc: 0.7591 - recall_6: 0.7591\n",
            "Epoch 00011: val_loss improved from 0.33422 to 0.32943, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
            "3600/3600 [==============================] - 3s 789us/sample - loss: 0.5225 - acc: 0.7625 - recall_6: 0.7625 - val_loss: 0.3294 - val_acc: 0.8742 - val_recall_6: 0.8742\n",
            "Epoch 12/150\n",
            "3500/3600 [============================>.] - ETA: 0s - loss: 0.5665 - acc: 0.7549 - recall_6: 0.7549\n",
            "Epoch 00012: val_loss did not improve from 0.32943\n",
            "3600/3600 [==============================] - 3s 748us/sample - loss: 0.5650 - acc: 0.7525 - recall_6: 0.7525 - val_loss: 0.5283 - val_acc: 0.7692 - val_recall_6: 0.7692\n",
            "Epoch 13/150\n",
            "3500/3600 [============================>.] - ETA: 0s - loss: 0.4944 - acc: 0.7809 - recall_6: 0.7809\n",
            "Epoch 00013: val_loss did not improve from 0.32943\n",
            "3600/3600 [==============================] - 3s 762us/sample - loss: 0.4952 - acc: 0.7817 - recall_6: 0.7817 - val_loss: 0.3437 - val_acc: 0.8700 - val_recall_6: 0.8700\n",
            "Epoch 14/150\n",
            "3500/3600 [============================>.] - ETA: 0s - loss: 0.5343 - acc: 0.7674 - recall_6: 0.7674\n",
            "Epoch 00014: val_loss did not improve from 0.32943\n",
            "3600/3600 [==============================] - 3s 742us/sample - loss: 0.5357 - acc: 0.7689 - recall_6: 0.7689 - val_loss: 0.3575 - val_acc: 0.8542 - val_recall_6: 0.8542\n",
            "Epoch 15/150\n",
            "3500/3600 [============================>.] - ETA: 0s - loss: 0.4973 - acc: 0.7940 - recall_6: 0.7940\n",
            "Epoch 00015: val_loss did not improve from 0.32943\n",
            "3600/3600 [==============================] - 3s 745us/sample - loss: 0.4963 - acc: 0.7961 - recall_6: 0.7961 - val_loss: 0.3763 - val_acc: 0.8425 - val_recall_6: 0.8425\n",
            "Epoch 16/150\n",
            "3500/3600 [============================>.] - ETA: 0s - loss: 0.4555 - acc: 0.7951 - recall_6: 0.7951\n",
            "Epoch 00016: val_loss did not improve from 0.32943\n",
            "3600/3600 [==============================] - 3s 746us/sample - loss: 0.4611 - acc: 0.7922 - recall_6: 0.7922 - val_loss: 0.5220 - val_acc: 0.7725 - val_recall_6: 0.7725\n",
            "Epoch 17/150\n",
            "3500/3600 [============================>.] - ETA: 0s - loss: 0.4410 - acc: 0.8086 - recall_6: 0.8086\n",
            "Epoch 00017: val_loss did not improve from 0.32943\n",
            "3600/3600 [==============================] - 3s 761us/sample - loss: 0.4441 - acc: 0.8083 - recall_6: 0.8083 - val_loss: 0.5387 - val_acc: 0.7708 - val_recall_6: 0.7708\n",
            "Epoch 18/150\n",
            "3500/3600 [============================>.] - ETA: 0s - loss: 0.4579 - acc: 0.7929 - recall_6: 0.7929\n",
            "Epoch 00018: val_loss did not improve from 0.32943\n",
            "3600/3600 [==============================] - 3s 748us/sample - loss: 0.4595 - acc: 0.7917 - recall_6: 0.7917 - val_loss: 0.5740 - val_acc: 0.7692 - val_recall_6: 0.7692\n",
            "Epoch 19/150\n",
            "3500/3600 [============================>.] - ETA: 0s - loss: 0.4788 - acc: 0.7903 - recall_6: 0.7903\n",
            "Epoch 00019: val_loss did not improve from 0.32943\n",
            "3600/3600 [==============================] - 3s 742us/sample - loss: 0.4756 - acc: 0.7931 - recall_6: 0.7931 - val_loss: 0.3995 - val_acc: 0.8367 - val_recall_6: 0.8367\n",
            "Epoch 20/150\n",
            "3500/3600 [============================>.] - ETA: 0s - loss: 0.4415 - acc: 0.8054 - recall_6: 0.8054\n",
            "Epoch 00020: val_loss did not improve from 0.32943\n",
            "3600/3600 [==============================] - 3s 781us/sample - loss: 0.4401 - acc: 0.8058 - recall_6: 0.8058 - val_loss: 0.4700 - val_acc: 0.8100 - val_recall_6: 0.8100\n",
            "Epoch 21/150\n",
            "3500/3600 [============================>.] - ETA: 0s - loss: 0.3853 - acc: 0.8289 - recall_6: 0.8289\n",
            "Epoch 00021: val_loss did not improve from 0.32943\n",
            "3600/3600 [==============================] - 3s 753us/sample - loss: 0.3832 - acc: 0.8269 - recall_6: 0.8269 - val_loss: 0.4643 - val_acc: 0.8142 - val_recall_6: 0.8142\n",
            "Epoch 22/150\n",
            "3500/3600 [============================>.] - ETA: 0s - loss: 0.4128 - acc: 0.8226 - recall_6: 0.8226\n",
            "Epoch 00022: val_loss did not improve from 0.32943\n",
            "3600/3600 [==============================] - 3s 744us/sample - loss: 0.4109 - acc: 0.8211 - recall_6: 0.8211 - val_loss: 0.6495 - val_acc: 0.7342 - val_recall_6: 0.7342\n",
            "Epoch 23/150\n",
            "3500/3600 [============================>.] - ETA: 0s - loss: 0.3771 - acc: 0.8377 - recall_6: 0.8377\n",
            "Epoch 00023: val_loss did not improve from 0.32943\n",
            "3600/3600 [==============================] - 3s 765us/sample - loss: 0.3758 - acc: 0.8386 - recall_6: 0.8386 - val_loss: 0.4701 - val_acc: 0.8025 - val_recall_6: 0.8025\n",
            "Epoch 24/150\n",
            "3500/3600 [============================>.] - ETA: 0s - loss: 0.3863 - acc: 0.8171 - recall_6: 0.8171\n",
            "Epoch 00024: val_loss improved from 0.32943 to 0.32487, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
            "3600/3600 [==============================] - 3s 784us/sample - loss: 0.3863 - acc: 0.8183 - recall_6: 0.8183 - val_loss: 0.3249 - val_acc: 0.8842 - val_recall_6: 0.8842\n",
            "Epoch 25/150\n",
            "3500/3600 [============================>.] - ETA: 0s - loss: 0.3826 - acc: 0.8337 - recall_6: 0.8337\n",
            "Epoch 00025: val_loss did not improve from 0.32487\n",
            "3600/3600 [==============================] - 3s 744us/sample - loss: 0.3795 - acc: 0.8350 - recall_6: 0.8350 - val_loss: 0.3292 - val_acc: 0.8700 - val_recall_6: 0.8700\n",
            "Epoch 26/150\n",
            "3500/3600 [============================>.] - ETA: 0s - loss: 0.3828 - acc: 0.8331 - recall_6: 0.8331\n",
            "Epoch 00026: val_loss did not improve from 0.32487\n",
            "3600/3600 [==============================] - 3s 766us/sample - loss: 0.3858 - acc: 0.8317 - recall_6: 0.8317 - val_loss: 0.5910 - val_acc: 0.7550 - val_recall_6: 0.7550\n",
            "Epoch 27/150\n",
            "3500/3600 [============================>.] - ETA: 0s - loss: 0.3538 - acc: 0.8483 - recall_6: 0.8483\n",
            "Epoch 00027: val_loss did not improve from 0.32487\n",
            "3600/3600 [==============================] - 3s 745us/sample - loss: 0.3514 - acc: 0.8483 - recall_6: 0.8483 - val_loss: 0.4305 - val_acc: 0.8358 - val_recall_6: 0.8358\n",
            "Epoch 28/150\n",
            "3500/3600 [============================>.] - ETA: 0s - loss: 0.3758 - acc: 0.8369 - recall_6: 0.8369\n",
            "Epoch 00028: val_loss did not improve from 0.32487\n",
            "3600/3600 [==============================] - 3s 737us/sample - loss: 0.3788 - acc: 0.8356 - recall_6: 0.8356 - val_loss: 0.5241 - val_acc: 0.7700 - val_recall_6: 0.7700\n",
            "Epoch 29/150\n",
            "3500/3600 [============================>.] - ETA: 0s - loss: 0.3407 - acc: 0.8566 - recall_6: 0.8566\n",
            "Epoch 00029: val_loss did not improve from 0.32487\n",
            "3600/3600 [==============================] - 3s 744us/sample - loss: 0.3374 - acc: 0.8572 - recall_6: 0.8572 - val_loss: 0.4769 - val_acc: 0.8000 - val_recall_6: 0.8000\n",
            "Epoch 30/150\n",
            "3500/3600 [============================>.] - ETA: 0s - loss: 0.3614 - acc: 0.8500 - recall_6: 0.8500\n",
            "Epoch 00030: val_loss did not improve from 0.32487\n",
            "3600/3600 [==============================] - 3s 781us/sample - loss: 0.3659 - acc: 0.8464 - recall_6: 0.8464 - val_loss: 0.5602 - val_acc: 0.7725 - val_recall_6: 0.7725\n",
            "Epoch 31/150\n",
            "3500/3600 [============================>.] - ETA: 0s - loss: 0.3544 - acc: 0.8429 - recall_6: 0.8429\n",
            "Epoch 00031: val_loss did not improve from 0.32487\n",
            "3600/3600 [==============================] - 3s 737us/sample - loss: 0.3518 - acc: 0.8428 - recall_6: 0.8428 - val_loss: 0.4627 - val_acc: 0.8133 - val_recall_6: 0.8133\n",
            "Epoch 32/150\n",
            "3500/3600 [============================>.] - ETA: 0s - loss: 0.3169 - acc: 0.8571 - recall_6: 0.8571\n",
            "Epoch 00032: val_loss improved from 0.32487 to 0.28497, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
            "3600/3600 [==============================] - 3s 777us/sample - loss: 0.3245 - acc: 0.8589 - recall_6: 0.8589 - val_loss: 0.2850 - val_acc: 0.8875 - val_recall_6: 0.8875\n",
            "Epoch 33/150\n",
            "3500/3600 [============================>.] - ETA: 0s - loss: 0.3252 - acc: 0.8629 - recall_6: 0.8629\n",
            "Epoch 00033: val_loss did not improve from 0.28497\n",
            "3600/3600 [==============================] - 3s 755us/sample - loss: 0.3270 - acc: 0.8619 - recall_6: 0.8619 - val_loss: 0.5971 - val_acc: 0.7442 - val_recall_6: 0.7442\n",
            "Epoch 34/150\n",
            "3500/3600 [============================>.] - ETA: 0s - loss: 0.3152 - acc: 0.8577 - recall_6: 0.8577\n",
            "Epoch 00034: val_loss did not improve from 0.28497\n",
            "3600/3600 [==============================] - 3s 745us/sample - loss: 0.3125 - acc: 0.8578 - recall_6: 0.8578 - val_loss: 0.3727 - val_acc: 0.8542 - val_recall_6: 0.8542\n",
            "Epoch 35/150\n",
            "3500/3600 [============================>.] - ETA: 0s - loss: 0.3144 - acc: 0.8649 - recall_6: 0.8649\n",
            "Epoch 00035: val_loss did not improve from 0.28497\n",
            "3600/3600 [==============================] - 3s 740us/sample - loss: 0.3168 - acc: 0.8633 - recall_6: 0.8633 - val_loss: 0.3927 - val_acc: 0.8458 - val_recall_6: 0.8458\n",
            "Epoch 36/150\n",
            "3500/3600 [============================>.] - ETA: 0s - loss: 0.3248 - acc: 0.8534 - recall_6: 0.8534\n",
            "Epoch 00036: val_loss did not improve from 0.28497\n",
            "3600/3600 [==============================] - 3s 766us/sample - loss: 0.3228 - acc: 0.8539 - recall_6: 0.8539 - val_loss: 0.3607 - val_acc: 0.8517 - val_recall_6: 0.8517\n",
            "Epoch 37/150\n",
            "3500/3600 [============================>.] - ETA: 0s - loss: 0.3066 - acc: 0.8737 - recall_6: 0.8737\n",
            "Epoch 00037: val_loss did not improve from 0.28497\n",
            "3600/3600 [==============================] - 3s 756us/sample - loss: 0.3068 - acc: 0.8736 - recall_6: 0.8736 - val_loss: 0.4134 - val_acc: 0.8375 - val_recall_6: 0.8375\n",
            "Epoch 38/150\n",
            "3500/3600 [============================>.] - ETA: 0s - loss: 0.3044 - acc: 0.8654 - recall_6: 0.8654\n",
            "Epoch 00038: val_loss did not improve from 0.28497\n",
            "3600/3600 [==============================] - 3s 751us/sample - loss: 0.3062 - acc: 0.8656 - recall_6: 0.8656 - val_loss: 0.3200 - val_acc: 0.8750 - val_recall_6: 0.8750\n",
            "Epoch 39/150\n",
            "2900/3600 [=======================>......] - ETA: 0s - loss: 0.2948 - acc: 0.8790 - recall_6: 0.8790"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FxW8fPu6wlY-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 799
        },
        "outputId": "4608c346-db6f-4372-93b8-53644c467bf3"
      },
      "source": [
        "# Иницијализација на променливите каде ќе бидат вчитани тест податоците\n",
        "test_data = []\n",
        "test_events = []\n",
        "test_runs_per_block = [[i for i in range(3)] for j in range(15)] # Covek, Sesija\n",
        "\n",
        "start_i = 7\n",
        "for i in range(7, 9): # Итерација низ секој испитен примерок\n",
        "  print(f\"====================== Примерок ({i}) ======================\")\n",
        "  print(\"Вчитување тест податоци од испитниот примерок \" + str(i) + \"...\")\n",
        "  \n",
        "  file_name = 'SBJ' + format(i, '02')\n",
        "  \n",
        "  # Иницијализација на помошни променливи\n",
        "  temp_test_data = np.empty(0)\n",
        "  temp_test_events = np.empty(0)\n",
        "  \n",
        "  for j in range(1, 4): # Итерација низ секоја сесија\n",
        "    file_test_set = 'S' + format(j, '02') + '/Test'\n",
        "\n",
        "    # Вчитување на податоците\n",
        "    full_path = 'drive/My Drive/Интелигентни Системи/Data/' + file_name + \"/\" + file_test_set + \"/testData.mat\"\n",
        "    temp = loadmat(full_path)['testData']\n",
        "    if temp_test_data.size != 0:\n",
        "      temp_test_data = np.concatenate((temp_test_data, temp), axis=2)\n",
        "    else: \n",
        "      temp_test_data = np.array(temp)\n",
        "\n",
        "    # Вчитување на редоследот на светкање\n",
        "    full_path = 'drive/My Drive/Интелигентни Системи/Data/' + file_name + \"/\" + file_test_set + \"/testEvents.txt\"\n",
        "    with open(full_path, \"r\") as file_events:\n",
        "      temp = file_events.read().splitlines()\n",
        "      if temp_test_events.size != 0:\n",
        "        temp_test_events = np.append(temp_test_events, temp)\n",
        "      else:\n",
        "        temp_test_events = np.array(temp)\n",
        "\n",
        "    # Вчитување на бројот на runs \n",
        "    full_path = 'drive/My Drive/Интелигентни Системи/Data/' + file_name + \"/\" + file_test_set + \"/runs_per_block.txt\"\n",
        "    with open(full_path, \"r\") as runs_per_block:\n",
        "      test_runs_per_block[i-1][j-1] = int(runs_per_block.read())\n",
        "\n",
        "    print(\"\\t - Тест податоците од сесија \" + str(j) + \" се вчитани.\")\n",
        "  # Зачувај ги тест податоците вчитани од испитниот примерок во низа\n",
        "  test_data.append(temp_test_data)\n",
        "  test_events.append(temp_test_events)\n",
        "  print(\"Тест податоците од испитниот примерок \" + str(i) + \" се вчитани.\\n\")\n",
        "\n",
        "  array_i = i - start_i\n",
        "      \n",
        "  \n",
        "  # =========================================================================\n",
        "\n",
        "  print(\"SBJ\" + str(format(i-1, '02')) + \"| Test_data: \" + str(test_data[array_i].shape)) # test_data to predict\n",
        "  print(\"SBJ\" + str(format(i-1, '02')) + \"| Test_events: \" + str(len(test_events[array_i]))) # test_events\n",
        "  for j in range (1,4):\n",
        "    print(\"SBJ\" + str(format(i-1, '02')) + \" / S\" + str(format(j-1, '02')) + \"| Runs per block: \" + str(test_runs_per_block[i-1][j-1])) # runs per block in SJB01, SJ00 \n",
        "\n",
        "  to_predict_data = reshape_data_to_mne_format(test_data[array_i])\n",
        "  predictions = models[array_i].predict(to_predict_data)\n",
        "  print(\"SBJ\" + str(format(i-1, '02')) + \"| Predictions: \" + str(len(predictions)))\n",
        "  # np.savetxt(\"predictions.csv\", predictions, delimiter=\",\")\n",
        "\n",
        "\n",
        "  # ========= FALI USTE DA SE ISPARSIRA PREDICTIONOT... NE E SREDEN OVOJ KOD DOLE =======\n",
        "\n",
        "  int_pred = np.argmax(predictions, axis=1)\n",
        "  int_ytest = np.argmax(y_test, axis=1)\n",
        "\n",
        "  session_start = 0\n",
        "  start_prediction_index = 0\n",
        "  end_prediction_index = 0\n",
        "  for session in range(0, 3):\n",
        "    print(f\"============== Сесија ({session}) ==============\")\n",
        "    for block in range(0, 50):    \n",
        "      events_per_block = test_runs_per_block[i-1][session]\n",
        "\n",
        "      start_prediction_index = session_start + (block*events_per_block)*8\n",
        "      end_prediction_index = session_start + ((block+1)*events_per_block)*8\n",
        "\n",
        "      block_prediction = int_pred[start_prediction_index:end_prediction_index]\n",
        "      prediction = np.bincount(block_prediction).argmax()\n",
        "\n",
        "      # UNCOMMENT ZA PODOBAR PRIKAZ :)\n",
        "      # print(f\"Session {session} | Block: {block} | Prediction: {prediction} | Address: {end_prediction_index}\")\n",
        "\n",
        "      print(str(prediction) + \",\", end=\"\")\n",
        "    session_start = end_prediction_index\n",
        "    print(\"\")\n",
        "  print(\"Stigna li do kraj: \" + str(session_start == len(predictions)))\n",
        "  print(f\"====================== Примерок ({i}) ======================\\n\\n\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "====================== Примерок (5) ======================\n",
            "Вчитување тест податоци од испитниот примерок 5...\n",
            "\t - Тест податоците од сесија 1 се вчитани.\n",
            "\t - Тест податоците од сесија 2 се вчитани.\n",
            "\t - Тест податоците од сесија 3 се вчитани.\n",
            "Тест податоците од испитниот примерок 5 се вчитани.\n",
            "\n",
            "SBJ04| Test_data: (8, 350, 8800)\n",
            "SBJ04| Test_events: 8800\n",
            "SBJ04 / S00| Runs per block: 8\n",
            "SBJ04 / S01| Runs per block: 7\n",
            "SBJ04 / S02| Runs per block: 7\n",
            "SBJ04| Predictions: 8800\n",
            "============== Сесија (0) ==============\n",
            "4,1,1,3,5,3,4,1,1,2,6,2,2,1,6,4,5,1,0,1,0,0,2,0,2,5,3,1,1,5,1,3,5,1,1,1,5,2,0,1,0,2,6,0,6,3,0,0,6,4,\n",
            "============== Сесија (1) ==============\n",
            "1,5,6,4,1,5,6,6,5,6,5,3,5,5,5,5,5,5,3,5,4,5,5,5,5,5,5,1,5,3,5,0,0,5,4,5,3,5,0,5,3,1,5,0,5,5,6,5,5,5,\n",
            "============== Сесија (2) ==============\n",
            "4,6,6,5,4,6,1,3,5,1,1,5,5,5,6,1,7,4,1,4,4,1,4,1,6,5,1,6,3,3,4,4,1,1,1,5,0,6,7,5,5,6,6,1,1,6,4,1,3,1,\n",
            "Stigna li do kraj: True\n",
            "====================== Примерок (5) ======================\n",
            "\n",
            "\n",
            "====================== Примерок (6) ======================\n",
            "Вчитување тест податоци од испитниот примерок 6...\n",
            "\t - Тест податоците од сесија 1 се вчитани.\n",
            "\t - Тест податоците од сесија 2 се вчитани.\n",
            "\t - Тест податоците од сесија 3 се вчитани.\n",
            "Тест податоците од испитниот примерок 6 се вчитани.\n",
            "\n",
            "SBJ05| Test_data: (8, 350, 8000)\n",
            "SBJ05| Test_events: 8000\n",
            "SBJ05 / S00| Runs per block: 4\n",
            "SBJ05 / S01| Runs per block: 7\n",
            "SBJ05 / S02| Runs per block: 9\n",
            "SBJ05| Predictions: 8000\n",
            "============== Сесија (0) ==============\n",
            "0,0,0,0,2,2,0,6,6,1,0,0,0,2,7,1,0,7,7,6,0,0,6,2,0,7,0,0,0,3,0,7,2,0,0,0,3,6,0,3,2,3,6,6,0,0,3,0,6,7,\n",
            "============== Сесија (1) ==============\n",
            "0,0,0,7,0,0,0,0,7,0,3,0,0,0,2,7,0,0,3,3,3,3,3,0,7,3,1,5,0,1,1,0,3,7,7,3,3,0,0,3,1,0,3,7,4,4,4,7,6,4,\n",
            "============== Сесија (2) ==============\n",
            "0,2,0,0,0,0,0,0,0,2,0,0,0,0,2,2,2,2,0,0,0,0,2,0,0,2,2,0,0,0,0,0,0,0,0,2,0,0,0,0,0,7,0,0,0,0,0,0,0,0,\n",
            "Stigna li do kraj: True\n",
            "====================== Примерок (6) ======================\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_854cF8A9NHD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# test_data = reshape_data_to_mne_format(test_data)\n",
        "# print(test_data.shape)\n",
        "# predictions = model.predict(X_test)\n",
        "# np.savetxt(\"predictions.csv\", predictions, delimiter=\",\")\n",
        "# np.savetxt(\"y_test.csv\", y_test, delimiter=\",\")\n",
        "\n",
        "\n",
        "# predictions = model.predict(X_test)\n",
        "# np.savetxt(\"predictions.csv\", predictions, delimiter=\",\")\n",
        "# np.savetxt(\"y_test.csv\", y_test, delimiter=\",\")\n",
        "\n",
        "# from collections import Counter\n",
        "# int_pred = np.argmax(predictions, axis=1)\n",
        "# int_ytest = np.argmax(y_test, axis=1)\n",
        "\n",
        "# correct = 0\n",
        "# for i in range(20):\n",
        "#   block_y = int_ytest[i*80:(i+1)*80]\n",
        "#   block_y_pred = int_pred[i*80:(i+1)*80]\n",
        "\n",
        "#   class_y = np.bincount(block_y).argmax()\n",
        "#   class_y_pred = np.bincount(block_y_pred).argmax()\n",
        "\n",
        "#   print(f\"Class Y: {class_y}, prediciton: {class_y_pred}\")\n",
        "#   if class_y == class_y_pred:\n",
        "#     correct = correct+1\n",
        "\n",
        "# correct"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}