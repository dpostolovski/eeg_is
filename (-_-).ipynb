{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of IS_project.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dpostolovski/eeg_is/blob/train_compare_full_data/(-_-).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wBqW8_NNlAgz",
        "colab_type": "text"
      },
      "source": [
        "<center>\n",
        "  <img alt=\"FINKI **LOGO**\" height=\"auto\" src=\"https://www.finki.ukim.mk/Content/dataImages/downloads/logo-large-500x500_2.png\" hspace=\"10px\" vspace=\"0px\">\n",
        "  <h1>\n",
        "    Интелигентни системи - Лабораториска вежба\n",
        "  </h1>\n",
        "\n",
        "  <h3><i>Група 5</i></h3>\n",
        "  <h4><i>Дамjан Постоловски, Стефан Тодоровски, Ангела Кралевска, Иван Крстев, Мариjа Величковска</i></h2>\n",
        "</center>\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UTx3XQgUOhCX",
        "colab_type": "code",
        "cellView": "both",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        },
        "outputId": "406aad59-ce36-452a-e555-ad3fcd04607e"
      },
      "source": [
        "#@title Монтирање на Google Drive податочниот систем\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rLrrPj8clKjP",
        "colab_type": "code",
        "cellView": "both",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 212
        },
        "outputId": "0df58fc8-546f-402c-fdcc-e05ec5c7a7f2"
      },
      "source": [
        "#@title Инсталирање, вчитување и иницијализација на потребните библиотеки\n",
        "!pip install mne \n",
        "!pip install termcolor\n",
        "\n",
        "%tensorflow_version 1.12.0\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import mne\n",
        "\n",
        "from sklearn import metrics \n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint \n",
        "from tensorflow.keras.utils import to_categorical as to_cat\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras import backend as K\n",
        "\n",
        "from scipy.io import loadmat\n",
        "from collections import Counter\n",
        "\n",
        "%cd drive/My\\ Drive/Интелигентни\\ Системи\n",
        "from EEGModels import DeepConvNet, EEGNet\n",
        "\n",
        "!mkdir saved_models\n",
        "\n",
        "K.set_image_data_format('channels_first')"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: mne in /usr/local/lib/python3.6/dist-packages (0.20.7)\n",
            "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.6/dist-packages (from mne) (1.18.5)\n",
            "Requirement already satisfied: scipy>=0.17.1 in /usr/local/lib/python3.6/dist-packages (from mne) (1.4.1)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.6/dist-packages (1.1.0)\n",
            "`%tensorflow_version` only switches the major version: 1.x or 2.x.\n",
            "You set: `1.12.0`. This will be interpreted as: `1.x`.\n",
            "\n",
            "\n",
            "TensorFlow is already loaded. Please restart the runtime to change versions.\n",
            "[Errno 2] No such file or directory: 'drive/My Drive/Интелигентни Системи'\n",
            "/content/drive/.shortcut-targets-by-id/1foXUZVE0mxnmx1CREGLvuWb3DEHpgrMB/Интелигентни Системи\n",
            "mkdir: cannot create directory ‘saved_models’: File exists\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qFQrid4jlFwH",
        "colab_type": "text"
      },
      "source": [
        "## Иницијализација на функции кои ќе ги користиме\n",
        "1. load_mat_data - ги вчитува .mat податоците.\n",
        "2. load_txt_data - ги вчитува .txt податоците.\n",
        "3. load_data - ги повикува претходните две функции и ги вчитува податоците за даден учесник.\n",
        "4. reshape -\n",
        "5. reshape_data_to_mne_format -\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l5zBkobVEkTf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_mat_data(folder_path, file_name, mode = 'Train'):\n",
        "    \"\"\"\n",
        "        Load and concatenate train mat data from all three sessions.\n",
        "\n",
        "        :param folder_path: path to the participant data\n",
        "        :param file_name: the name of the mat file to be loaded (without .mat extension)\n",
        "        :param mode: Train or Test data \n",
        "        :return: numpy array containing the mat data\n",
        "    \"\"\"\n",
        "    data = np.empty(0)\n",
        "    for session in range(1, 4):  # Итерација низ секоја сесија\n",
        "        path = folder_path + '/S' + format(session, '02') + '/' + mode + '/' + file_name + '.mat'\n",
        "        temp = loadmat(path)[file_name]\n",
        "        if data.size != 0:\n",
        "            data = np.concatenate((data, temp), axis=2)\n",
        "        else:\n",
        "            data = np.array(temp)\n",
        "    return data\n",
        "\n",
        "\n",
        "def load_txt_data(folder_path, file_name, mode = 'Train'):\n",
        "    \"\"\"\n",
        "        Load and concatenate txt data from all three sessions.\n",
        "\n",
        "        :param folder_path: path to the participant data\n",
        "        :param file_name: the name of the file to be loaded\n",
        "        :param mode: Train or Test data \n",
        "        :return: numpy array containing the wanted data\n",
        "    \"\"\"\n",
        "    data = np.empty(0)\n",
        "    for session in range(1, 4):  # Итерација низ секоја сесија\n",
        "        path = folder_path + '/S' + format(session, '02') + '/' + mode + '/' + file_name\n",
        "        with open(path, \"r\") as file:\n",
        "            temp = file.read().splitlines()\n",
        "            if file_name == 'trainLabels.txt':\n",
        "                temp = np.repeat(temp, 8 * 10)\n",
        "            if data.size != 0:\n",
        "                data = np.concatenate((data, temp))\n",
        "            else:\n",
        "                data = np.array(temp)\n",
        "    return data\n",
        "\n",
        "\n",
        "def load_data(participant):\n",
        "    \"\"\"\n",
        "        Load data for the given participant.\n",
        "\n",
        "        :param participant: Participant number (1-15)\n",
        "        :return: train_data, train_labels, train_events, train_targets\n",
        "    \"\"\"\n",
        "    print(\"Вчитување податоци од испитниот примерок (учесник) \" + str(participant) + '...')\n",
        "    path_to_data = 'Data/SBJ' + format(participant, '02')\n",
        "\n",
        "    train_data = load_mat_data(path_to_data, 'trainData')\n",
        "    train_labels = load_txt_data(path_to_data, 'trainLabels.txt')\n",
        "    train_events = load_txt_data(path_to_data, 'trainEvents.txt')\n",
        "    train_targets = load_txt_data(path_to_data, 'trainTargets.txt')\n",
        "\n",
        "    print(\"Податоците од испитниот примерок (учесник) \" + str(participant) + \" се вчитани.\\n\")\n",
        "    return train_data, train_labels, train_events, train_targets\n",
        "\n",
        "\n",
        "def load_test_data(participant):\n",
        "    \"\"\"\n",
        "        Load test data for the given participant.\n",
        "\n",
        "        :param participant: Participant number (1-15)\n",
        "        :return: test_date, test_events\n",
        "    \"\"\"\n",
        "    print(\"Вчитување тест податоци од испитниот примерок (учесник) \" + str(participant) + '...')\n",
        "    path_to_data = 'Data/SBJ' + format(participant, '02')\n",
        "\n",
        "    test_date = load_mat_data(path_to_data, 'testData', 'Test')\n",
        "    test_events = load_txt_data(path_to_data, 'testEvents.txt', 'Test')\n",
        "\n",
        "    print(\"Податоците од испитниот примерок (учесник) \" + str(participant) + \" се вчитани.\\n\")\n",
        "    return test_date, test_events\n",
        "\n",
        "\n",
        "def reshape(data, labels, events, targets):\n",
        "  mne_array = np.swapaxes(data, 0, 2) # (епохa, канал, настан). \n",
        "  mne_array = np.swapaxes(mne_array, 1, 2) # (епохa, канал, настан). \n",
        "  mne_array = mne_array.reshape(mne_array.shape[0], 1, 8, 350)\n",
        "\n",
        "  labels_arr = labels.astype(np.int)\n",
        "  events_arr = events.astype(np.int)\n",
        "  return mne_array, labels_arr-1, events_arr-1\n",
        "\n",
        "\n",
        "def reshape_data_to_mne_format(data):\n",
        "  mne_array = np.swapaxes(data, 0, 2) # (епохa, канал, настан). \n",
        "  mne_array = np.swapaxes(mne_array, 1, 2) # (епохa, канал, настан). \n",
        "  mne_array = mne_array.reshape(mne_array.shape[0], 1, 8, 350)\n",
        "\n",
        "  return mne_array"
      ],
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9hj0HEEqPVBa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "9782d330-dcfd-4db3-f4aa-5f16fd8e4978"
      },
      "source": [
        "PARTICIPANT_START = 5\n",
        "PARTICIPANT_END = 7\n",
        "\n",
        "# Глобална низа каде ќе се зачувуваат тренираните модели\n",
        "models = []\n",
        "\n",
        "for participant in range(PARTICIPANT_START, PARTICIPANT_END):  # Итерација низ секој испитен примерок\n",
        "    train_data, train_labels, train_events, train_targets = load_data(participant)\n",
        "    \n",
        "    data, labels, events = reshape(train_data, train_labels, train_events, train_targets)\n",
        "    X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.25, random_state=42)\n",
        "\n",
        "    model = DeepConvNet(nb_classes = 8, Chans = 8, Samples = 350)\n",
        "    model.compile(loss = 'categorical_crossentropy', metrics=['accuracy'],optimizer = Adam(0.0009))\n",
        "    checkpointer = ModelCheckpoint(filepath='saved_models/weights.best.basic_mlp.hdf5', \n",
        "                                  verbose=1, save_best_only=True)\n",
        "\n",
        "    y_train = to_cat(y_train)\n",
        "    y_test = to_cat(y_test)\n",
        "\n",
        "    num_batch_size=100\n",
        "    num_epochs=50\n",
        "    model.fit(X_train, y_train, batch_size=num_batch_size, epochs=num_epochs, \\\n",
        "              validation_data=(X_test, y_test),callbacks=[checkpointer], verbose=1)\n",
        "\n",
        "    score = model.evaluate(X_test, y_test, verbose=1)\n",
        "    print(score)\n",
        "\n",
        "    models.append(model) # Ke imame 15 modeli neli, pa vo niza se staveni\n",
        "                        # pristap do niv model[i]"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Вчитување тест податоци од испитниот примерок (учесник) 5...\n",
            "Податоците од испитниот примерок (учесник) 5 се вчитани.\n",
            "\n",
            "Version 10\n",
            "Version 10\n",
            "Version 10\n",
            "Version 10\n",
            "Version 10\n",
            "Version 10\n",
            "Version 10\n",
            "Train on 3600 samples, validate on 1200 samples\n",
            "Epoch 1/50\n",
            "3400/3600 [===========================>..] - ETA: 0s - loss: 2.3218 - acc: 0.1526\n",
            "Epoch 00001: val_loss improved from inf to 2.41387, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
            "3600/3600 [==============================] - 13s 4ms/sample - loss: 2.3192 - acc: 0.1556 - val_loss: 2.4139 - val_acc: 0.1158\n",
            "Epoch 2/50\n",
            "3400/3600 [===========================>..] - ETA: 0s - loss: 2.2736 - acc: 0.1697\n",
            "Epoch 00002: val_loss did not improve from 2.41387\n",
            "3600/3600 [==============================] - 1s 280us/sample - loss: 2.2745 - acc: 0.1672 - val_loss: 2.6321 - val_acc: 0.0908\n",
            "Epoch 3/50\n",
            "3400/3600 [===========================>..] - ETA: 0s - loss: 2.2257 - acc: 0.1776\n",
            "Epoch 00003: val_loss did not improve from 2.41387\n",
            "3600/3600 [==============================] - 1s 243us/sample - loss: 2.2221 - acc: 0.1783 - val_loss: 2.4442 - val_acc: 0.1142\n",
            "Epoch 4/50\n",
            "3400/3600 [===========================>..] - ETA: 0s - loss: 2.1421 - acc: 0.1976\n",
            "Epoch 00004: val_loss improved from 2.41387 to 2.20978, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
            "3600/3600 [==============================] - 1s 278us/sample - loss: 2.1417 - acc: 0.1981 - val_loss: 2.2098 - val_acc: 0.1358\n",
            "Epoch 5/50\n",
            "3400/3600 [===========================>..] - ETA: 0s - loss: 2.0491 - acc: 0.2426\n",
            "Epoch 00005: val_loss improved from 2.20978 to 2.02518, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
            "3600/3600 [==============================] - 1s 284us/sample - loss: 2.0453 - acc: 0.2433 - val_loss: 2.0252 - val_acc: 0.1750\n",
            "Epoch 6/50\n",
            "3400/3600 [===========================>..] - ETA: 0s - loss: 1.8408 - acc: 0.3200\n",
            "Epoch 00006: val_loss did not improve from 2.02518\n",
            "3600/3600 [==============================] - 1s 239us/sample - loss: 1.8398 - acc: 0.3189 - val_loss: 2.0761 - val_acc: 0.2242\n",
            "Epoch 7/50\n",
            "3400/3600 [===========================>..] - ETA: 0s - loss: 1.7497 - acc: 0.3350\n",
            "Epoch 00007: val_loss improved from 2.02518 to 1.71125, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
            "3600/3600 [==============================] - 1s 282us/sample - loss: 1.7478 - acc: 0.3344 - val_loss: 1.7113 - val_acc: 0.3400\n",
            "Epoch 8/50\n",
            "3400/3600 [===========================>..] - ETA: 0s - loss: 1.6988 - acc: 0.3668\n",
            "Epoch 00008: val_loss did not improve from 1.71125\n",
            "3600/3600 [==============================] - 1s 246us/sample - loss: 1.7017 - acc: 0.3656 - val_loss: 1.8661 - val_acc: 0.2592\n",
            "Epoch 9/50\n",
            "3400/3600 [===========================>..] - ETA: 0s - loss: 1.6362 - acc: 0.3812\n",
            "Epoch 00009: val_loss did not improve from 1.71125\n",
            "3600/3600 [==============================] - 1s 239us/sample - loss: 1.6380 - acc: 0.3803 - val_loss: 2.0060 - val_acc: 0.2133\n",
            "Epoch 10/50\n",
            "3400/3600 [===========================>..] - ETA: 0s - loss: 1.5683 - acc: 0.3921\n",
            "Epoch 00010: val_loss did not improve from 1.71125\n",
            "3600/3600 [==============================] - 1s 246us/sample - loss: 1.5728 - acc: 0.3922 - val_loss: 1.8610 - val_acc: 0.3092\n",
            "Epoch 11/50\n",
            "3400/3600 [===========================>..] - ETA: 0s - loss: 1.5383 - acc: 0.4153\n",
            "Epoch 00011: val_loss did not improve from 1.71125\n",
            "3600/3600 [==============================] - 1s 251us/sample - loss: 1.5360 - acc: 0.4142 - val_loss: 1.7807 - val_acc: 0.3175\n",
            "Epoch 12/50\n",
            "3400/3600 [===========================>..] - ETA: 0s - loss: 1.5263 - acc: 0.4247\n",
            "Epoch 00012: val_loss improved from 1.71125 to 1.60893, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
            "3600/3600 [==============================] - 1s 278us/sample - loss: 1.5209 - acc: 0.4256 - val_loss: 1.6089 - val_acc: 0.3600\n",
            "Epoch 13/50\n",
            "3500/3600 [============================>.] - ETA: 0s - loss: 1.4747 - acc: 0.4540\n",
            "Epoch 00013: val_loss did not improve from 1.60893\n",
            "3600/3600 [==============================] - 1s 256us/sample - loss: 1.4770 - acc: 0.4508 - val_loss: 1.7936 - val_acc: 0.3400\n",
            "Epoch 14/50\n",
            "3400/3600 [===========================>..] - ETA: 0s - loss: 1.3685 - acc: 0.4871\n",
            "Epoch 00014: val_loss did not improve from 1.60893\n",
            "3600/3600 [==============================] - 1s 249us/sample - loss: 1.3728 - acc: 0.4850 - val_loss: 1.6998 - val_acc: 0.3733\n",
            "Epoch 15/50\n",
            "3400/3600 [===========================>..] - ETA: 0s - loss: 1.3770 - acc: 0.4832\n",
            "Epoch 00015: val_loss did not improve from 1.60893\n",
            "3600/3600 [==============================] - 1s 242us/sample - loss: 1.3833 - acc: 0.4803 - val_loss: 2.2648 - val_acc: 0.2083\n",
            "Epoch 16/50\n",
            "3500/3600 [============================>.] - ETA: 0s - loss: 1.3132 - acc: 0.5091\n",
            "Epoch 00016: val_loss improved from 1.60893 to 1.58029, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
            "3600/3600 [==============================] - 1s 292us/sample - loss: 1.3112 - acc: 0.5092 - val_loss: 1.5803 - val_acc: 0.3917\n",
            "Epoch 17/50\n",
            "3400/3600 [===========================>..] - ETA: 0s - loss: 1.2806 - acc: 0.5235\n",
            "Epoch 00017: val_loss improved from 1.58029 to 1.39259, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
            "3600/3600 [==============================] - 1s 283us/sample - loss: 1.2825 - acc: 0.5225 - val_loss: 1.3926 - val_acc: 0.4625\n",
            "Epoch 18/50\n",
            "3400/3600 [===========================>..] - ETA: 0s - loss: 1.2186 - acc: 0.5418\n",
            "Epoch 00018: val_loss improved from 1.39259 to 1.29324, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
            "3600/3600 [==============================] - 1s 285us/sample - loss: 1.2208 - acc: 0.5397 - val_loss: 1.2932 - val_acc: 0.5017\n",
            "Epoch 19/50\n",
            "3400/3600 [===========================>..] - ETA: 0s - loss: 1.2046 - acc: 0.5526\n",
            "Epoch 00019: val_loss did not improve from 1.29324\n",
            "3600/3600 [==============================] - 1s 257us/sample - loss: 1.2144 - acc: 0.5500 - val_loss: 1.6586 - val_acc: 0.3850\n",
            "Epoch 20/50\n",
            "3400/3600 [===========================>..] - ETA: 0s - loss: 1.1754 - acc: 0.5515\n",
            "Epoch 00020: val_loss did not improve from 1.29324\n",
            "3600/3600 [==============================] - 1s 246us/sample - loss: 1.1750 - acc: 0.5522 - val_loss: 1.3113 - val_acc: 0.5292\n",
            "Epoch 21/50\n",
            "3400/3600 [===========================>..] - ETA: 0s - loss: 1.1486 - acc: 0.5726\n",
            "Epoch 00021: val_loss improved from 1.29324 to 1.27602, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
            "3600/3600 [==============================] - 1s 279us/sample - loss: 1.1507 - acc: 0.5700 - val_loss: 1.2760 - val_acc: 0.5258\n",
            "Epoch 22/50\n",
            "3400/3600 [===========================>..] - ETA: 0s - loss: 1.0959 - acc: 0.5832\n",
            "Epoch 00022: val_loss did not improve from 1.27602\n",
            "3600/3600 [==============================] - 1s 253us/sample - loss: 1.0975 - acc: 0.5850 - val_loss: 1.3526 - val_acc: 0.4675\n",
            "Epoch 23/50\n",
            "3400/3600 [===========================>..] - ETA: 0s - loss: 1.0560 - acc: 0.6082\n",
            "Epoch 00023: val_loss did not improve from 1.27602\n",
            "3600/3600 [==============================] - 1s 248us/sample - loss: 1.0570 - acc: 0.6097 - val_loss: 1.4744 - val_acc: 0.4150\n",
            "Epoch 24/50\n",
            "3400/3600 [===========================>..] - ETA: 0s - loss: 1.0413 - acc: 0.6118\n",
            "Epoch 00024: val_loss did not improve from 1.27602\n",
            "3600/3600 [==============================] - 1s 248us/sample - loss: 1.0472 - acc: 0.6100 - val_loss: 1.2782 - val_acc: 0.5158\n",
            "Epoch 25/50\n",
            "3400/3600 [===========================>..] - ETA: 0s - loss: 1.0136 - acc: 0.6262\n",
            "Epoch 00025: val_loss improved from 1.27602 to 1.23768, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
            "3600/3600 [==============================] - 1s 294us/sample - loss: 1.0137 - acc: 0.6244 - val_loss: 1.2377 - val_acc: 0.5225\n",
            "Epoch 26/50\n",
            "3400/3600 [===========================>..] - ETA: 0s - loss: 0.9939 - acc: 0.6318\n",
            "Epoch 00026: val_loss improved from 1.23768 to 1.09824, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
            "3600/3600 [==============================] - 1s 281us/sample - loss: 0.9956 - acc: 0.6303 - val_loss: 1.0982 - val_acc: 0.5825\n",
            "Epoch 27/50\n",
            "3400/3600 [===========================>..] - ETA: 0s - loss: 0.9619 - acc: 0.6444\n",
            "Epoch 00027: val_loss improved from 1.09824 to 1.07841, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
            "3600/3600 [==============================] - 1s 289us/sample - loss: 0.9678 - acc: 0.6417 - val_loss: 1.0784 - val_acc: 0.6042\n",
            "Epoch 28/50\n",
            "3300/3600 [==========================>...] - ETA: 0s - loss: 0.9071 - acc: 0.6679\n",
            "Epoch 00028: val_loss did not improve from 1.07841\n",
            "3600/3600 [==============================] - 1s 250us/sample - loss: 0.9060 - acc: 0.6678 - val_loss: 1.1077 - val_acc: 0.5783\n",
            "Epoch 29/50\n",
            "3400/3600 [===========================>..] - ETA: 0s - loss: 0.8486 - acc: 0.6882\n",
            "Epoch 00029: val_loss did not improve from 1.07841\n",
            "3600/3600 [==============================] - 1s 248us/sample - loss: 0.8515 - acc: 0.6867 - val_loss: 1.1724 - val_acc: 0.5575\n",
            "Epoch 30/50\n",
            "3400/3600 [===========================>..] - ETA: 0s - loss: 0.8494 - acc: 0.6800\n",
            "Epoch 00030: val_loss did not improve from 1.07841\n",
            "3600/3600 [==============================] - 1s 255us/sample - loss: 0.8490 - acc: 0.6811 - val_loss: 1.0793 - val_acc: 0.5800\n",
            "Epoch 31/50\n",
            "3400/3600 [===========================>..] - ETA: 0s - loss: 0.8098 - acc: 0.7032\n",
            "Epoch 00031: val_loss improved from 1.07841 to 1.07358, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
            "3600/3600 [==============================] - 1s 278us/sample - loss: 0.8099 - acc: 0.7044 - val_loss: 1.0736 - val_acc: 0.5925\n",
            "Epoch 32/50\n",
            "3400/3600 [===========================>..] - ETA: 0s - loss: 0.7916 - acc: 0.7135\n",
            "Epoch 00032: val_loss improved from 1.07358 to 0.99865, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
            "3600/3600 [==============================] - 1s 281us/sample - loss: 0.7965 - acc: 0.7097 - val_loss: 0.9986 - val_acc: 0.6150\n",
            "Epoch 33/50\n",
            "3400/3600 [===========================>..] - ETA: 0s - loss: 0.7866 - acc: 0.7097\n",
            "Epoch 00033: val_loss did not improve from 0.99865\n",
            "3600/3600 [==============================] - 1s 257us/sample - loss: 0.7811 - acc: 0.7128 - val_loss: 1.0076 - val_acc: 0.6292\n",
            "Epoch 34/50\n",
            "3400/3600 [===========================>..] - ETA: 0s - loss: 0.7584 - acc: 0.7309\n",
            "Epoch 00034: val_loss improved from 0.99865 to 0.92830, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
            "3600/3600 [==============================] - 1s 281us/sample - loss: 0.7608 - acc: 0.7297 - val_loss: 0.9283 - val_acc: 0.6383\n",
            "Epoch 35/50\n",
            "3400/3600 [===========================>..] - ETA: 0s - loss: 0.7111 - acc: 0.7385\n",
            "Epoch 00035: val_loss improved from 0.92830 to 0.74828, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
            "3600/3600 [==============================] - 1s 284us/sample - loss: 0.7154 - acc: 0.7369 - val_loss: 0.7483 - val_acc: 0.7392\n",
            "Epoch 36/50\n",
            "3400/3600 [===========================>..] - ETA: 0s - loss: 0.6804 - acc: 0.7647\n",
            "Epoch 00036: val_loss did not improve from 0.74828\n",
            "3600/3600 [==============================] - 1s 251us/sample - loss: 0.6822 - acc: 0.7647 - val_loss: 0.9378 - val_acc: 0.6483\n",
            "Epoch 37/50\n",
            "3400/3600 [===========================>..] - ETA: 0s - loss: 0.6625 - acc: 0.7691\n",
            "Epoch 00037: val_loss did not improve from 0.74828\n",
            "3600/3600 [==============================] - 1s 245us/sample - loss: 0.6631 - acc: 0.7692 - val_loss: 0.7988 - val_acc: 0.7000\n",
            "Epoch 38/50\n",
            "3300/3600 [==========================>...] - ETA: 0s - loss: 0.6543 - acc: 0.7582\n",
            "Epoch 00038: val_loss improved from 0.74828 to 0.71943, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
            "3600/3600 [==============================] - 1s 292us/sample - loss: 0.6668 - acc: 0.7553 - val_loss: 0.7194 - val_acc: 0.7342\n",
            "Epoch 39/50\n",
            "3400/3600 [===========================>..] - ETA: 0s - loss: 0.5940 - acc: 0.7935\n",
            "Epoch 00039: val_loss did not improve from 0.71943\n",
            "3600/3600 [==============================] - 1s 250us/sample - loss: 0.6009 - acc: 0.7900 - val_loss: 0.8025 - val_acc: 0.6975\n",
            "Epoch 40/50\n",
            "3400/3600 [===========================>..] - ETA: 0s - loss: 0.6157 - acc: 0.7812\n",
            "Epoch 00040: val_loss did not improve from 0.71943\n",
            "3600/3600 [==============================] - 1s 243us/sample - loss: 0.6199 - acc: 0.7772 - val_loss: 0.7833 - val_acc: 0.6950\n",
            "Epoch 41/50\n",
            "3400/3600 [===========================>..] - ETA: 0s - loss: 0.5742 - acc: 0.8012\n",
            "Epoch 00041: val_loss improved from 0.71943 to 0.63562, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
            "3600/3600 [==============================] - 1s 286us/sample - loss: 0.5754 - acc: 0.8000 - val_loss: 0.6356 - val_acc: 0.7883\n",
            "Epoch 42/50\n",
            "3300/3600 [==========================>...] - ETA: 0s - loss: 0.5393 - acc: 0.8167\n",
            "Epoch 00042: val_loss did not improve from 0.63562\n",
            "3600/3600 [==============================] - 1s 251us/sample - loss: 0.5438 - acc: 0.8128 - val_loss: 0.7136 - val_acc: 0.7408\n",
            "Epoch 43/50\n",
            "3300/3600 [==========================>...] - ETA: 0s - loss: 0.5426 - acc: 0.8115\n",
            "Epoch 00043: val_loss did not improve from 0.63562\n",
            "3600/3600 [==============================] - 1s 248us/sample - loss: 0.5415 - acc: 0.8136 - val_loss: 0.7081 - val_acc: 0.7425\n",
            "Epoch 44/50\n",
            "3300/3600 [==========================>...] - ETA: 0s - loss: 0.5415 - acc: 0.8170\n",
            "Epoch 00044: val_loss improved from 0.63562 to 0.59407, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
            "3600/3600 [==============================] - 1s 324us/sample - loss: 0.5421 - acc: 0.8147 - val_loss: 0.5941 - val_acc: 0.8017\n",
            "Epoch 45/50\n",
            "3400/3600 [===========================>..] - ETA: 0s - loss: 0.5023 - acc: 0.8306\n",
            "Epoch 00045: val_loss improved from 0.59407 to 0.55182, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
            "3600/3600 [==============================] - 1s 279us/sample - loss: 0.5026 - acc: 0.8297 - val_loss: 0.5518 - val_acc: 0.8250\n",
            "Epoch 46/50\n",
            "3400/3600 [===========================>..] - ETA: 0s - loss: 0.5025 - acc: 0.8276\n",
            "Epoch 00046: val_loss did not improve from 0.55182\n",
            "3600/3600 [==============================] - 1s 249us/sample - loss: 0.5104 - acc: 0.8242 - val_loss: 0.6015 - val_acc: 0.7933\n",
            "Epoch 47/50\n",
            "3400/3600 [===========================>..] - ETA: 0s - loss: 0.4787 - acc: 0.8397\n",
            "Epoch 00047: val_loss did not improve from 0.55182\n",
            "3600/3600 [==============================] - 1s 255us/sample - loss: 0.4812 - acc: 0.8383 - val_loss: 0.5915 - val_acc: 0.7975\n",
            "Epoch 48/50\n",
            "3400/3600 [===========================>..] - ETA: 0s - loss: 0.4773 - acc: 0.8400\n",
            "Epoch 00048: val_loss did not improve from 0.55182\n",
            "3600/3600 [==============================] - 1s 246us/sample - loss: 0.4833 - acc: 0.8361 - val_loss: 0.5852 - val_acc: 0.8000\n",
            "Epoch 49/50\n",
            "3400/3600 [===========================>..] - ETA: 0s - loss: 0.4599 - acc: 0.8450\n",
            "Epoch 00049: val_loss did not improve from 0.55182\n",
            "3600/3600 [==============================] - 1s 247us/sample - loss: 0.4575 - acc: 0.8469 - val_loss: 0.5736 - val_acc: 0.8150\n",
            "Epoch 50/50\n",
            "3400/3600 [===========================>..] - ETA: 0s - loss: 0.4411 - acc: 0.8503\n",
            "Epoch 00050: val_loss improved from 0.55182 to 0.48787, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
            "3600/3600 [==============================] - 1s 292us/sample - loss: 0.4402 - acc: 0.8508 - val_loss: 0.4879 - val_acc: 0.8383\n",
            "1200/1200 [==============================] - 0s 148us/sample - loss: 0.4879 - acc: 0.8383\n",
            "[0.4878654634952545, 0.8383333]\n",
            "Вчитување тест податоци од испитниот примерок (учесник) 6...\n",
            "Податоците од испитниот примерок (учесник) 6 се вчитани.\n",
            "\n",
            "Version 10\n",
            "Version 10\n",
            "Version 10\n",
            "Version 10\n",
            "Version 10\n",
            "Version 10\n",
            "Version 10\n",
            "Train on 3600 samples, validate on 1200 samples\n",
            "Epoch 1/50\n",
            "3500/3600 [============================>.] - ETA: 0s - loss: 2.3692 - acc: 0.1386\n",
            "Epoch 00001: val_loss improved from inf to 2.27226, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
            "3600/3600 [==============================] - 13s 4ms/sample - loss: 2.3657 - acc: 0.1389 - val_loss: 2.2723 - val_acc: 0.1217\n",
            "Epoch 2/50\n",
            "3300/3600 [==========================>...] - ETA: 0s - loss: 2.2465 - acc: 0.1645\n",
            "Epoch 00002: val_loss did not improve from 2.27226\n",
            "3600/3600 [==============================] - 1s 277us/sample - loss: 2.2493 - acc: 0.1631 - val_loss: 2.2908 - val_acc: 0.1425\n",
            "Epoch 3/50\n",
            "3300/3600 [==========================>...] - ETA: 0s - loss: 2.2227 - acc: 0.1782\n",
            "Epoch 00003: val_loss did not improve from 2.27226\n",
            "3600/3600 [==============================] - 1s 256us/sample - loss: 2.2177 - acc: 0.1783 - val_loss: 2.3299 - val_acc: 0.1267\n",
            "Epoch 4/50\n",
            "3400/3600 [===========================>..] - ETA: 0s - loss: 2.1472 - acc: 0.2094\n",
            "Epoch 00004: val_loss improved from 2.27226 to 2.21102, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
            "3600/3600 [==============================] - 1s 278us/sample - loss: 2.1490 - acc: 0.2078 - val_loss: 2.2110 - val_acc: 0.1775\n",
            "Epoch 5/50\n",
            "3400/3600 [===========================>..] - ETA: 0s - loss: 2.0866 - acc: 0.2224\n",
            "Epoch 00005: val_loss improved from 2.21102 to 2.17161, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
            "3600/3600 [==============================] - 1s 283us/sample - loss: 2.0854 - acc: 0.2228 - val_loss: 2.1716 - val_acc: 0.1867\n",
            "Epoch 6/50\n",
            "3300/3600 [==========================>...] - ETA: 0s - loss: 2.0346 - acc: 0.2361\n",
            "Epoch 00006: val_loss improved from 2.17161 to 2.08955, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
            "3600/3600 [==============================] - 1s 293us/sample - loss: 2.0339 - acc: 0.2367 - val_loss: 2.0895 - val_acc: 0.2150\n",
            "Epoch 7/50\n",
            "3400/3600 [===========================>..] - ETA: 0s - loss: 1.9924 - acc: 0.2453\n",
            "Epoch 00007: val_loss did not improve from 2.08955\n",
            "3600/3600 [==============================] - 1s 244us/sample - loss: 1.9918 - acc: 0.2456 - val_loss: 2.1817 - val_acc: 0.1933\n",
            "Epoch 8/50\n",
            "3400/3600 [===========================>..] - ETA: 0s - loss: 1.9127 - acc: 0.2668\n",
            "Epoch 00008: val_loss did not improve from 2.08955\n",
            "3600/3600 [==============================] - 1s 251us/sample - loss: 1.9157 - acc: 0.2661 - val_loss: 2.2476 - val_acc: 0.2308\n",
            "Epoch 9/50\n",
            "3300/3600 [==========================>...] - ETA: 0s - loss: 1.8858 - acc: 0.2879\n",
            "Epoch 00009: val_loss did not improve from 2.08955\n",
            "3600/3600 [==============================] - 1s 253us/sample - loss: 1.8851 - acc: 0.2869 - val_loss: 2.1685 - val_acc: 0.2167\n",
            "Epoch 10/50\n",
            "3400/3600 [===========================>..] - ETA: 0s - loss: 1.8469 - acc: 0.2988\n",
            "Epoch 00010: val_loss did not improve from 2.08955\n",
            "3600/3600 [==============================] - 1s 249us/sample - loss: 1.8582 - acc: 0.2969 - val_loss: 2.2979 - val_acc: 0.2192\n",
            "Epoch 11/50\n",
            "3400/3600 [===========================>..] - ETA: 0s - loss: 1.8238 - acc: 0.3197\n",
            "Epoch 00011: val_loss did not improve from 2.08955\n",
            "3600/3600 [==============================] - 1s 253us/sample - loss: 1.8235 - acc: 0.3186 - val_loss: 2.2271 - val_acc: 0.2008\n",
            "Epoch 12/50\n",
            "3400/3600 [===========================>..] - ETA: 0s - loss: 1.7873 - acc: 0.3141\n",
            "Epoch 00012: val_loss did not improve from 2.08955\n",
            "3600/3600 [==============================] - 1s 252us/sample - loss: 1.7860 - acc: 0.3139 - val_loss: 2.0985 - val_acc: 0.2408\n",
            "Epoch 13/50\n",
            "3400/3600 [===========================>..] - ETA: 0s - loss: 1.7279 - acc: 0.3426\n",
            "Epoch 00013: val_loss improved from 2.08955 to 1.87694, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
            "3600/3600 [==============================] - 1s 285us/sample - loss: 1.7333 - acc: 0.3422 - val_loss: 1.8769 - val_acc: 0.2642\n",
            "Epoch 14/50\n",
            "3500/3600 [============================>.] - ETA: 0s - loss: 1.7142 - acc: 0.3543\n",
            "Epoch 00014: val_loss did not improve from 1.87694\n",
            "3600/3600 [==============================] - 1s 258us/sample - loss: 1.7170 - acc: 0.3536 - val_loss: 2.1533 - val_acc: 0.2217\n",
            "Epoch 15/50\n",
            "3400/3600 [===========================>..] - ETA: 0s - loss: 1.6864 - acc: 0.3665\n",
            "Epoch 00015: val_loss did not improve from 1.87694\n",
            "3600/3600 [==============================] - 1s 250us/sample - loss: 1.6866 - acc: 0.3675 - val_loss: 1.9653 - val_acc: 0.2633\n",
            "Epoch 16/50\n",
            "3400/3600 [===========================>..] - ETA: 0s - loss: 1.6670 - acc: 0.3626\n",
            "Epoch 00016: val_loss did not improve from 1.87694\n",
            "3600/3600 [==============================] - 1s 249us/sample - loss: 1.6714 - acc: 0.3617 - val_loss: 2.0938 - val_acc: 0.2550\n",
            "Epoch 17/50\n",
            "3400/3600 [===========================>..] - ETA: 0s - loss: 1.6267 - acc: 0.3824\n",
            "Epoch 00017: val_loss did not improve from 1.87694\n",
            "3600/3600 [==============================] - 1s 256us/sample - loss: 1.6300 - acc: 0.3808 - val_loss: 2.0685 - val_acc: 0.2608\n",
            "Epoch 18/50\n",
            "3400/3600 [===========================>..] - ETA: 0s - loss: 1.5930 - acc: 0.3918\n",
            "Epoch 00018: val_loss did not improve from 1.87694\n",
            "3600/3600 [==============================] - 1s 250us/sample - loss: 1.6006 - acc: 0.3892 - val_loss: 1.9325 - val_acc: 0.2858\n",
            "Epoch 19/50\n",
            "3400/3600 [===========================>..] - ETA: 0s - loss: 1.5739 - acc: 0.4074\n",
            "Epoch 00019: val_loss did not improve from 1.87694\n",
            "3600/3600 [==============================] - 1s 247us/sample - loss: 1.5773 - acc: 0.4031 - val_loss: 2.0079 - val_acc: 0.2933\n",
            "Epoch 20/50\n",
            "3400/3600 [===========================>..] - ETA: 0s - loss: 1.5445 - acc: 0.4288\n",
            "Epoch 00020: val_loss improved from 1.87694 to 1.86460, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
            "3600/3600 [==============================] - 1s 290us/sample - loss: 1.5477 - acc: 0.4239 - val_loss: 1.8646 - val_acc: 0.2758\n",
            "Epoch 21/50\n",
            "3400/3600 [===========================>..] - ETA: 0s - loss: 1.5114 - acc: 0.4303\n",
            "Epoch 00021: val_loss improved from 1.86460 to 1.75807, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
            "3600/3600 [==============================] - 1s 282us/sample - loss: 1.5097 - acc: 0.4308 - val_loss: 1.7581 - val_acc: 0.3200\n",
            "Epoch 22/50\n",
            "3400/3600 [===========================>..] - ETA: 0s - loss: 1.5146 - acc: 0.4353\n",
            "Epoch 00022: val_loss did not improve from 1.75807\n",
            "3600/3600 [==============================] - 1s 248us/sample - loss: 1.5151 - acc: 0.4333 - val_loss: 1.7853 - val_acc: 0.3267\n",
            "Epoch 23/50\n",
            "3500/3600 [============================>.] - ETA: 0s - loss: 1.4608 - acc: 0.4549\n",
            "Epoch 00023: val_loss did not improve from 1.75807\n",
            "3600/3600 [==============================] - 1s 265us/sample - loss: 1.4611 - acc: 0.4544 - val_loss: 1.9299 - val_acc: 0.3133\n",
            "Epoch 24/50\n",
            "3400/3600 [===========================>..] - ETA: 0s - loss: 1.4448 - acc: 0.4571\n",
            "Epoch 00024: val_loss did not improve from 1.75807\n",
            "3600/3600 [==============================] - 1s 250us/sample - loss: 1.4480 - acc: 0.4547 - val_loss: 1.8062 - val_acc: 0.3425\n",
            "Epoch 25/50\n",
            "3400/3600 [===========================>..] - ETA: 0s - loss: 1.4331 - acc: 0.4591\n",
            "Epoch 00025: val_loss did not improve from 1.75807\n",
            "3600/3600 [==============================] - 1s 252us/sample - loss: 1.4351 - acc: 0.4578 - val_loss: 1.7778 - val_acc: 0.3375\n",
            "Epoch 26/50\n",
            "3300/3600 [==========================>...] - ETA: 0s - loss: 1.4076 - acc: 0.4742\n",
            "Epoch 00026: val_loss did not improve from 1.75807\n",
            "3600/3600 [==============================] - 1s 257us/sample - loss: 1.4151 - acc: 0.4717 - val_loss: 1.8316 - val_acc: 0.3208\n",
            "Epoch 27/50\n",
            "3400/3600 [===========================>..] - ETA: 0s - loss: 1.3681 - acc: 0.4979\n",
            "Epoch 00027: val_loss improved from 1.75807 to 1.72729, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
            "3600/3600 [==============================] - 1s 283us/sample - loss: 1.3762 - acc: 0.4958 - val_loss: 1.7273 - val_acc: 0.3683\n",
            "Epoch 28/50\n",
            "3400/3600 [===========================>..] - ETA: 0s - loss: 1.3638 - acc: 0.5012\n",
            "Epoch 00028: val_loss did not improve from 1.72729\n",
            "3600/3600 [==============================] - 1s 254us/sample - loss: 1.3639 - acc: 0.5011 - val_loss: 1.7764 - val_acc: 0.3500\n",
            "Epoch 29/50\n",
            "3300/3600 [==========================>...] - ETA: 0s - loss: 1.3192 - acc: 0.5233\n",
            "Epoch 00029: val_loss improved from 1.72729 to 1.67458, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
            "3600/3600 [==============================] - 1s 291us/sample - loss: 1.3232 - acc: 0.5192 - val_loss: 1.6746 - val_acc: 0.3725\n",
            "Epoch 30/50\n",
            "3400/3600 [===========================>..] - ETA: 0s - loss: 1.3112 - acc: 0.5124\n",
            "Epoch 00030: val_loss did not improve from 1.67458\n",
            "3600/3600 [==============================] - 1s 249us/sample - loss: 1.3106 - acc: 0.5153 - val_loss: 1.6832 - val_acc: 0.3775\n",
            "Epoch 31/50\n",
            "3300/3600 [==========================>...] - ETA: 0s - loss: 1.2874 - acc: 0.5273\n",
            "Epoch 00031: val_loss improved from 1.67458 to 1.60147, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
            "3600/3600 [==============================] - 1s 296us/sample - loss: 1.2924 - acc: 0.5239 - val_loss: 1.6015 - val_acc: 0.3975\n",
            "Epoch 32/50\n",
            "3400/3600 [===========================>..] - ETA: 0s - loss: 1.2846 - acc: 0.5224\n",
            "Epoch 00032: val_loss did not improve from 1.60147\n",
            "3600/3600 [==============================] - 1s 256us/sample - loss: 1.2928 - acc: 0.5214 - val_loss: 1.6708 - val_acc: 0.3783\n",
            "Epoch 33/50\n",
            "3400/3600 [===========================>..] - ETA: 0s - loss: 1.2778 - acc: 0.5244\n",
            "Epoch 00033: val_loss improved from 1.60147 to 1.59134, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
            "3600/3600 [==============================] - 1s 282us/sample - loss: 1.2801 - acc: 0.5233 - val_loss: 1.5913 - val_acc: 0.3925\n",
            "Epoch 34/50\n",
            "3300/3600 [==========================>...] - ETA: 0s - loss: 1.2123 - acc: 0.5661\n",
            "Epoch 00034: val_loss did not improve from 1.59134\n",
            "3600/3600 [==============================] - 1s 264us/sample - loss: 1.2296 - acc: 0.5575 - val_loss: 1.5977 - val_acc: 0.3983\n",
            "Epoch 35/50\n",
            "3300/3600 [==========================>...] - ETA: 0s - loss: 1.1854 - acc: 0.5694\n",
            "Epoch 00035: val_loss improved from 1.59134 to 1.57446, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
            "3600/3600 [==============================] - 1s 286us/sample - loss: 1.1973 - acc: 0.5619 - val_loss: 1.5745 - val_acc: 0.4292\n",
            "Epoch 36/50\n",
            "3300/3600 [==========================>...] - ETA: 0s - loss: 1.1941 - acc: 0.5603\n",
            "Epoch 00036: val_loss improved from 1.57446 to 1.53185, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
            "3600/3600 [==============================] - 1s 288us/sample - loss: 1.1970 - acc: 0.5597 - val_loss: 1.5319 - val_acc: 0.4325\n",
            "Epoch 37/50\n",
            "3500/3600 [============================>.] - ETA: 0s - loss: 1.1710 - acc: 0.5774\n",
            "Epoch 00037: val_loss did not improve from 1.53185\n",
            "3600/3600 [==============================] - 1s 262us/sample - loss: 1.1683 - acc: 0.5792 - val_loss: 1.5469 - val_acc: 0.4200\n",
            "Epoch 38/50\n",
            "3400/3600 [===========================>..] - ETA: 0s - loss: 1.1272 - acc: 0.6059\n",
            "Epoch 00038: val_loss improved from 1.53185 to 1.48527, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
            "3600/3600 [==============================] - 1s 287us/sample - loss: 1.1299 - acc: 0.6050 - val_loss: 1.4853 - val_acc: 0.4425\n",
            "Epoch 39/50\n",
            "3400/3600 [===========================>..] - ETA: 0s - loss: 1.0996 - acc: 0.6029\n",
            "Epoch 00039: val_loss improved from 1.48527 to 1.44093, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
            "3600/3600 [==============================] - 1s 295us/sample - loss: 1.1009 - acc: 0.6042 - val_loss: 1.4409 - val_acc: 0.4725\n",
            "Epoch 40/50\n",
            "3400/3600 [===========================>..] - ETA: 0s - loss: 1.0853 - acc: 0.6112\n",
            "Epoch 00040: val_loss did not improve from 1.44093\n",
            "3600/3600 [==============================] - 1s 250us/sample - loss: 1.0864 - acc: 0.6114 - val_loss: 1.4531 - val_acc: 0.4658\n",
            "Epoch 41/50\n",
            "3400/3600 [===========================>..] - ETA: 0s - loss: 1.0731 - acc: 0.6147\n",
            "Epoch 00041: val_loss improved from 1.44093 to 1.37425, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
            "3600/3600 [==============================] - 1s 286us/sample - loss: 1.0737 - acc: 0.6133 - val_loss: 1.3743 - val_acc: 0.4992\n",
            "Epoch 42/50\n",
            "3300/3600 [==========================>...] - ETA: 0s - loss: 1.0207 - acc: 0.6321\n",
            "Epoch 00042: val_loss did not improve from 1.37425\n",
            "3600/3600 [==============================] - 1s 260us/sample - loss: 1.0284 - acc: 0.6333 - val_loss: 1.4149 - val_acc: 0.4675\n",
            "Epoch 43/50\n",
            "3400/3600 [===========================>..] - ETA: 0s - loss: 1.0155 - acc: 0.6344\n",
            "Epoch 00043: val_loss did not improve from 1.37425\n",
            "3600/3600 [==============================] - 1s 251us/sample - loss: 1.0188 - acc: 0.6344 - val_loss: 1.3865 - val_acc: 0.4967\n",
            "Epoch 44/50\n",
            "3400/3600 [===========================>..] - ETA: 0s - loss: 1.0013 - acc: 0.6456\n",
            "Epoch 00044: val_loss improved from 1.37425 to 1.30732, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
            "3600/3600 [==============================] - 1s 288us/sample - loss: 1.0085 - acc: 0.6447 - val_loss: 1.3073 - val_acc: 0.5092\n",
            "Epoch 45/50\n",
            "3500/3600 [============================>.] - ETA: 0s - loss: 1.0119 - acc: 0.6406\n",
            "Epoch 00045: val_loss did not improve from 1.30732\n",
            "3600/3600 [==============================] - 1s 266us/sample - loss: 1.0102 - acc: 0.6422 - val_loss: 1.3221 - val_acc: 0.5042\n",
            "Epoch 46/50\n",
            "3400/3600 [===========================>..] - ETA: 0s - loss: 0.9673 - acc: 0.6571\n",
            "Epoch 00046: val_loss improved from 1.30732 to 1.30113, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
            "3600/3600 [==============================] - 1s 286us/sample - loss: 0.9657 - acc: 0.6581 - val_loss: 1.3011 - val_acc: 0.5208\n",
            "Epoch 47/50\n",
            "3400/3600 [===========================>..] - ETA: 0s - loss: 0.9558 - acc: 0.6594\n",
            "Epoch 00047: val_loss improved from 1.30113 to 1.24907, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
            "3600/3600 [==============================] - 1s 292us/sample - loss: 0.9608 - acc: 0.6567 - val_loss: 1.2491 - val_acc: 0.5392\n",
            "Epoch 48/50\n",
            "3500/3600 [============================>.] - ETA: 0s - loss: 0.9152 - acc: 0.6820\n",
            "Epoch 00048: val_loss did not improve from 1.24907\n",
            "3600/3600 [==============================] - 1s 265us/sample - loss: 0.9153 - acc: 0.6822 - val_loss: 1.2642 - val_acc: 0.5283\n",
            "Epoch 49/50\n",
            "3400/3600 [===========================>..] - ETA: 0s - loss: 0.8993 - acc: 0.6865\n",
            "Epoch 00049: val_loss did not improve from 1.24907\n",
            "3600/3600 [==============================] - 1s 258us/sample - loss: 0.9028 - acc: 0.6844 - val_loss: 1.2849 - val_acc: 0.5442\n",
            "Epoch 50/50\n",
            "3500/3600 [============================>.] - ETA: 0s - loss: 0.8716 - acc: 0.6989\n",
            "Epoch 00050: val_loss improved from 1.24907 to 1.16292, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
            "3600/3600 [==============================] - 1s 304us/sample - loss: 0.8738 - acc: 0.6975 - val_loss: 1.1629 - val_acc: 0.5750\n",
            "1200/1200 [==============================] - 0s 166us/sample - loss: 1.1629 - acc: 0.5750\n",
            "[1.1629235045115154, 0.575]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VZRQXjwZlK_1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 862
        },
        "outputId": "231136e2-d681-4690-ce89-46b5be42da8c"
      },
      "source": [
        "# Иницијализација на променливите каде ќе бидат вчитани тест податоците\n",
        "test_data = []\n",
        "test_events = []\n",
        "test_runs_per_block = [[i for i in range(3)] for j in range(15)] # Covek, Sesija\n",
        "\n",
        "start_i = PARTICIPANT_START\n",
        "for participant in range(PARTICIPANT_START, PARTICIPANT_END): # Итерација низ секој испитен примерок\n",
        "  print(f\"====================== Примерок ({participant}) ======================\")\n",
        "  print(\"Вчитување тест податоци од испитниот примерок \" + str(participant) + \"...\")\n",
        "  \n",
        "  test_data, test_events = load_test_data(participant)\n",
        "  \n",
        "  for j in range(1, 4): # Итерација низ секоја сесија\n",
        "    file_test_set = 'S' + format(j, '02') + '/Test'\n",
        "\n",
        "    # Вчитување на бројот на runs \n",
        "    full_path = 'Data/' + file_name + \"/\" + file_test_set + \"/runs_per_block.txt\"\n",
        "    with open(full_path, \"r\") as runs_per_block:\n",
        "      test_runs_per_block[i-1][j-1] = int(runs_per_block.read())\n",
        "\n",
        "    print(\"\\t - Тест податоците од сесија \" + str(j) + \" се вчитани.\")\n",
        "  # Зачувај ги тест податоците вчитани од испитниот примерок во низа\n",
        "  print(\"Тест податоците од испитниот примерок \" + str(i) + \" се вчитани.\\n\")\n",
        "\n",
        "  array_i = i - start_i\n",
        "      \n",
        "  \n",
        "  # =========================================================================\n",
        "\n",
        "  print(\"SBJ\" + str(format(i, '02')) + \"| Test_data: \" + str(test_data[array_i].shape)) # test_data to predict\n",
        "  print(\"SBJ\" + str(format(i, '02')) + \"| Test_events: \" + str(len(test_events[array_i]))) # test_events\n",
        "  for j in range (1,4):\n",
        "    print(\"SBJ\" + str(format(i, '02')) + \" / S\" + str(format(j, '02')) + \"| Runs per block: \" + str(test_runs_per_block[i-1][j-1])) # runs per block in SJB01, SJ00 \n",
        "\n",
        "  to_predict_data = reshape_data_to_mne_format(test_data)\n",
        "  predictions = models[array_i].predict(to_predict_data)\n",
        "  print(\"SBJ\" + str(format(i, '02')) + \"| Predictions: \" + str(len(predictions)))\n",
        "  # np.savetxt(\"predictions.csv\", predictions, delimiter=\",\")\n",
        "\n",
        "\n",
        "  # ========= FALI USTE DA SE ISPARSIRA PREDICTIONOT... NE E SREDEN OVOJ KOD DOLE =======\n",
        "\n",
        "  int_pred = np.argmax(predictions, axis=1)\n",
        "  int_ytest = np.argmax(y_test, axis=1)\n",
        "\n",
        "  session_start = 0\n",
        "  start_prediction_index = 0\n",
        "  end_prediction_index = 0\n",
        "  for session in range(0, 3):\n",
        "    print(f\"============== Сесија ({session}) ==============\")\n",
        "    for block in range(0, 50):    \n",
        "      events_per_block = test_runs_per_block[i-1][session]\n",
        "\n",
        "      start_prediction_index = session_start + (block*events_per_block)*8\n",
        "      end_prediction_index = session_start + ((block+1)*events_per_block)*8\n",
        "\n",
        "      block_prediction = int_pred[start_prediction_index:end_prediction_index]\n",
        "      prediction = np.bincount(block_prediction).argmax()\n",
        "\n",
        "      # UNCOMMENT ZA PODOBAR PRIKAZ :)\n",
        "      # print(f\"Session {session} | Block: {block} | Prediction: {prediction} | Address: {end_prediction_index}\")\n",
        "\n",
        "      print(str(prediction) + \",\", end=\"\")\n",
        "    session_start = end_prediction_index\n",
        "    print(\"\")\n",
        "  print(\"Stigna li do kraj: \" + str(session_start == len(predictions)))\n",
        "  print(f\"====================== Примерок ({i}) ======================\\n\\n\")"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "====================== Примерок (5) ======================\n",
            "Вчитување тест податоци од испитниот примерок 5...\n",
            "Вчитување тест податоци од испитниот примерок (учесник) 5...\n",
            "Податоците од испитниот примерок (учесник) 5 се вчитани.\n",
            "\n",
            "\t - Тест податоците од сесија 1 се вчитани.\n",
            "\t - Тест податоците од сесија 2 се вчитани.\n",
            "\t - Тест податоците од сесија 3 се вчитани.\n",
            "Тест податоците од испитниот примерок 6 се вчитани.\n",
            "\n",
            "SBJ06| Test_data: (350, 8800)\n",
            "SBJ06| Test_events: 1\n",
            "SBJ06 / S01| Runs per block: 4\n",
            "SBJ06 / S02| Runs per block: 7\n",
            "SBJ06 / S03| Runs per block: 9\n",
            "SBJ06| Predictions: 8800\n",
            "============== Сесија (0) ==============\n",
            "4,4,0,0,4,0,3,5,3,0,4,0,4,4,4,3,0,3,5,2,3,2,3,5,3,3,0,0,0,3,4,0,0,0,0,0,0,0,0,0,0,0,0,0,3,0,0,0,2,0,\n",
            "============== Сесија (1) ==============\n",
            "0,4,0,0,0,0,0,3,0,0,0,0,0,2,0,0,4,0,2,2,3,0,2,3,0,0,0,4,4,2,0,0,2,2,0,0,0,2,0,0,0,0,0,0,0,0,0,0,0,0,\n",
            "============== Сесија (2) ==============\n",
            "0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,3,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,\n",
            "Stigna li do kraj: False\n",
            "====================== Примерок (6) ======================\n",
            "\n",
            "\n",
            "====================== Примерок (6) ======================\n",
            "Вчитување тест податоци од испитниот примерок 6...\n",
            "Вчитување тест податоци од испитниот примерок (учесник) 6...\n",
            "Податоците од испитниот примерок (учесник) 6 се вчитани.\n",
            "\n",
            "\t - Тест податоците од сесија 1 се вчитани.\n",
            "\t - Тест податоците од сесија 2 се вчитани.\n",
            "\t - Тест податоците од сесија 3 се вчитани.\n",
            "Тест податоците од испитниот примерок 6 се вчитани.\n",
            "\n",
            "SBJ06| Test_data: (350, 8000)\n",
            "SBJ06| Test_events: 1\n",
            "SBJ06 / S01| Runs per block: 4\n",
            "SBJ06 / S02| Runs per block: 7\n",
            "SBJ06 / S03| Runs per block: 9\n",
            "SBJ06| Predictions: 8000\n",
            "============== Сесија (0) ==============\n",
            "0,2,0,2,2,2,2,6,6,2,6,2,5,2,2,2,6,6,7,3,2,2,7,2,2,7,2,2,2,2,2,7,2,2,2,2,5,6,2,6,2,2,6,6,2,1,6,6,2,6,\n",
            "============== Сесија (1) ==============\n",
            "6,2,2,6,2,2,2,2,2,2,5,0,0,2,2,7,2,2,6,2,2,2,6,2,7,6,5,5,2,2,7,2,5,7,2,7,2,0,5,5,2,0,5,7,4,0,4,4,5,4,\n",
            "============== Сесија (2) ==============\n",
            "2,2,2,1,2,2,0,2,0,2,1,0,1,0,2,2,1,2,2,2,2,0,2,2,0,2,2,2,1,1,0,2,0,0,0,2,2,2,2,0,0,1,2,2,1,2,0,0,2,2,\n",
            "Stigna li do kraj: True\n",
            "====================== Примерок (6) ======================\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cfMZvSyt28g9",
        "colab_type": "text"
      },
      "source": [
        "## Визуелизација на податоците"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VTcvc3zf8Kib",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title Локација на сензорите\n",
        "#@markdown Може да се забележи дека каналите кои ги отчитуваме се наоѓаат во средниот и задниот дел на мозокот.\n",
        "montage = mne.channels.make_standard_montage(\"standard_alphabetic\")\n",
        "montage.plot();"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f5axzLaGPHFw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@title Histogram и зависности помеѓу 8те канали\n",
        "from scipy import io\n",
        "import matplotlib.pyplot as plt\n",
        "t = io.loadmat('drive/My Drive/Интелигентни Системи/Data/SBJ01/S01-Train/trainData.mat')['trainData'] \n",
        "t[0].shape\n",
        "\n",
        "fig, axs = plt.subplots(2)\n",
        "# plot histogram\n",
        "axs[0].hist(t[0][3])\n",
        "axs[1].plot(range(0,350), t[0][2][0:350])\n",
        "\n",
        "k = 0\n",
        "fig, axs = plt.subplots(8,8)\n",
        "for i in range(8):\n",
        "  for y in range(8):\n",
        "    axs[i,y].plot(t[i][0], t[y][0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CuJLBCQ5utVb",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title Визуелизација на EEG сигналите во рамки на еден настан (првиот настан).\n",
        "fig, axs = plt.subplots(8)\n",
        "swapped_matrix = np.swapaxes(data, 1, 2) # (канал, настан, епоха).\n",
        "\n",
        "for channel in range(0, 8):\n",
        "  axs[channel].set_title(ch_names[channel])\n",
        "  for epoch in range(0, 350):\n",
        "    y_arr = data[channel][epoch][0]\n",
        "    axs[channel].plot(range(0,350), swapped_matrix[channel][0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rMKdeZBKf2G3",
        "colab_type": "code",
        "cellView": "both",
        "colab": {}
      },
      "source": [
        "#@title Визуелизација на EEG сигналите во првата,средната и последната епоха.\n",
        "#@markdown 1. Визуелизација на EEG податоците по канали за првата, средната и последната епоха.\n",
        "#@markdown 2. Power Spectrum Density на 175-тата епоха. Во оваа епоха \n",
        "#@markdown сигналите би биле најстабилни за објектот кој светка.\n",
        "\n",
        "middle_epoch = mne_array[175]\n",
        "first_epoch = mne_array[0]\n",
        "last_epoch = mne_array[349]\n",
        "raw_middle = mne.io.RawArray(middle_epoch, mne_info)\n",
        "raw_first = mne.io.RawArray(first_epoch, mne_info)\n",
        "raw_last = mne.io.RawArray(last_epoch, mne_info)\n",
        "for epoch in range(0, 350): # Секоја епоха\n",
        "  i = 0\n",
        "  for event in range(0, 1600): # Настан\n",
        "    \n",
        "    np.array([1, 2, 3])\n",
        "    i = i+1\n",
        "\n",
        "\n",
        "\n",
        "print(\"\\n\")\n",
        "print(colored('====== 1 ======', 'red'))\n",
        "print(colored(\"Прва епоха од сите 1600 настани\", 'blue'))\n",
        "raw_first.plot(n_channels=8, scalings=dict(eeg=40), title='EEG Signals',\n",
        "         show=True, block=True, color = dict(eeg='blue'))\n",
        "print(colored(\"Средна епоха од сите 1600 настани\", 'blue'))\n",
        "raw_middle.plot(n_channels=8, scalings=dict(eeg=40), title='EEG Signals',\n",
        "         show=True, block=True, color = dict(eeg='blue'))\n",
        "print(colored(\"Последна епоха од сите 1600 настани\", 'blue'))\n",
        "raw_last.plot(n_channels=8, scalings=dict(eeg=40), title='EEG Signals',\n",
        "         show=True, block=True, color = dict(eeg='blue'))\n",
        "print(\"\\n\")\n",
        "print(colored('====== 2 ======', 'red'))\n",
        "raw_middle.plot_psd(area_mode='range', show=False, average=True);\n",
        "raw_data.plot_image();"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I4_WKbfszWbP",
        "colab_type": "code",
        "cellView": "both",
        "colab": {}
      },
      "source": [
        "#@title Визуелна споредба на EEG податоците при светкање на првиот и последниот објект  \n",
        "#@markdown Во првиот случај вршиме споредба на EEG податоците кога првиот и последниот \n",
        "#@markdown објект светнал без разлика дали бил target, додека во вториот случај ги споредуваме\n",
        "#@markdown EEG податоците за случаи само кога тие објекти биле target објекти.\n",
        "\n",
        "# Извлекување на настаните каде светнал првиот објект.\n",
        "first_object_events = [index for index, value in enumerate(events_arr) if value == '1']\n",
        "first_object_eeg_data = np.zeros((8,350, len(first_object_events)))\n",
        "for channel in range(0, 8): # Секој канал\n",
        "  for epoch in range(0, 350): # Секоја епоха\n",
        "    i = 0\n",
        "    for event in first_object_events: # Настан\n",
        "      first_object_eeg_data[channel][epoch][i] = data[channel][epoch][event]\n",
        "      i = i+1\n",
        "\n",
        "# Креирање на соодветна дводимензионална низа за mne библиотеката\n",
        "mne_first_obj_array = np.swapaxes(first_object_eeg_data, 0, 1) # (епохa, канал, настан).\n",
        "epoch = mne_first_obj_array[175] \n",
        "first_object_raw = mne.io.RawArray(epoch, mne_info)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Извлекување на настаните каде светнал првиот објект и бил target.\n",
        "first_object_events_target = [index for index, value in enumerate(events_arr) if value == '1']\n",
        "for event_pos in first_object_events_target:\n",
        "  if targets_arr[event_pos] == 1:\n",
        "    continue # Продолжи\n",
        "  else:\n",
        "    first_object_events_target.remove(event_pos) # Избриши -> Објектот не е target\n",
        "first_object_target_eeg_data = np.zeros((8,350, len(first_object_events_target)))\n",
        "for channel in range(0, 8): # Секој канал\n",
        "  for epoch in range(0, 350): # Секоја епоха\n",
        "    i = 0\n",
        "    for event in first_object_events_target: # Настан\n",
        "      first_object_target_eeg_data[channel][epoch][i] = data[channel][epoch][event]\n",
        "      i = i+1\n",
        "\n",
        "# Креирање на соодветна дводимензионална низа за mne библиотеката\n",
        "mne_first_obj_target_array = np.swapaxes(first_object_target_eeg_data, 0, 1) # (епохa, канал, настан).\n",
        "epoch = mne_first_obj_target_array[175] \n",
        "first_object_target_raw = mne.io.RawArray(epoch, mne_info)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Извлекување на настаните каде светнал последниот објект.\n",
        "last_object_events = [index for index, value in enumerate(events_arr) if value == '8']\n",
        "last_object_eeg_data = np.zeros((8,350, len(last_object_events)))\n",
        "for channel in range(0, 8): # Секој канал\n",
        "  for epoch in range(0, 350): # Секоја епоха\n",
        "    i = 0\n",
        "    for event in last_object_events: # Настан\n",
        "      last_object_eeg_data[channel][epoch][i] = data[channel][epoch][event]\n",
        "      i = i+1\n",
        "\n",
        "# Креирање на соодветна дводимензионална низа за mne библиотеката\n",
        "mne_last_obj_array = np.swapaxes(last_object_eeg_data, 0, 1) # (епохa, канал, настан).\n",
        "epoch = mne_last_obj_array[175] \n",
        "last_object_raw = mne.io.RawArray(epoch, mne_info)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Извлекување на настаните каде светнал последниот објект и бил target.\n",
        "last_object_events_target = [index for index, value in enumerate(events_arr) if value == '8']\n",
        "for event_pos in last_object_events_target:\n",
        "  if targets_arr[event_pos] == 1:\n",
        "    continue # Продолжи\n",
        "  else:\n",
        "    last_object_events_target.remove(event_pos) # Избриши -> Објектот не е target\n",
        "last_object_target_eeg_data = np.zeros((8,350, len(last_object_events_target)))\n",
        "for channel in range(0, 8): # Секој канал\n",
        "  for epoch in range(0, 350): # Секоја епоха\n",
        "    i = 0\n",
        "    for event in last_object_events_target: # Настан\n",
        "      last_object_target_eeg_data[channel][epoch][i] = data[channel][epoch][event]\n",
        "      i = i+1\n",
        "      \n",
        "# Креирање на соодветна дводимензионална низа за mne библиотеката\n",
        "mne_last_obj_target_array = np.swapaxes(last_object_target_eeg_data, 0, 1) # (епохa, канал, настан).\n",
        "epoch = mne_last_obj_target_array[175] \n",
        "last_object_target_raw = mne.io.RawArray(epoch, mne_info)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Исцртување и печатење\n",
        "print(\"\\n\\n\")\n",
        "print(colored('====== ПРВ ОБЈЕКТ - Книги на полица ======', 'red'))\n",
        "print(colored(\"Вкупно светнал: \" + str(len(first_object_events)), 'blue'))\n",
        "print(colored(\"Вкупно светнал и бил target: \" + str(len(first_object_events_target)), 'blue'))\n",
        "print(\"\\n\")\n",
        "print(colored('====== ПОСЛЕДЕН ОБЈЕКТ - Слика закачена на ѕид ======', 'red'))\n",
        "print(colored(\"Вкупно светнал: \" + str(len(last_object_events)), 'blue'))\n",
        "print(colored(\"Вкупно светнал и бил target: \" + str(len(last_object_events_target)), 'blue'))\n",
        "print(\"\\n\")\n",
        "print(colored('====== Графици со EEG податоци кога светнале првиот и последниот објект  ======', 'green'))\n",
        "first_object_raw.plot(n_channels=8, scalings=dict(eeg=40), title='EEG Signals',\n",
        "         show=True, block=True, color = dict(eeg='blue'));\n",
        "last_object_raw.plot(n_channels=8, scalings=dict(eeg=40), title='EEG Signals',\n",
        "         show=True, block=True, color = dict(eeg='blue'));\n",
        "print(\"\\n\")\n",
        "print(colored('====== Графици со EEG податоци кога светнале првиот и последниот објект и биле target  ======', 'green'))\n",
        "first_object_raw.plot(n_channels=8, scalings=dict(eeg=40), title='EEG Signals',\n",
        "         show=True, block=True, color = dict(eeg='blue'));\n",
        "last_object_raw.plot(n_channels=8, scalings=dict(eeg=40), title='EEG Signals',\n",
        "         show=True, block=True, color = dict(eeg='blue'));"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1zC35biqMbTp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DHYR7GIeNruZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from mne.preprocessing import ICA\n",
        "raw.plot_psd(tmin=0.2, tmax=1.2, fmin=0, fmax=60, average=True, spatial_colors=False);\n",
        "num_components = 8\n",
        "ica = ICA(n_components=num_components, method='fastica')\n",
        "ica.fit(raw)\n",
        "ica.plot_sources(raw);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5-i6hg3BxtcW",
        "colab_type": "text"
      },
      "source": [
        "## Претпроцесирање"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0E9R0I2Yx39Z",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title TO-DO\n",
        "# TO-DO"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MAZF5d2ltrUp",
        "colab_type": "code",
        "cellView": "both",
        "colab": {}
      },
      "source": [
        "#@title Стандардизација на податоците\n",
        "\n",
        "standardizer = mne.decoding.Scaler(scalings='mean')\n",
        "standardizer.fit(mne_array)\n",
        "standardized_data = standardizer.transform(mne_array)\n",
        "print(\"Просекот е:\",-round(standardized_data.mean()))\n",
        "print(\"Варијансата е:\",round(standardized_data.var()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lNN3G9EuNozP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@title Нормализација метод бр. 2\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "from scipy.io import loadmat\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
        "def min_max_scale(dataset: np.ndarray) -> np.ndarray:\n",
        "    scaler = MinMaxScaler(feature_range=[0, 1])\n",
        "    scaled_data = scaler.fit_transform(dataset)\n",
        "    return scaled_data\n",
        "\n",
        "def standard_scale(dataset: np.ndarray) -> np.ndarray:\n",
        "    scaler = StandardScaler()\n",
        "    scaled_data = scaler.fit_transform(dataset)\n",
        "    return scaled_data\n",
        "\n",
        "data = loadmat('drive/My Drive/Интелигентни Системи/Data/SBJ01/S01-Train/trainData.mat')['trainData'] \n",
        "\n",
        "v_min = data.min(axis=(0, 1), keepdims=True)\n",
        "v_max = data.max(axis=(0, 1), keepdims=True)\n",
        "print(\"Нормализирани податоци:\")\n",
        "(data - v_min)/(v_max - v_min)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "97RpFhn51lwT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@title Отстранување на шум - претстава\n",
        "\n",
        "Min, Max = round(mne_array.min()),round(mne_array.max())*1000000\n",
        "picks = mne.pick_types(raw_data.info, meg=False, eeg=True, stim=False, eog=False)\n",
        "mne.viz.plot_epochs_image(raw_data, picks='eeg', vmin= Min, vmax=Max)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jXNjfoUeMyzK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vFPhowa1M6YW",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vMlIYsd8EguD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@title Отстранување на шум - реултати\n",
        "xd = mne.preprocessing.Xdawn(n_components=2, signal_cov=None)\n",
        "xd.fit(raw_data)\n",
        "epochs_denoised = xd.apply(raw_data)\n",
        "epochs_denoised.keys()\n",
        "mne.viz.plot_epochs_image(epochs_denoised['1'], picks='eeg', vmin=Min, vmax=Max)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sfTW-yXXbtfC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@title Downsampling\n",
        "events = raw_data.events\n",
        "epochs = mne.Epochs(raw, events, tmin=-0.1, tmax=1, preload=True)\n",
        "print(epochs)\n",
        "# Downsample to 175 Hz\n",
        "print('Original sampling rate:', epochs.info['sfreq'], 'Hz')\n",
        "epochs_resampled = epochs.copy().resample(175, npad='auto')\n",
        "print('New sampling rate:', epochs_resampled.info['sfreq'], 'Hz')\n",
        "\n",
        "# Plot a piece of data to see the effects of downsampling\n",
        "plt.figure(figsize=(7, 3))\n",
        "\n",
        "n_samples_to_plot = int(0.5 * epochs.info['sfreq'])  # plot 0.5 seconds of data\n",
        "plt.plot(epochs.times[:n_samples_to_plot],\n",
        "         epochs.get_data()[ 0, 0, :n_samples_to_plot], color='black')\n",
        "\n",
        "n_samples_to_plot = int(0.5 * epochs_resampled.info['sfreq'])\n",
        "plt.plot(epochs_resampled.times[:n_samples_to_plot],\n",
        "         epochs_resampled.get_data()[ 0, 0, :n_samples_to_plot],\n",
        "         '-o', color='red')\n",
        "\n",
        "plt.xlabel('time (s)')\n",
        "plt.legend(['original', 'downsampled'], loc='best')\n",
        "plt.title('Effect of downsampling')\n",
        "mne.viz.tight_layout()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HAudEh07MUzy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@title Principal Component Analysis\n",
        "pca = mne.decoding.UnsupervisedSpatialFilter(PCA(8), average=False)\n",
        "pca_data = pca.fit_transform(mne_array)\n",
        "ev = mne.EvokedArray(np.mean(pca_data, axis=0),\n",
        "                     mne.create_info(8, raw_data.info['sfreq'],\n",
        "                                     ch_types='eeg'), tmin=Min)\n",
        "ev.plot(show=False, window_title=\"PCA\", time_unit='ms')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}