{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Faza4.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dpostolovski/eeg_is/blob/train_compare_full_data/Phase%204%20-%20Final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2UDle2I8OMUa",
        "colab_type": "code",
        "outputId": "e67a3a62-ee05-413c-a34b-b3842e232af3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7qm05RkaOpZW",
        "colab_type": "code",
        "outputId": "b19a32e5-aadd-459c-a2b7-ddfa7c8f06a4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        }
      },
      "source": [
        "#@title Инсталирање и вчитување на потребните библиотеки\n",
        "!pip install mne \n",
        "!pip install termcolor\n",
        "!wget \"https://raw.githubusercontent.com/vlawhern/arl-eegmodels/master/EEGModels.py\"\n",
        "\n",
        "%tensorflow_version 1.12.0\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import mne\n",
        "\n",
        "from sklearn import metrics \n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint \n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras import backend as K\n",
        "\n",
        "from scipy.io import loadmat\n",
        "from collections import Counter\n",
        "\n",
        "K.set_image_data_format('channels_first')\n",
        "\n",
        "import sys\n",
        "sys.path.append('drive/My Drive/Интелигентни Системи')\n",
        "from EEGModels import DeepConvNet, EEGNet\n",
        "\n",
        "!mkdir saved_models"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: mne in /usr/local/lib/python3.6/dist-packages (0.20.6)\n",
            "Requirement already satisfied: scipy>=0.17.1 in /usr/local/lib/python3.6/dist-packages (from mne) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.6/dist-packages (from mne) (1.18.5)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.6/dist-packages (1.1.0)\n",
            "--2020-06-14 20:58:47--  https://raw.githubusercontent.com/vlawhern/arl-eegmodels/master/EEGModels.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 18283 (18K) [text/plain]\n",
            "Saving to: ‘EEGModels.py.1’\n",
            "\n",
            "EEGModels.py.1      100%[===================>]  17.85K  --.-KB/s    in 0.01s   \n",
            "\n",
            "2020-06-14 20:58:47 (1.39 MB/s) - ‘EEGModels.py.1’ saved [18283/18283]\n",
            "\n",
            "`%tensorflow_version` only switches the major version: 1.x or 2.x.\n",
            "You set: `1.12.0`. This will be interpreted as: `1.x`.\n",
            "\n",
            "\n",
            "TensorFlow is already loaded. Please restart the runtime to change versions.\n",
            "mkdir: cannot create directory ‘saved_models’: File exists\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y2CpCSd15Hvv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def reshape(data, labels, events, targets):\n",
        "  mne_array = np.swapaxes(data, 0, 2) # (епохa, канал, настан). \n",
        "  mne_array = np.swapaxes(mne_array, 1, 2) # (епохa, канал, настан). \n",
        "  mne_array = mne_array.reshape(mne_array.shape[0], 1, 8, 350)\n",
        "\n",
        "  labels_arr = labels.astype(np.int)\n",
        "  events_arr = events.astype(np.int)\n",
        "  return mne_array, labels_arr-1, events_arr-1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0wIxcjNywN0a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def reshape_data_to_mne_format(data):\n",
        "  mne_array = np.swapaxes(data, 0, 2) # (епохa, канал, настан). \n",
        "  mne_array = np.swapaxes(mne_array, 1, 2) # (епохa, канал, настан). \n",
        "  mne_array = mne_array.reshape(mne_array.shape[0], 1, 8, 350)\n",
        "\n",
        "  return mne_array"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tU0YDj0OO4jD",
        "colab_type": "code",
        "outputId": "ee494f1a-7b7b-4f75-cf43-40693e68bad1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Иницијализација на променливите каде ќе бидат вчитани податоците\n",
        "train_data = []\n",
        "train_labels = []\n",
        "train_events = []\n",
        "train_targets = []\n",
        "models = []\n",
        "\n",
        "start_i = 3\n",
        "for i in range(3, 4): # Итерација низ секој испитен примерок\n",
        "  print(\"Вчитување тест податоци од испитниот примерок \" + str(i) + \"...\")\n",
        "\n",
        "  file_name = 'SBJ' + format(i, '02')\n",
        "  \n",
        "  # Иницијализација на помошни променливи\n",
        "  temp_train_data = np.empty(0)\n",
        "  temp_train_labels = np.empty(0)\n",
        "  temp_train_events = np.empty(0)\n",
        "  temp_train_targets = np.empty(0)\n",
        "\n",
        "  for j in range(1, 4): # Итерација низ секоја сесија\n",
        "    file_train_set = 'S' + format(j, '02') + '/Train'\n",
        "\n",
        "    # Вчитување на податоците\n",
        "    full_path = 'drive/My Drive/Интелигентни Системи/Data/' + file_name + \"/\" + file_train_set + \"/trainData.mat\"\n",
        "    temp = loadmat(full_path)['trainData']\n",
        "    if temp_train_data.size != 0:\n",
        "      temp_train_data = np.concatenate((temp_train_data, temp), axis=2)\n",
        "    else: \n",
        "      temp_train_data = np.array(temp)\n",
        "\n",
        "    # Вчитување на label-ите\n",
        "    full_path = 'drive/My Drive/Интелигентни Системи/Data/' + file_name + \"/\" + file_train_set + \"/trainLabels.txt\"\n",
        "    with open(full_path, \"r\") as file_labels:\n",
        "      temp = file_labels.read().splitlines()\n",
        "      temp = np.repeat(temp, 8*10)\n",
        "      if temp_train_labels.size != 0:\n",
        "        temp_train_labels = np.concatenate((temp_train_labels, temp))\n",
        "      else:\n",
        "        temp_train_labels = np.array(temp)\n",
        "\n",
        "    # Вчитување на редоследот на светкање\n",
        "    full_path = 'drive/My Drive/Интелигентни Системи/Data/' + file_name + \"/\" + file_train_set + \"/trainEvents.txt\"\n",
        "    with open(full_path, \"r\") as file_events:\n",
        "      temp = file_events.read().splitlines()\n",
        "      if temp_train_events.size != 0:\n",
        "        temp_train_events = np.append(temp_train_events, temp)\n",
        "      else:\n",
        "        temp_train_events = np.array(temp)\n",
        "      \n",
        "\n",
        "    # Вчитување на редоследот на објекти кои се target\n",
        "    full_path = 'drive/My Drive/Интелигентни Системи/Data/' + file_name + \"/\" + file_train_set + \"/trainTargets.txt\"\n",
        "    with open(full_path, \"r\") as file_targets:\n",
        "      temp = file_targets.read().splitlines()\n",
        "      if temp_train_targets.size != 0:\n",
        "        temp_train_targets = np.concatenate((temp_train_targets, temp))\n",
        "      else:\n",
        "        temp_train_targets = np.array(temp)\n",
        "\n",
        "    print(\"\\t - Податоците од сесија \" + str(j) + \" се вчитани.\")\n",
        "  # Зачувај ги податоците вчитани од испитниот примерок во низа\n",
        "  train_data.append(temp_train_data)\n",
        "  train_labels.append(temp_train_labels)\n",
        "  train_events.append(temp_train_events)\n",
        "  train_targets.append(temp_train_targets)\n",
        "  print(\"Податоците од испитниот примерок \" + str(i) + \" се вчитани.\\n\")\n",
        "\n",
        "  array_i = i - start_i\n",
        "      \n",
        "\n",
        "  data, labels, events = reshape(train_data[array_i], train_labels[array_i], train_events[array_i], train_targets[array_i])\n",
        "  X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.25, random_state=42)\n",
        "\n",
        "  model = DeepConvNet(nb_classes = 8, Chans = 8, Samples = 350)\n",
        "  model.compile(loss = 'categorical_crossentropy', metrics=['accuracy'],optimizer = Adam(0.0009))\n",
        "  checkpointer = ModelCheckpoint(filepath='saved_models/weights.best.basic_mlp.hdf5', \n",
        "                                verbose=1, save_best_only=True)\n",
        "\n",
        "\n",
        "  y_train = to_categorical(y_train)\n",
        "  y_test = to_categorical(y_test)\n",
        "\n",
        "  num_batch_size=100\n",
        "  num_epochs=200\n",
        "  model.fit(X_train, y_train, batch_size=num_batch_size, epochs=num_epochs, \\\n",
        "            validation_data=(X_test, y_test),callbacks=[checkpointer], verbose=1)\n",
        "\n",
        "  score = model.evaluate(X_test, y_test, verbose=1)\n",
        "  print(score)\n",
        "\n",
        "  models.append(model) # Ke imame 15 modeli neli, pa vo niza se staveni\n",
        "                       # pristap do niv model[i]"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Вчитување тест податоци од испитниот примерок 3...\n",
            "\t - Податоците од сесија 1 се вчитани.\n",
            "\t - Податоците од сесија 2 се вчитани.\n",
            "\t - Податоците од сесија 3 се вчитани.\n",
            "Податоците од испитниот примерок 3 се вчитани.\n",
            "\n",
            "Train on 3600 samples, validate on 1200 samples\n",
            "Epoch 1/200\n",
            "3200/3600 [=========================>....] - ETA: 0s - loss: 2.2834 - acc: 0.1603\n",
            "Epoch 00001: val_loss improved from inf to 2.62156, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
            "3600/3600 [==============================] - 2s 487us/sample - loss: 2.2767 - acc: 0.1633 - val_loss: 2.6216 - val_acc: 0.1117\n",
            "Epoch 2/200\n",
            "3400/3600 [===========================>..] - ETA: 0s - loss: 2.1321 - acc: 0.2065\n",
            "Epoch 00002: val_loss improved from 2.62156 to 2.54600, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
            "3600/3600 [==============================] - 1s 198us/sample - loss: 2.1310 - acc: 0.2050 - val_loss: 2.5460 - val_acc: 0.1175\n",
            "Epoch 3/200\n",
            "3200/3600 [=========================>....] - ETA: 0s - loss: 2.0532 - acc: 0.2222\n",
            "Epoch 00003: val_loss did not improve from 2.54600\n",
            "3600/3600 [==============================] - 1s 172us/sample - loss: 2.0518 - acc: 0.2219 - val_loss: 2.8394 - val_acc: 0.1133\n",
            "Epoch 4/200\n",
            "3300/3600 [==========================>...] - ETA: 0s - loss: 2.0156 - acc: 0.2342\n",
            "Epoch 00004: val_loss did not improve from 2.54600\n",
            "3600/3600 [==============================] - 1s 165us/sample - loss: 2.0195 - acc: 0.2333 - val_loss: 2.9759 - val_acc: 0.1175\n",
            "Epoch 5/200\n",
            "3500/3600 [============================>.] - ETA: 0s - loss: 1.9826 - acc: 0.2469\n",
            "Epoch 00005: val_loss improved from 2.54600 to 2.24902, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
            "3600/3600 [==============================] - 1s 196us/sample - loss: 1.9830 - acc: 0.2461 - val_loss: 2.2490 - val_acc: 0.1608\n",
            "Epoch 6/200\n",
            "3300/3600 [==========================>...] - ETA: 0s - loss: 1.9761 - acc: 0.2548\n",
            "Epoch 00006: val_loss did not improve from 2.24902\n",
            "3600/3600 [==============================] - 1s 170us/sample - loss: 1.9731 - acc: 0.2531 - val_loss: 2.2546 - val_acc: 0.1850\n",
            "Epoch 7/200\n",
            "3500/3600 [============================>.] - ETA: 0s - loss: 1.9462 - acc: 0.2674\n",
            "Epoch 00007: val_loss improved from 2.24902 to 2.06114, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
            "3600/3600 [==============================] - 1s 191us/sample - loss: 1.9476 - acc: 0.2667 - val_loss: 2.0611 - val_acc: 0.2133\n",
            "Epoch 8/200\n",
            "3400/3600 [===========================>..] - ETA: 0s - loss: 1.9220 - acc: 0.2721\n",
            "Epoch 00008: val_loss did not improve from 2.06114\n",
            "3600/3600 [==============================] - 1s 175us/sample - loss: 1.9202 - acc: 0.2717 - val_loss: 2.6200 - val_acc: 0.1742\n",
            "Epoch 9/200\n",
            "3100/3600 [========================>.....] - ETA: 0s - loss: 1.9301 - acc: 0.2635\n",
            "Epoch 00009: val_loss did not improve from 2.06114\n",
            "3600/3600 [==============================] - 1s 173us/sample - loss: 1.9293 - acc: 0.2658 - val_loss: 2.3358 - val_acc: 0.1575\n",
            "Epoch 10/200\n",
            "3200/3600 [=========================>....] - ETA: 0s - loss: 1.8829 - acc: 0.2837\n",
            "Epoch 00010: val_loss did not improve from 2.06114\n",
            "3600/3600 [==============================] - 1s 172us/sample - loss: 1.8840 - acc: 0.2831 - val_loss: 2.2425 - val_acc: 0.1850\n",
            "Epoch 11/200\n",
            "3300/3600 [==========================>...] - ETA: 0s - loss: 1.8633 - acc: 0.2918\n",
            "Epoch 00011: val_loss did not improve from 2.06114\n",
            "3600/3600 [==============================] - 1s 162us/sample - loss: 1.8655 - acc: 0.2903 - val_loss: 2.2389 - val_acc: 0.1933\n",
            "Epoch 12/200\n",
            "3300/3600 [==========================>...] - ETA: 0s - loss: 1.8599 - acc: 0.2970\n",
            "Epoch 00012: val_loss did not improve from 2.06114\n",
            "3600/3600 [==============================] - 1s 164us/sample - loss: 1.8609 - acc: 0.2933 - val_loss: 2.2040 - val_acc: 0.2408\n",
            "Epoch 13/200\n",
            "3200/3600 [=========================>....] - ETA: 0s - loss: 1.8295 - acc: 0.3044\n",
            "Epoch 00013: val_loss did not improve from 2.06114\n",
            "3600/3600 [==============================] - 1s 168us/sample - loss: 1.8343 - acc: 0.3042 - val_loss: 2.3210 - val_acc: 0.1933\n",
            "Epoch 14/200\n",
            "3500/3600 [============================>.] - ETA: 0s - loss: 1.8096 - acc: 0.3097\n",
            "Epoch 00014: val_loss did not improve from 2.06114\n",
            "3600/3600 [==============================] - 1s 170us/sample - loss: 1.8139 - acc: 0.3067 - val_loss: 2.1792 - val_acc: 0.2025\n",
            "Epoch 15/200\n",
            "3400/3600 [===========================>..] - ETA: 0s - loss: 1.7899 - acc: 0.3265\n",
            "Epoch 00015: val_loss improved from 2.06114 to 2.03819, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
            "3600/3600 [==============================] - 1s 183us/sample - loss: 1.7847 - acc: 0.3278 - val_loss: 2.0382 - val_acc: 0.2525\n",
            "Epoch 16/200\n",
            "3500/3600 [============================>.] - ETA: 0s - loss: 1.7446 - acc: 0.3366\n",
            "Epoch 00016: val_loss improved from 2.03819 to 1.94307, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
            "3600/3600 [==============================] - 1s 190us/sample - loss: 1.7462 - acc: 0.3353 - val_loss: 1.9431 - val_acc: 0.2683\n",
            "Epoch 17/200\n",
            "3300/3600 [==========================>...] - ETA: 0s - loss: 1.7372 - acc: 0.3439\n",
            "Epoch 00017: val_loss did not improve from 1.94307\n",
            "3600/3600 [==============================] - 1s 165us/sample - loss: 1.7369 - acc: 0.3422 - val_loss: 2.0858 - val_acc: 0.2300\n",
            "Epoch 18/200\n",
            "3500/3600 [============================>.] - ETA: 0s - loss: 1.7294 - acc: 0.3366\n",
            "Epoch 00018: val_loss improved from 1.94307 to 1.93383, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
            "3600/3600 [==============================] - 1s 190us/sample - loss: 1.7336 - acc: 0.3350 - val_loss: 1.9338 - val_acc: 0.2642\n",
            "Epoch 19/200\n",
            "3300/3600 [==========================>...] - ETA: 0s - loss: 1.7169 - acc: 0.3503\n",
            "Epoch 00019: val_loss did not improve from 1.93383\n",
            "3600/3600 [==============================] - 1s 169us/sample - loss: 1.7165 - acc: 0.3522 - val_loss: 1.9908 - val_acc: 0.2442\n",
            "Epoch 20/200\n",
            "3400/3600 [===========================>..] - ETA: 0s - loss: 1.6896 - acc: 0.3682\n",
            "Epoch 00020: val_loss improved from 1.93383 to 1.83856, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
            "3600/3600 [==============================] - 1s 192us/sample - loss: 1.6946 - acc: 0.3667 - val_loss: 1.8386 - val_acc: 0.2967\n",
            "Epoch 21/200\n",
            "3500/3600 [============================>.] - ETA: 0s - loss: 1.6739 - acc: 0.3640\n",
            "Epoch 00021: val_loss did not improve from 1.83856\n",
            "3600/3600 [==============================] - 1s 176us/sample - loss: 1.6722 - acc: 0.3650 - val_loss: 1.9532 - val_acc: 0.2683\n",
            "Epoch 22/200\n",
            "3400/3600 [===========================>..] - ETA: 0s - loss: 1.6719 - acc: 0.3679\n",
            "Epoch 00022: val_loss improved from 1.83856 to 1.83677, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
            "3600/3600 [==============================] - 1s 191us/sample - loss: 1.6752 - acc: 0.3672 - val_loss: 1.8368 - val_acc: 0.2917\n",
            "Epoch 23/200\n",
            "3400/3600 [===========================>..] - ETA: 0s - loss: 1.6430 - acc: 0.3759\n",
            "Epoch 00023: val_loss did not improve from 1.83677\n",
            "3600/3600 [==============================] - 1s 168us/sample - loss: 1.6435 - acc: 0.3753 - val_loss: 2.0312 - val_acc: 0.2600\n",
            "Epoch 24/200\n",
            "3300/3600 [==========================>...] - ETA: 0s - loss: 1.6280 - acc: 0.3694\n",
            "Epoch 00024: val_loss did not improve from 1.83677\n",
            "3600/3600 [==============================] - 1s 183us/sample - loss: 1.6343 - acc: 0.3686 - val_loss: 2.0544 - val_acc: 0.2475\n",
            "Epoch 25/200\n",
            "3300/3600 [==========================>...] - ETA: 0s - loss: 1.6212 - acc: 0.3821\n",
            "Epoch 00025: val_loss did not improve from 1.83677\n",
            "3600/3600 [==============================] - 1s 166us/sample - loss: 1.6172 - acc: 0.3847 - val_loss: 1.8374 - val_acc: 0.2867\n",
            "Epoch 26/200\n",
            "3300/3600 [==========================>...] - ETA: 0s - loss: 1.6094 - acc: 0.3918\n",
            "Epoch 00026: val_loss improved from 1.83677 to 1.83509, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
            "3600/3600 [==============================] - 1s 193us/sample - loss: 1.6107 - acc: 0.3908 - val_loss: 1.8351 - val_acc: 0.2942\n",
            "Epoch 27/200\n",
            "3300/3600 [==========================>...] - ETA: 0s - loss: 1.5670 - acc: 0.4042\n",
            "Epoch 00027: val_loss improved from 1.83509 to 1.73730, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
            "3600/3600 [==============================] - 1s 186us/sample - loss: 1.5737 - acc: 0.4011 - val_loss: 1.7373 - val_acc: 0.3200\n",
            "Epoch 28/200\n",
            "3400/3600 [===========================>..] - ETA: 0s - loss: 1.5838 - acc: 0.3965\n",
            "Epoch 00028: val_loss did not improve from 1.73730\n",
            "3600/3600 [==============================] - 1s 184us/sample - loss: 1.5865 - acc: 0.3953 - val_loss: 1.9399 - val_acc: 0.2742\n",
            "Epoch 29/200\n",
            "3500/3600 [============================>.] - ETA: 0s - loss: 1.5668 - acc: 0.3951\n",
            "Epoch 00029: val_loss did not improve from 1.73730\n",
            "3600/3600 [==============================] - 1s 175us/sample - loss: 1.5671 - acc: 0.3944 - val_loss: 1.8036 - val_acc: 0.3142\n",
            "Epoch 30/200\n",
            "3400/3600 [===========================>..] - ETA: 0s - loss: 1.5540 - acc: 0.4153\n",
            "Epoch 00030: val_loss improved from 1.73730 to 1.71734, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
            "3600/3600 [==============================] - 1s 185us/sample - loss: 1.5522 - acc: 0.4147 - val_loss: 1.7173 - val_acc: 0.3308\n",
            "Epoch 31/200\n",
            "3400/3600 [===========================>..] - ETA: 0s - loss: 1.5290 - acc: 0.4229\n",
            "Epoch 00031: val_loss did not improve from 1.71734\n",
            "3600/3600 [==============================] - 1s 181us/sample - loss: 1.5375 - acc: 0.4183 - val_loss: 1.8337 - val_acc: 0.2942\n",
            "Epoch 32/200\n",
            "3400/3600 [===========================>..] - ETA: 0s - loss: 1.5313 - acc: 0.4259\n",
            "Epoch 00032: val_loss did not improve from 1.71734\n",
            "3600/3600 [==============================] - 1s 177us/sample - loss: 1.5306 - acc: 0.4269 - val_loss: 1.7385 - val_acc: 0.3150\n",
            "Epoch 33/200\n",
            "3300/3600 [==========================>...] - ETA: 0s - loss: 1.5135 - acc: 0.4191\n",
            "Epoch 00033: val_loss did not improve from 1.71734\n",
            "3600/3600 [==============================] - 1s 168us/sample - loss: 1.5132 - acc: 0.4200 - val_loss: 1.7908 - val_acc: 0.3100\n",
            "Epoch 34/200\n",
            "3500/3600 [============================>.] - ETA: 0s - loss: 1.5051 - acc: 0.4320\n",
            "Epoch 00034: val_loss did not improve from 1.71734\n",
            "3600/3600 [==============================] - 1s 172us/sample - loss: 1.5045 - acc: 0.4333 - val_loss: 1.7678 - val_acc: 0.3058\n",
            "Epoch 35/200\n",
            "3300/3600 [==========================>...] - ETA: 0s - loss: 1.4919 - acc: 0.4233\n",
            "Epoch 00035: val_loss did not improve from 1.71734\n",
            "3600/3600 [==============================] - 1s 172us/sample - loss: 1.4856 - acc: 0.4239 - val_loss: 1.7971 - val_acc: 0.3133\n",
            "Epoch 36/200\n",
            "3300/3600 [==========================>...] - ETA: 0s - loss: 1.4766 - acc: 0.4418\n",
            "Epoch 00036: val_loss improved from 1.71734 to 1.65572, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
            "3600/3600 [==============================] - 1s 193us/sample - loss: 1.4813 - acc: 0.4403 - val_loss: 1.6557 - val_acc: 0.3667\n",
            "Epoch 37/200\n",
            "3300/3600 [==========================>...] - ETA: 0s - loss: 1.4583 - acc: 0.4500\n",
            "Epoch 00037: val_loss did not improve from 1.65572\n",
            "3600/3600 [==============================] - 1s 166us/sample - loss: 1.4634 - acc: 0.4469 - val_loss: 1.6791 - val_acc: 0.3383\n",
            "Epoch 38/200\n",
            "3500/3600 [============================>.] - ETA: 0s - loss: 1.4560 - acc: 0.4463\n",
            "Epoch 00038: val_loss did not improve from 1.65572\n",
            "3600/3600 [==============================] - 1s 171us/sample - loss: 1.4588 - acc: 0.4447 - val_loss: 1.7677 - val_acc: 0.3200\n",
            "Epoch 39/200\n",
            "3500/3600 [============================>.] - ETA: 0s - loss: 1.4525 - acc: 0.4520\n",
            "Epoch 00039: val_loss improved from 1.65572 to 1.62938, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
            "3600/3600 [==============================] - 1s 206us/sample - loss: 1.4498 - acc: 0.4528 - val_loss: 1.6294 - val_acc: 0.3692\n",
            "Epoch 40/200\n",
            "3500/3600 [============================>.] - ETA: 0s - loss: 1.4411 - acc: 0.4486\n",
            "Epoch 00040: val_loss did not improve from 1.62938\n",
            "3600/3600 [==============================] - 1s 175us/sample - loss: 1.4395 - acc: 0.4486 - val_loss: 1.7479 - val_acc: 0.3233\n",
            "Epoch 41/200\n",
            "3400/3600 [===========================>..] - ETA: 0s - loss: 1.4521 - acc: 0.4547\n",
            "Epoch 00041: val_loss did not improve from 1.62938\n",
            "3600/3600 [==============================] - 1s 164us/sample - loss: 1.4533 - acc: 0.4528 - val_loss: 1.6583 - val_acc: 0.3583\n",
            "Epoch 42/200\n",
            "3300/3600 [==========================>...] - ETA: 0s - loss: 1.4225 - acc: 0.4597\n",
            "Epoch 00042: val_loss did not improve from 1.62938\n",
            "3600/3600 [==============================] - 1s 182us/sample - loss: 1.4194 - acc: 0.4614 - val_loss: 1.7867 - val_acc: 0.3200\n",
            "Epoch 43/200\n",
            "3400/3600 [===========================>..] - ETA: 0s - loss: 1.4171 - acc: 0.4597\n",
            "Epoch 00043: val_loss did not improve from 1.62938\n",
            "3600/3600 [==============================] - 1s 179us/sample - loss: 1.4225 - acc: 0.4564 - val_loss: 1.6722 - val_acc: 0.3383\n",
            "Epoch 44/200\n",
            "3400/3600 [===========================>..] - ETA: 0s - loss: 1.4114 - acc: 0.4779\n",
            "Epoch 00044: val_loss improved from 1.62938 to 1.58346, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
            "3600/3600 [==============================] - 1s 187us/sample - loss: 1.4154 - acc: 0.4767 - val_loss: 1.5835 - val_acc: 0.3858\n",
            "Epoch 45/200\n",
            "3200/3600 [=========================>....] - ETA: 0s - loss: 1.3771 - acc: 0.4769\n",
            "Epoch 00045: val_loss did not improve from 1.58346\n",
            "3600/3600 [==============================] - 1s 162us/sample - loss: 1.3855 - acc: 0.4733 - val_loss: 1.6257 - val_acc: 0.3708\n",
            "Epoch 46/200\n",
            "3200/3600 [=========================>....] - ETA: 0s - loss: 1.3891 - acc: 0.4812\n",
            "Epoch 00046: val_loss improved from 1.58346 to 1.57728, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
            "3600/3600 [==============================] - 1s 190us/sample - loss: 1.4015 - acc: 0.4783 - val_loss: 1.5773 - val_acc: 0.3892\n",
            "Epoch 47/200\n",
            "3400/3600 [===========================>..] - ETA: 0s - loss: 1.3879 - acc: 0.4703\n",
            "Epoch 00047: val_loss improved from 1.57728 to 1.53871, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
            "3600/3600 [==============================] - 1s 201us/sample - loss: 1.3862 - acc: 0.4714 - val_loss: 1.5387 - val_acc: 0.4242\n",
            "Epoch 48/200\n",
            "3300/3600 [==========================>...] - ETA: 0s - loss: 1.3544 - acc: 0.4852\n",
            "Epoch 00048: val_loss did not improve from 1.53871\n",
            "3600/3600 [==============================] - 1s 164us/sample - loss: 1.3652 - acc: 0.4828 - val_loss: 1.5677 - val_acc: 0.3933\n",
            "Epoch 49/200\n",
            "3200/3600 [=========================>....] - ETA: 0s - loss: 1.3356 - acc: 0.4938\n",
            "Epoch 00049: val_loss did not improve from 1.53871\n",
            "3600/3600 [==============================] - 1s 167us/sample - loss: 1.3453 - acc: 0.4883 - val_loss: 1.5510 - val_acc: 0.3992\n",
            "Epoch 50/200\n",
            "3400/3600 [===========================>..] - ETA: 0s - loss: 1.3384 - acc: 0.5071\n",
            "Epoch 00050: val_loss did not improve from 1.53871\n",
            "3600/3600 [==============================] - 1s 179us/sample - loss: 1.3411 - acc: 0.5058 - val_loss: 1.5681 - val_acc: 0.3908\n",
            "Epoch 51/200\n",
            "3200/3600 [=========================>....] - ETA: 0s - loss: 1.3518 - acc: 0.5013\n",
            "Epoch 00051: val_loss did not improve from 1.53871\n",
            "3600/3600 [==============================] - 1s 170us/sample - loss: 1.3578 - acc: 0.4944 - val_loss: 1.5506 - val_acc: 0.4167\n",
            "Epoch 52/200\n",
            "3400/3600 [===========================>..] - ETA: 0s - loss: 1.3403 - acc: 0.4991\n",
            "Epoch 00052: val_loss improved from 1.53871 to 1.52008, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
            "3600/3600 [==============================] - 1s 198us/sample - loss: 1.3385 - acc: 0.5011 - val_loss: 1.5201 - val_acc: 0.4192\n",
            "Epoch 53/200\n",
            "3500/3600 [============================>.] - ETA: 0s - loss: 1.3202 - acc: 0.5111\n",
            "Epoch 00053: val_loss improved from 1.52008 to 1.48919, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
            "3600/3600 [==============================] - 1s 201us/sample - loss: 1.3247 - acc: 0.5092 - val_loss: 1.4892 - val_acc: 0.4300\n",
            "Epoch 54/200\n",
            "3200/3600 [=========================>....] - ETA: 0s - loss: 1.3012 - acc: 0.5213\n",
            "Epoch 00054: val_loss did not improve from 1.48919\n",
            "3600/3600 [==============================] - 1s 170us/sample - loss: 1.3087 - acc: 0.5172 - val_loss: 1.5474 - val_acc: 0.3992\n",
            "Epoch 55/200\n",
            "3200/3600 [=========================>....] - ETA: 0s - loss: 1.3007 - acc: 0.5156\n",
            "Epoch 00055: val_loss improved from 1.48919 to 1.44863, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
            "3600/3600 [==============================] - 1s 191us/sample - loss: 1.3097 - acc: 0.5119 - val_loss: 1.4486 - val_acc: 0.4383\n",
            "Epoch 56/200\n",
            "3200/3600 [=========================>....] - ETA: 0s - loss: 1.3203 - acc: 0.5019\n",
            "Epoch 00056: val_loss did not improve from 1.44863\n",
            "3600/3600 [==============================] - 1s 161us/sample - loss: 1.3191 - acc: 0.5031 - val_loss: 1.5628 - val_acc: 0.3875\n",
            "Epoch 57/200\n",
            "3500/3600 [============================>.] - ETA: 0s - loss: 1.3114 - acc: 0.5091\n",
            "Epoch 00057: val_loss did not improve from 1.44863\n",
            "3600/3600 [==============================] - 1s 175us/sample - loss: 1.3128 - acc: 0.5083 - val_loss: 1.5605 - val_acc: 0.3992\n",
            "Epoch 58/200\n",
            "3400/3600 [===========================>..] - ETA: 0s - loss: 1.3108 - acc: 0.5091\n",
            "Epoch 00058: val_loss improved from 1.44863 to 1.43365, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
            "3600/3600 [==============================] - 1s 181us/sample - loss: 1.3111 - acc: 0.5086 - val_loss: 1.4336 - val_acc: 0.4583\n",
            "Epoch 59/200\n",
            "3500/3600 [============================>.] - ETA: 0s - loss: 1.2794 - acc: 0.5269\n",
            "Epoch 00059: val_loss did not improve from 1.43365\n",
            "3600/3600 [==============================] - 1s 177us/sample - loss: 1.2794 - acc: 0.5267 - val_loss: 1.4525 - val_acc: 0.4483\n",
            "Epoch 60/200\n",
            "3400/3600 [===========================>..] - ETA: 0s - loss: 1.2868 - acc: 0.5179\n",
            "Epoch 00060: val_loss did not improve from 1.43365\n",
            "3600/3600 [==============================] - 1s 168us/sample - loss: 1.2925 - acc: 0.5144 - val_loss: 1.5140 - val_acc: 0.4083\n",
            "Epoch 61/200\n",
            "3200/3600 [=========================>....] - ETA: 0s - loss: 1.2676 - acc: 0.5197\n",
            "Epoch 00061: val_loss improved from 1.43365 to 1.42955, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
            "3600/3600 [==============================] - 1s 195us/sample - loss: 1.2766 - acc: 0.5186 - val_loss: 1.4296 - val_acc: 0.4642\n",
            "Epoch 62/200\n",
            "3200/3600 [=========================>....] - ETA: 0s - loss: 1.2779 - acc: 0.5269\n",
            "Epoch 00062: val_loss improved from 1.42955 to 1.41412, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
            "3600/3600 [==============================] - 1s 188us/sample - loss: 1.2824 - acc: 0.5231 - val_loss: 1.4141 - val_acc: 0.4717\n",
            "Epoch 63/200\n",
            "3500/3600 [============================>.] - ETA: 0s - loss: 1.2526 - acc: 0.5411\n",
            "Epoch 00063: val_loss did not improve from 1.41412\n",
            "3600/3600 [==============================] - 1s 170us/sample - loss: 1.2571 - acc: 0.5369 - val_loss: 1.4604 - val_acc: 0.4442\n",
            "Epoch 64/200\n",
            "3400/3600 [===========================>..] - ETA: 0s - loss: 1.2572 - acc: 0.5374\n",
            "Epoch 00064: val_loss did not improve from 1.41412\n",
            "3600/3600 [==============================] - 1s 174us/sample - loss: 1.2540 - acc: 0.5397 - val_loss: 1.4718 - val_acc: 0.4392\n",
            "Epoch 65/200\n",
            "3200/3600 [=========================>....] - ETA: 0s - loss: 1.2480 - acc: 0.5300\n",
            "Epoch 00065: val_loss did not improve from 1.41412\n",
            "3600/3600 [==============================] - 1s 171us/sample - loss: 1.2509 - acc: 0.5281 - val_loss: 1.4935 - val_acc: 0.4192\n",
            "Epoch 66/200\n",
            "3400/3600 [===========================>..] - ETA: 0s - loss: 1.2037 - acc: 0.5562\n",
            "Epoch 00066: val_loss did not improve from 1.41412\n",
            "3600/3600 [==============================] - 1s 175us/sample - loss: 1.2082 - acc: 0.5553 - val_loss: 1.4630 - val_acc: 0.4492\n",
            "Epoch 67/200\n",
            "3400/3600 [===========================>..] - ETA: 0s - loss: 1.2260 - acc: 0.5491\n",
            "Epoch 00067: val_loss did not improve from 1.41412\n",
            "3600/3600 [==============================] - 1s 180us/sample - loss: 1.2305 - acc: 0.5467 - val_loss: 1.5517 - val_acc: 0.4183\n",
            "Epoch 68/200\n",
            "3200/3600 [=========================>....] - ETA: 0s - loss: 1.2136 - acc: 0.5381\n",
            "Epoch 00068: val_loss improved from 1.41412 to 1.38036, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
            "3600/3600 [==============================] - 1s 190us/sample - loss: 1.2215 - acc: 0.5336 - val_loss: 1.3804 - val_acc: 0.4850\n",
            "Epoch 69/200\n",
            "3400/3600 [===========================>..] - ETA: 0s - loss: 1.2024 - acc: 0.5518\n",
            "Epoch 00069: val_loss did not improve from 1.38036\n",
            "3600/3600 [==============================] - 1s 188us/sample - loss: 1.2042 - acc: 0.5497 - val_loss: 1.4342 - val_acc: 0.4683\n",
            "Epoch 70/200\n",
            "3400/3600 [===========================>..] - ETA: 0s - loss: 1.1869 - acc: 0.5585\n",
            "Epoch 00070: val_loss improved from 1.38036 to 1.35730, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
            "3600/3600 [==============================] - 1s 183us/sample - loss: 1.1928 - acc: 0.5575 - val_loss: 1.3573 - val_acc: 0.4917\n",
            "Epoch 71/200\n",
            "3100/3600 [========================>.....] - ETA: 0s - loss: 1.1812 - acc: 0.5732\n",
            "Epoch 00071: val_loss did not improve from 1.35730\n",
            "3600/3600 [==============================] - 1s 180us/sample - loss: 1.1915 - acc: 0.5703 - val_loss: 1.4252 - val_acc: 0.4658\n",
            "Epoch 72/200\n",
            "3100/3600 [========================>.....] - ETA: 0s - loss: 1.1824 - acc: 0.5471\n",
            "Epoch 00072: val_loss did not improve from 1.35730\n",
            "3600/3600 [==============================] - 1s 173us/sample - loss: 1.1854 - acc: 0.5467 - val_loss: 1.3995 - val_acc: 0.4775\n",
            "Epoch 73/200\n",
            "3300/3600 [==========================>...] - ETA: 0s - loss: 1.1907 - acc: 0.5697\n",
            "Epoch 00073: val_loss improved from 1.35730 to 1.31546, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
            "3600/3600 [==============================] - 1s 207us/sample - loss: 1.1995 - acc: 0.5686 - val_loss: 1.3155 - val_acc: 0.5042\n",
            "Epoch 74/200\n",
            "3300/3600 [==========================>...] - ETA: 0s - loss: 1.1717 - acc: 0.5648\n",
            "Epoch 00074: val_loss did not improve from 1.31546\n",
            "3600/3600 [==============================] - 1s 157us/sample - loss: 1.1789 - acc: 0.5631 - val_loss: 1.3335 - val_acc: 0.5125\n",
            "Epoch 75/200\n",
            "3300/3600 [==========================>...] - ETA: 0s - loss: 1.1600 - acc: 0.5794\n",
            "Epoch 00075: val_loss did not improve from 1.31546\n",
            "3600/3600 [==============================] - 1s 168us/sample - loss: 1.1641 - acc: 0.5769 - val_loss: 1.3206 - val_acc: 0.5125\n",
            "Epoch 76/200\n",
            "3500/3600 [============================>.] - ETA: 0s - loss: 1.1647 - acc: 0.5726\n",
            "Epoch 00076: val_loss did not improve from 1.31546\n",
            "3600/3600 [==============================] - 1s 159us/sample - loss: 1.1656 - acc: 0.5736 - val_loss: 1.3577 - val_acc: 0.5025\n",
            "Epoch 77/200\n",
            "3500/3600 [============================>.] - ETA: 0s - loss: 1.1612 - acc: 0.5763\n",
            "Epoch 00077: val_loss improved from 1.31546 to 1.31142, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
            "3600/3600 [==============================] - 1s 196us/sample - loss: 1.1623 - acc: 0.5758 - val_loss: 1.3114 - val_acc: 0.5058\n",
            "Epoch 78/200\n",
            "3300/3600 [==========================>...] - ETA: 0s - loss: 1.1485 - acc: 0.5779\n",
            "Epoch 00078: val_loss improved from 1.31142 to 1.30080, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
            "3600/3600 [==============================] - 1s 188us/sample - loss: 1.1474 - acc: 0.5794 - val_loss: 1.3008 - val_acc: 0.5217\n",
            "Epoch 79/200\n",
            "3200/3600 [=========================>....] - ETA: 0s - loss: 1.1383 - acc: 0.5769\n",
            "Epoch 00079: val_loss did not improve from 1.30080\n",
            "3600/3600 [==============================] - 1s 174us/sample - loss: 1.1442 - acc: 0.5756 - val_loss: 1.3130 - val_acc: 0.5083\n",
            "Epoch 80/200\n",
            "3300/3600 [==========================>...] - ETA: 0s - loss: 1.1536 - acc: 0.5697\n",
            "Epoch 00080: val_loss did not improve from 1.30080\n",
            "3600/3600 [==============================] - 1s 164us/sample - loss: 1.1577 - acc: 0.5686 - val_loss: 1.3495 - val_acc: 0.4867\n",
            "Epoch 81/200\n",
            "3200/3600 [=========================>....] - ETA: 0s - loss: 1.1317 - acc: 0.5834\n",
            "Epoch 00081: val_loss improved from 1.30080 to 1.25764, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
            "3600/3600 [==============================] - 1s 195us/sample - loss: 1.1313 - acc: 0.5850 - val_loss: 1.2576 - val_acc: 0.5575\n",
            "Epoch 82/200\n",
            "3400/3600 [===========================>..] - ETA: 0s - loss: 1.1384 - acc: 0.5794\n",
            "Epoch 00082: val_loss did not improve from 1.25764\n",
            "3600/3600 [==============================] - 1s 179us/sample - loss: 1.1395 - acc: 0.5803 - val_loss: 1.3355 - val_acc: 0.5058\n",
            "Epoch 83/200\n",
            "3300/3600 [==========================>...] - ETA: 0s - loss: 1.1139 - acc: 0.5918\n",
            "Epoch 00083: val_loss improved from 1.25764 to 1.21497, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
            "3600/3600 [==============================] - 1s 192us/sample - loss: 1.1183 - acc: 0.5906 - val_loss: 1.2150 - val_acc: 0.5567\n",
            "Epoch 84/200\n",
            "3400/3600 [===========================>..] - ETA: 0s - loss: 1.1076 - acc: 0.5918\n",
            "Epoch 00084: val_loss did not improve from 1.21497\n",
            "3600/3600 [==============================] - 1s 177us/sample - loss: 1.1060 - acc: 0.5931 - val_loss: 1.3461 - val_acc: 0.4950\n",
            "Epoch 85/200\n",
            "3500/3600 [============================>.] - ETA: 0s - loss: 1.0972 - acc: 0.6080\n",
            "Epoch 00085: val_loss did not improve from 1.21497\n",
            "3600/3600 [==============================] - 1s 173us/sample - loss: 1.1022 - acc: 0.6056 - val_loss: 1.3841 - val_acc: 0.4600\n",
            "Epoch 86/200\n",
            "3200/3600 [=========================>....] - ETA: 0s - loss: 1.0943 - acc: 0.6031\n",
            "Epoch 00086: val_loss did not improve from 1.21497\n",
            "3600/3600 [==============================] - 1s 169us/sample - loss: 1.0973 - acc: 0.6008 - val_loss: 1.3385 - val_acc: 0.5075\n",
            "Epoch 87/200\n",
            "3400/3600 [===========================>..] - ETA: 0s - loss: 1.1035 - acc: 0.5832\n",
            "Epoch 00087: val_loss did not improve from 1.21497\n",
            "3600/3600 [==============================] - 1s 157us/sample - loss: 1.1040 - acc: 0.5836 - val_loss: 1.3228 - val_acc: 0.5125\n",
            "Epoch 88/200\n",
            "3300/3600 [==========================>...] - ETA: 0s - loss: 1.0938 - acc: 0.6027\n",
            "Epoch 00088: val_loss did not improve from 1.21497\n",
            "3600/3600 [==============================] - 1s 182us/sample - loss: 1.1048 - acc: 0.5953 - val_loss: 1.2264 - val_acc: 0.5533\n",
            "Epoch 89/200\n",
            "3500/3600 [============================>.] - ETA: 0s - loss: 1.0899 - acc: 0.6020\n",
            "Epoch 00089: val_loss did not improve from 1.21497\n",
            "3600/3600 [==============================] - 1s 180us/sample - loss: 1.0910 - acc: 0.6003 - val_loss: 1.2728 - val_acc: 0.5175\n",
            "Epoch 90/200\n",
            "3300/3600 [==========================>...] - ETA: 0s - loss: 1.0948 - acc: 0.5994\n",
            "Epoch 00090: val_loss did not improve from 1.21497\n",
            "3600/3600 [==============================] - 1s 169us/sample - loss: 1.0994 - acc: 0.6006 - val_loss: 1.2392 - val_acc: 0.5317\n",
            "Epoch 91/200\n",
            "3400/3600 [===========================>..] - ETA: 0s - loss: 1.0775 - acc: 0.6103\n",
            "Epoch 00091: val_loss did not improve from 1.21497\n",
            "3600/3600 [==============================] - 1s 180us/sample - loss: 1.0823 - acc: 0.6086 - val_loss: 1.2892 - val_acc: 0.5258\n",
            "Epoch 92/200\n",
            "3400/3600 [===========================>..] - ETA: 0s - loss: 1.0697 - acc: 0.6179\n",
            "Epoch 00092: val_loss improved from 1.21497 to 1.14499, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
            "3600/3600 [==============================] - 1s 196us/sample - loss: 1.0677 - acc: 0.6183 - val_loss: 1.1450 - val_acc: 0.5858\n",
            "Epoch 93/200\n",
            "3300/3600 [==========================>...] - ETA: 0s - loss: 1.0942 - acc: 0.6021\n",
            "Epoch 00093: val_loss did not improve from 1.14499\n",
            "3600/3600 [==============================] - 1s 172us/sample - loss: 1.0933 - acc: 0.6031 - val_loss: 1.2050 - val_acc: 0.5542\n",
            "Epoch 94/200\n",
            "3500/3600 [============================>.] - ETA: 0s - loss: 1.0754 - acc: 0.6060\n",
            "Epoch 00094: val_loss did not improve from 1.14499\n",
            "3600/3600 [==============================] - 1s 177us/sample - loss: 1.0761 - acc: 0.6067 - val_loss: 1.1863 - val_acc: 0.5658\n",
            "Epoch 95/200\n",
            "3200/3600 [=========================>....] - ETA: 0s - loss: 1.0337 - acc: 0.6259\n",
            "Epoch 00095: val_loss did not improve from 1.14499\n",
            "3600/3600 [==============================] - 1s 167us/sample - loss: 1.0459 - acc: 0.6219 - val_loss: 1.2674 - val_acc: 0.5142\n",
            "Epoch 96/200\n",
            "3200/3600 [=========================>....] - ETA: 0s - loss: 1.0757 - acc: 0.6147\n",
            "Epoch 00096: val_loss did not improve from 1.14499\n",
            "3600/3600 [==============================] - 1s 169us/sample - loss: 1.0814 - acc: 0.6128 - val_loss: 1.2017 - val_acc: 0.5517\n",
            "Epoch 97/200\n",
            "3500/3600 [============================>.] - ETA: 0s - loss: 1.0871 - acc: 0.5949\n",
            "Epoch 00097: val_loss did not improve from 1.14499\n",
            "3600/3600 [==============================] - 1s 180us/sample - loss: 1.0878 - acc: 0.5950 - val_loss: 1.2224 - val_acc: 0.5425\n",
            "Epoch 98/200\n",
            "3400/3600 [===========================>..] - ETA: 0s - loss: 1.0536 - acc: 0.6224\n",
            "Epoch 00098: val_loss did not improve from 1.14499\n",
            "3600/3600 [==============================] - 1s 179us/sample - loss: 1.0523 - acc: 0.6228 - val_loss: 1.2140 - val_acc: 0.5300\n",
            "Epoch 99/200\n",
            "3300/3600 [==========================>...] - ETA: 0s - loss: 1.0260 - acc: 0.6373\n",
            "Epoch 00099: val_loss did not improve from 1.14499\n",
            "3600/3600 [==============================] - 1s 169us/sample - loss: 1.0194 - acc: 0.6397 - val_loss: 1.1812 - val_acc: 0.5633\n",
            "Epoch 100/200\n",
            "3300/3600 [==========================>...] - ETA: 0s - loss: 1.0496 - acc: 0.6188\n",
            "Epoch 00100: val_loss did not improve from 1.14499\n",
            "3600/3600 [==============================] - 1s 179us/sample - loss: 1.0585 - acc: 0.6175 - val_loss: 1.1674 - val_acc: 0.5758\n",
            "Epoch 101/200\n",
            "3200/3600 [=========================>....] - ETA: 0s - loss: 1.0322 - acc: 0.6244\n",
            "Epoch 00101: val_loss did not improve from 1.14499\n",
            "3600/3600 [==============================] - 1s 181us/sample - loss: 1.0329 - acc: 0.6219 - val_loss: 1.3356 - val_acc: 0.4858\n",
            "Epoch 102/200\n",
            "3300/3600 [==========================>...] - ETA: 0s - loss: 1.0405 - acc: 0.6164\n",
            "Epoch 00102: val_loss did not improve from 1.14499\n",
            "3600/3600 [==============================] - 1s 176us/sample - loss: 1.0437 - acc: 0.6172 - val_loss: 1.1818 - val_acc: 0.5550\n",
            "Epoch 103/200\n",
            "3400/3600 [===========================>..] - ETA: 0s - loss: 1.0437 - acc: 0.6232\n",
            "Epoch 00103: val_loss did not improve from 1.14499\n",
            "3600/3600 [==============================] - 1s 159us/sample - loss: 1.0435 - acc: 0.6211 - val_loss: 1.2295 - val_acc: 0.5367\n",
            "Epoch 104/200\n",
            "3300/3600 [==========================>...] - ETA: 0s - loss: 1.0324 - acc: 0.6185\n",
            "Epoch 00104: val_loss did not improve from 1.14499\n",
            "3600/3600 [==============================] - 1s 174us/sample - loss: 1.0291 - acc: 0.6169 - val_loss: 1.1749 - val_acc: 0.5708\n",
            "Epoch 105/200\n",
            "3500/3600 [============================>.] - ETA: 0s - loss: 1.0143 - acc: 0.6354\n",
            "Epoch 00105: val_loss improved from 1.14499 to 1.10995, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
            "3600/3600 [==============================] - 1s 171us/sample - loss: 1.0157 - acc: 0.6350 - val_loss: 1.1099 - val_acc: 0.5983\n",
            "Epoch 106/200\n",
            "3400/3600 [===========================>..] - ETA: 0s - loss: 1.0174 - acc: 0.6329\n",
            "Epoch 00106: val_loss did not improve from 1.10995\n",
            "3600/3600 [==============================] - 1s 176us/sample - loss: 1.0133 - acc: 0.6344 - val_loss: 1.1639 - val_acc: 0.5750\n",
            "Epoch 107/200\n",
            "3500/3600 [============================>.] - ETA: 0s - loss: 1.0137 - acc: 0.6354\n",
            "Epoch 00107: val_loss did not improve from 1.10995\n",
            "3600/3600 [==============================] - 1s 168us/sample - loss: 1.0140 - acc: 0.6344 - val_loss: 1.1710 - val_acc: 0.5750\n",
            "Epoch 108/200\n",
            "3200/3600 [=========================>....] - ETA: 0s - loss: 1.0221 - acc: 0.6266\n",
            "Epoch 00108: val_loss did not improve from 1.10995\n",
            "3600/3600 [==============================] - 1s 172us/sample - loss: 1.0257 - acc: 0.6244 - val_loss: 1.1547 - val_acc: 0.5675\n",
            "Epoch 109/200\n",
            "3400/3600 [===========================>..] - ETA: 0s - loss: 1.0085 - acc: 0.6426\n",
            "Epoch 00109: val_loss did not improve from 1.10995\n",
            "3600/3600 [==============================] - 1s 162us/sample - loss: 1.0127 - acc: 0.6397 - val_loss: 1.2305 - val_acc: 0.5475\n",
            "Epoch 110/200\n",
            "3500/3600 [============================>.] - ETA: 0s - loss: 1.0117 - acc: 0.6249\n",
            "Epoch 00110: val_loss did not improve from 1.10995\n",
            "3600/3600 [==============================] - 1s 166us/sample - loss: 1.0152 - acc: 0.6231 - val_loss: 1.1789 - val_acc: 0.5533\n",
            "Epoch 111/200\n",
            "3400/3600 [===========================>..] - ETA: 0s - loss: 1.0052 - acc: 0.6276\n",
            "Epoch 00111: val_loss did not improve from 1.10995\n",
            "3600/3600 [==============================] - 1s 172us/sample - loss: 1.0052 - acc: 0.6261 - val_loss: 1.1190 - val_acc: 0.5842\n",
            "Epoch 112/200\n",
            "3400/3600 [===========================>..] - ETA: 0s - loss: 1.0144 - acc: 0.6226\n",
            "Epoch 00112: val_loss did not improve from 1.10995\n",
            "3600/3600 [==============================] - 1s 179us/sample - loss: 1.0141 - acc: 0.6236 - val_loss: 1.2477 - val_acc: 0.5267\n",
            "Epoch 113/200\n",
            "3200/3600 [=========================>....] - ETA: 0s - loss: 0.9776 - acc: 0.6494\n",
            "Epoch 00113: val_loss did not improve from 1.10995\n",
            "3600/3600 [==============================] - 1s 171us/sample - loss: 0.9854 - acc: 0.6483 - val_loss: 1.1318 - val_acc: 0.5642\n",
            "Epoch 114/200\n",
            "3400/3600 [===========================>..] - ETA: 0s - loss: 1.0046 - acc: 0.6288\n",
            "Epoch 00114: val_loss did not improve from 1.10995\n",
            "3600/3600 [==============================] - 1s 182us/sample - loss: 0.9998 - acc: 0.6325 - val_loss: 1.1108 - val_acc: 0.5925\n",
            "Epoch 115/200\n",
            "3500/3600 [============================>.] - ETA: 0s - loss: 0.9853 - acc: 0.6494\n",
            "Epoch 00115: val_loss improved from 1.10995 to 1.05656, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
            "3600/3600 [==============================] - 1s 196us/sample - loss: 0.9868 - acc: 0.6478 - val_loss: 1.0566 - val_acc: 0.6308\n",
            "Epoch 116/200\n",
            "3300/3600 [==========================>...] - ETA: 0s - loss: 0.9918 - acc: 0.6433\n",
            "Epoch 00116: val_loss did not improve from 1.05656\n",
            "3600/3600 [==============================] - 1s 175us/sample - loss: 1.0059 - acc: 0.6389 - val_loss: 1.0649 - val_acc: 0.6108\n",
            "Epoch 117/200\n",
            "3500/3600 [============================>.] - ETA: 0s - loss: 0.9914 - acc: 0.6391\n",
            "Epoch 00117: val_loss did not improve from 1.05656\n",
            "3600/3600 [==============================] - 1s 176us/sample - loss: 0.9886 - acc: 0.6422 - val_loss: 1.1068 - val_acc: 0.5975\n",
            "Epoch 118/200\n",
            "3400/3600 [===========================>..] - ETA: 0s - loss: 0.9757 - acc: 0.6426\n",
            "Epoch 00118: val_loss did not improve from 1.05656\n",
            "3600/3600 [==============================] - 1s 177us/sample - loss: 0.9849 - acc: 0.6408 - val_loss: 1.0819 - val_acc: 0.6050\n",
            "Epoch 119/200\n",
            "3400/3600 [===========================>..] - ETA: 0s - loss: 0.9813 - acc: 0.6424\n",
            "Epoch 00119: val_loss did not improve from 1.05656\n",
            "3600/3600 [==============================] - 1s 176us/sample - loss: 0.9826 - acc: 0.6425 - val_loss: 1.1538 - val_acc: 0.5733\n",
            "Epoch 120/200\n",
            "3400/3600 [===========================>..] - ETA: 0s - loss: 0.9706 - acc: 0.6441\n",
            "Epoch 00120: val_loss did not improve from 1.05656\n",
            "3600/3600 [==============================] - 1s 183us/sample - loss: 0.9735 - acc: 0.6431 - val_loss: 1.1856 - val_acc: 0.5558\n",
            "Epoch 121/200\n",
            "3100/3600 [========================>.....] - ETA: 0s - loss: 0.9863 - acc: 0.6500\n",
            "Epoch 00121: val_loss did not improve from 1.05656\n",
            "3600/3600 [==============================] - 1s 167us/sample - loss: 0.9868 - acc: 0.6500 - val_loss: 1.0765 - val_acc: 0.6158\n",
            "Epoch 122/200\n",
            "3200/3600 [=========================>....] - ETA: 0s - loss: 0.9642 - acc: 0.6425\n",
            "Epoch 00122: val_loss did not improve from 1.05656\n",
            "3600/3600 [==============================] - 1s 165us/sample - loss: 0.9746 - acc: 0.6378 - val_loss: 1.1132 - val_acc: 0.5875\n",
            "Epoch 123/200\n",
            "3300/3600 [==========================>...] - ETA: 0s - loss: 0.9695 - acc: 0.6455\n",
            "Epoch 00123: val_loss improved from 1.05656 to 1.05350, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
            "3600/3600 [==============================] - 1s 189us/sample - loss: 0.9725 - acc: 0.6447 - val_loss: 1.0535 - val_acc: 0.6075\n",
            "Epoch 124/200\n",
            "3500/3600 [============================>.] - ETA: 0s - loss: 0.9605 - acc: 0.6543\n",
            "Epoch 00124: val_loss did not improve from 1.05350\n",
            "3600/3600 [==============================] - 1s 178us/sample - loss: 0.9622 - acc: 0.6539 - val_loss: 1.2073 - val_acc: 0.5342\n",
            "Epoch 125/200\n",
            "3300/3600 [==========================>...] - ETA: 0s - loss: 0.9585 - acc: 0.6582\n",
            "Epoch 00125: val_loss did not improve from 1.05350\n",
            "3600/3600 [==============================] - 1s 175us/sample - loss: 0.9533 - acc: 0.6619 - val_loss: 1.0798 - val_acc: 0.6092\n",
            "Epoch 126/200\n",
            "3500/3600 [============================>.] - ETA: 0s - loss: 0.9277 - acc: 0.6643\n",
            "Epoch 00126: val_loss improved from 1.05350 to 1.00808, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
            "3600/3600 [==============================] - 1s 185us/sample - loss: 0.9331 - acc: 0.6617 - val_loss: 1.0081 - val_acc: 0.6308\n",
            "Epoch 127/200\n",
            "3200/3600 [=========================>....] - ETA: 0s - loss: 0.9431 - acc: 0.6631\n",
            "Epoch 00127: val_loss did not improve from 1.00808\n",
            "3600/3600 [==============================] - 1s 161us/sample - loss: 0.9533 - acc: 0.6583 - val_loss: 1.0512 - val_acc: 0.6242\n",
            "Epoch 128/200\n",
            "3500/3600 [============================>.] - ETA: 0s - loss: 0.9583 - acc: 0.6586\n",
            "Epoch 00128: val_loss did not improve from 1.00808\n",
            "3600/3600 [==============================] - 1s 174us/sample - loss: 0.9617 - acc: 0.6567 - val_loss: 1.0737 - val_acc: 0.5933\n",
            "Epoch 129/200\n",
            "3400/3600 [===========================>..] - ETA: 0s - loss: 0.9283 - acc: 0.6606\n",
            "Epoch 00129: val_loss did not improve from 1.00808\n",
            "3600/3600 [==============================] - 1s 159us/sample - loss: 0.9261 - acc: 0.6619 - val_loss: 1.0200 - val_acc: 0.6233\n",
            "Epoch 130/200\n",
            "3400/3600 [===========================>..] - ETA: 0s - loss: 0.9369 - acc: 0.6618\n",
            "Epoch 00130: val_loss did not improve from 1.00808\n",
            "3600/3600 [==============================] - 1s 173us/sample - loss: 0.9376 - acc: 0.6611 - val_loss: 1.0217 - val_acc: 0.6308\n",
            "Epoch 131/200\n",
            "3500/3600 [============================>.] - ETA: 0s - loss: 0.9397 - acc: 0.6606\n",
            "Epoch 00131: val_loss improved from 1.00808 to 0.99852, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
            "3600/3600 [==============================] - 1s 202us/sample - loss: 0.9389 - acc: 0.6600 - val_loss: 0.9985 - val_acc: 0.6500\n",
            "Epoch 132/200\n",
            "3200/3600 [=========================>....] - ETA: 0s - loss: 0.9327 - acc: 0.6616\n",
            "Epoch 00132: val_loss did not improve from 0.99852\n",
            "3600/3600 [==============================] - 1s 167us/sample - loss: 0.9412 - acc: 0.6578 - val_loss: 1.0641 - val_acc: 0.6183\n",
            "Epoch 133/200\n",
            "3300/3600 [==========================>...] - ETA: 0s - loss: 0.9293 - acc: 0.6579\n",
            "Epoch 00133: val_loss did not improve from 0.99852\n",
            "3600/3600 [==============================] - 1s 164us/sample - loss: 0.9306 - acc: 0.6583 - val_loss: 1.0816 - val_acc: 0.5983\n",
            "Epoch 134/200\n",
            "3100/3600 [========================>.....] - ETA: 0s - loss: 0.9339 - acc: 0.6574\n",
            "Epoch 00134: val_loss did not improve from 0.99852\n",
            "3600/3600 [==============================] - 1s 164us/sample - loss: 0.9414 - acc: 0.6567 - val_loss: 1.1315 - val_acc: 0.5967\n",
            "Epoch 135/200\n",
            "3500/3600 [============================>.] - ETA: 0s - loss: 0.9198 - acc: 0.6691\n",
            "Epoch 00135: val_loss improved from 0.99852 to 0.95541, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
            "3600/3600 [==============================] - 1s 197us/sample - loss: 0.9230 - acc: 0.6675 - val_loss: 0.9554 - val_acc: 0.6683\n",
            "Epoch 136/200\n",
            "3200/3600 [=========================>....] - ETA: 0s - loss: 0.9184 - acc: 0.6650\n",
            "Epoch 00136: val_loss did not improve from 0.95541\n",
            "3600/3600 [==============================] - 1s 168us/sample - loss: 0.9219 - acc: 0.6672 - val_loss: 0.9916 - val_acc: 0.6358\n",
            "Epoch 137/200\n",
            "3100/3600 [========================>.....] - ETA: 0s - loss: 0.9262 - acc: 0.6716\n",
            "Epoch 00137: val_loss did not improve from 0.95541\n",
            "3600/3600 [==============================] - 1s 155us/sample - loss: 0.9310 - acc: 0.6678 - val_loss: 1.0146 - val_acc: 0.6292\n",
            "Epoch 138/200\n",
            "3300/3600 [==========================>...] - ETA: 0s - loss: 0.9159 - acc: 0.6703\n",
            "Epoch 00138: val_loss did not improve from 0.95541\n",
            "3600/3600 [==============================] - 1s 178us/sample - loss: 0.9170 - acc: 0.6694 - val_loss: 1.0703 - val_acc: 0.5992\n",
            "Epoch 139/200\n",
            "3500/3600 [============================>.] - ETA: 0s - loss: 0.9253 - acc: 0.6554\n",
            "Epoch 00139: val_loss did not improve from 0.95541\n",
            "3600/3600 [==============================] - 1s 155us/sample - loss: 0.9263 - acc: 0.6567 - val_loss: 0.9960 - val_acc: 0.6392\n",
            "Epoch 140/200\n",
            "3400/3600 [===========================>..] - ETA: 0s - loss: 0.9108 - acc: 0.6762\n",
            "Epoch 00140: val_loss did not improve from 0.95541\n",
            "3600/3600 [==============================] - 1s 172us/sample - loss: 0.9121 - acc: 0.6744 - val_loss: 1.0805 - val_acc: 0.6025\n",
            "Epoch 141/200\n",
            "3200/3600 [=========================>....] - ETA: 0s - loss: 0.9050 - acc: 0.6809\n",
            "Epoch 00141: val_loss did not improve from 0.95541\n",
            "3600/3600 [==============================] - 1s 182us/sample - loss: 0.9182 - acc: 0.6781 - val_loss: 1.0671 - val_acc: 0.5967\n",
            "Epoch 142/200\n",
            "3300/3600 [==========================>...] - ETA: 0s - loss: 0.9243 - acc: 0.6645\n",
            "Epoch 00142: val_loss did not improve from 0.95541\n",
            "3600/3600 [==============================] - 1s 178us/sample - loss: 0.9344 - acc: 0.6633 - val_loss: 1.0447 - val_acc: 0.6133\n",
            "Epoch 143/200\n",
            "3300/3600 [==========================>...] - ETA: 0s - loss: 0.9273 - acc: 0.6627\n",
            "Epoch 00143: val_loss did not improve from 0.95541\n",
            "3600/3600 [==============================] - 1s 170us/sample - loss: 0.9309 - acc: 0.6608 - val_loss: 1.0363 - val_acc: 0.6200\n",
            "Epoch 144/200\n",
            "3300/3600 [==========================>...] - ETA: 0s - loss: 0.9147 - acc: 0.6697\n",
            "Epoch 00144: val_loss did not improve from 0.95541\n",
            "3600/3600 [==============================] - 1s 163us/sample - loss: 0.9122 - acc: 0.6703 - val_loss: 1.1161 - val_acc: 0.5750\n",
            "Epoch 145/200\n",
            "3300/3600 [==========================>...] - ETA: 0s - loss: 0.9080 - acc: 0.6758\n",
            "Epoch 00145: val_loss did not improve from 0.95541\n",
            "3600/3600 [==============================] - 1s 176us/sample - loss: 0.9079 - acc: 0.6778 - val_loss: 1.0731 - val_acc: 0.5925\n",
            "Epoch 146/200\n",
            "3400/3600 [===========================>..] - ETA: 0s - loss: 0.9117 - acc: 0.6724\n",
            "Epoch 00146: val_loss did not improve from 0.95541\n",
            "3600/3600 [==============================] - 1s 167us/sample - loss: 0.9139 - acc: 0.6731 - val_loss: 0.9966 - val_acc: 0.6250\n",
            "Epoch 147/200\n",
            "3300/3600 [==========================>...] - ETA: 0s - loss: 0.8908 - acc: 0.6818\n",
            "Epoch 00147: val_loss did not improve from 0.95541\n",
            "3600/3600 [==============================] - 1s 170us/sample - loss: 0.8981 - acc: 0.6753 - val_loss: 1.1567 - val_acc: 0.5625\n",
            "Epoch 148/200\n",
            "3500/3600 [============================>.] - ETA: 0s - loss: 0.9210 - acc: 0.6586\n",
            "Epoch 00148: val_loss did not improve from 0.95541\n",
            "3600/3600 [==============================] - 1s 170us/sample - loss: 0.9188 - acc: 0.6589 - val_loss: 0.9606 - val_acc: 0.6617\n",
            "Epoch 149/200\n",
            "3400/3600 [===========================>..] - ETA: 0s - loss: 0.8976 - acc: 0.6794\n",
            "Epoch 00149: val_loss did not improve from 0.95541\n",
            "3600/3600 [==============================] - 1s 163us/sample - loss: 0.9010 - acc: 0.6772 - val_loss: 0.9716 - val_acc: 0.6525\n",
            "Epoch 150/200\n",
            "3400/3600 [===========================>..] - ETA: 0s - loss: 0.8891 - acc: 0.6794\n",
            "Epoch 00150: val_loss improved from 0.95541 to 0.94377, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
            "3600/3600 [==============================] - 1s 186us/sample - loss: 0.8923 - acc: 0.6781 - val_loss: 0.9438 - val_acc: 0.6683\n",
            "Epoch 151/200\n",
            "3500/3600 [============================>.] - ETA: 0s - loss: 0.8745 - acc: 0.6860\n",
            "Epoch 00151: val_loss did not improve from 0.94377\n",
            "3600/3600 [==============================] - 1s 180us/sample - loss: 0.8753 - acc: 0.6858 - val_loss: 1.0385 - val_acc: 0.6308\n",
            "Epoch 152/200\n",
            "3200/3600 [=========================>....] - ETA: 0s - loss: 0.8815 - acc: 0.6784\n",
            "Epoch 00152: val_loss did not improve from 0.94377\n",
            "3600/3600 [==============================] - 1s 170us/sample - loss: 0.8879 - acc: 0.6778 - val_loss: 0.9615 - val_acc: 0.6625\n",
            "Epoch 153/200\n",
            "3300/3600 [==========================>...] - ETA: 0s - loss: 0.9038 - acc: 0.6839\n",
            "Epoch 00153: val_loss did not improve from 0.94377\n",
            "3600/3600 [==============================] - 1s 170us/sample - loss: 0.9169 - acc: 0.6797 - val_loss: 0.9555 - val_acc: 0.6625\n",
            "Epoch 154/200\n",
            "3400/3600 [===========================>..] - ETA: 0s - loss: 0.8750 - acc: 0.6924\n",
            "Epoch 00154: val_loss did not improve from 0.94377\n",
            "3600/3600 [==============================] - 1s 161us/sample - loss: 0.8787 - acc: 0.6908 - val_loss: 0.9710 - val_acc: 0.6500\n",
            "Epoch 155/200\n",
            "3300/3600 [==========================>...] - ETA: 0s - loss: 0.8956 - acc: 0.6794\n",
            "Epoch 00155: val_loss did not improve from 0.94377\n",
            "3600/3600 [==============================] - 1s 182us/sample - loss: 0.9022 - acc: 0.6761 - val_loss: 1.0016 - val_acc: 0.6308\n",
            "Epoch 156/200\n",
            "3400/3600 [===========================>..] - ETA: 0s - loss: 0.8727 - acc: 0.6794\n",
            "Epoch 00156: val_loss improved from 0.94377 to 0.92707, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
            "3600/3600 [==============================] - 1s 196us/sample - loss: 0.8720 - acc: 0.6792 - val_loss: 0.9271 - val_acc: 0.6767\n",
            "Epoch 157/200\n",
            "3300/3600 [==========================>...] - ETA: 0s - loss: 0.9053 - acc: 0.6809\n",
            "Epoch 00157: val_loss did not improve from 0.92707\n",
            "3600/3600 [==============================] - 1s 154us/sample - loss: 0.9093 - acc: 0.6789 - val_loss: 0.9472 - val_acc: 0.6733\n",
            "Epoch 158/200\n",
            "3400/3600 [===========================>..] - ETA: 0s - loss: 0.8883 - acc: 0.6750\n",
            "Epoch 00158: val_loss did not improve from 0.92707\n",
            "3600/3600 [==============================] - 1s 164us/sample - loss: 0.8898 - acc: 0.6742 - val_loss: 0.9922 - val_acc: 0.6500\n",
            "Epoch 159/200\n",
            "3200/3600 [=========================>....] - ETA: 0s - loss: 0.8675 - acc: 0.6872\n",
            "Epoch 00159: val_loss did not improve from 0.92707\n",
            "3600/3600 [==============================] - 1s 171us/sample - loss: 0.8704 - acc: 0.6875 - val_loss: 0.9773 - val_acc: 0.6450\n",
            "Epoch 160/200\n",
            "3500/3600 [============================>.] - ETA: 0s - loss: 0.8939 - acc: 0.6800\n",
            "Epoch 00160: val_loss did not improve from 0.92707\n",
            "3600/3600 [==============================] - 1s 183us/sample - loss: 0.8951 - acc: 0.6783 - val_loss: 0.9641 - val_acc: 0.6408\n",
            "Epoch 161/200\n",
            "3200/3600 [=========================>....] - ETA: 0s - loss: 0.8738 - acc: 0.6888\n",
            "Epoch 00161: val_loss did not improve from 0.92707\n",
            "3600/3600 [==============================] - 1s 171us/sample - loss: 0.8850 - acc: 0.6847 - val_loss: 0.9990 - val_acc: 0.6400\n",
            "Epoch 162/200\n",
            "3300/3600 [==========================>...] - ETA: 0s - loss: 0.8760 - acc: 0.6842\n",
            "Epoch 00162: val_loss did not improve from 0.92707\n",
            "3600/3600 [==============================] - 1s 161us/sample - loss: 0.8829 - acc: 0.6792 - val_loss: 0.9455 - val_acc: 0.6642\n",
            "Epoch 163/200\n",
            "3200/3600 [=========================>....] - ETA: 0s - loss: 0.8788 - acc: 0.6825\n",
            "Epoch 00163: val_loss did not improve from 0.92707\n",
            "3600/3600 [==============================] - 1s 174us/sample - loss: 0.8819 - acc: 0.6808 - val_loss: 1.0890 - val_acc: 0.5925\n",
            "Epoch 164/200\n",
            "3400/3600 [===========================>..] - ETA: 0s - loss: 0.8948 - acc: 0.6812\n",
            "Epoch 00164: val_loss did not improve from 0.92707\n",
            "3600/3600 [==============================] - 1s 169us/sample - loss: 0.8972 - acc: 0.6803 - val_loss: 0.9763 - val_acc: 0.6592\n",
            "Epoch 165/200\n",
            "3300/3600 [==========================>...] - ETA: 0s - loss: 0.8548 - acc: 0.6924\n",
            "Epoch 00165: val_loss did not improve from 0.92707\n",
            "3600/3600 [==============================] - 1s 170us/sample - loss: 0.8590 - acc: 0.6911 - val_loss: 1.1056 - val_acc: 0.5842\n",
            "Epoch 166/200\n",
            "3400/3600 [===========================>..] - ETA: 0s - loss: 0.8506 - acc: 0.6985\n",
            "Epoch 00166: val_loss did not improve from 0.92707\n",
            "3600/3600 [==============================] - 1s 172us/sample - loss: 0.8557 - acc: 0.6958 - val_loss: 0.9707 - val_acc: 0.6575\n",
            "Epoch 167/200\n",
            "3500/3600 [============================>.] - ETA: 0s - loss: 0.8616 - acc: 0.6909\n",
            "Epoch 00167: val_loss did not improve from 0.92707\n",
            "3600/3600 [==============================] - 1s 179us/sample - loss: 0.8594 - acc: 0.6922 - val_loss: 0.9984 - val_acc: 0.6442\n",
            "Epoch 168/200\n",
            "3200/3600 [=========================>....] - ETA: 0s - loss: 0.8719 - acc: 0.6888\n",
            "Epoch 00168: val_loss improved from 0.92707 to 0.86849, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
            "3600/3600 [==============================] - 1s 197us/sample - loss: 0.8787 - acc: 0.6853 - val_loss: 0.8685 - val_acc: 0.7108\n",
            "Epoch 169/200\n",
            "3400/3600 [===========================>..] - ETA: 0s - loss: 0.8606 - acc: 0.6962\n",
            "Epoch 00169: val_loss did not improve from 0.86849\n",
            "3600/3600 [==============================] - 1s 170us/sample - loss: 0.8611 - acc: 0.6969 - val_loss: 0.9674 - val_acc: 0.6550\n",
            "Epoch 170/200\n",
            "3300/3600 [==========================>...] - ETA: 0s - loss: 0.8685 - acc: 0.6924\n",
            "Epoch 00170: val_loss did not improve from 0.86849\n",
            "3600/3600 [==============================] - 1s 166us/sample - loss: 0.8641 - acc: 0.6908 - val_loss: 0.9723 - val_acc: 0.6467\n",
            "Epoch 171/200\n",
            "3400/3600 [===========================>..] - ETA: 0s - loss: 0.8586 - acc: 0.6909\n",
            "Epoch 00171: val_loss did not improve from 0.86849\n",
            "3600/3600 [==============================] - 1s 162us/sample - loss: 0.8616 - acc: 0.6894 - val_loss: 0.9366 - val_acc: 0.6742\n",
            "Epoch 172/200\n",
            "3500/3600 [============================>.] - ETA: 0s - loss: 0.8563 - acc: 0.6854\n",
            "Epoch 00172: val_loss did not improve from 0.86849\n",
            "3600/3600 [==============================] - 1s 156us/sample - loss: 0.8558 - acc: 0.6864 - val_loss: 0.9877 - val_acc: 0.6350\n",
            "Epoch 173/200\n",
            "3500/3600 [============================>.] - ETA: 0s - loss: 0.8547 - acc: 0.6971\n",
            "Epoch 00173: val_loss did not improve from 0.86849\n",
            "3600/3600 [==============================] - 1s 169us/sample - loss: 0.8581 - acc: 0.6956 - val_loss: 0.9431 - val_acc: 0.6667\n",
            "Epoch 174/200\n",
            "3500/3600 [============================>.] - ETA: 0s - loss: 0.8509 - acc: 0.6957\n",
            "Epoch 00174: val_loss did not improve from 0.86849\n",
            "3600/3600 [==============================] - 1s 159us/sample - loss: 0.8558 - acc: 0.6928 - val_loss: 0.9346 - val_acc: 0.6658\n",
            "Epoch 175/200\n",
            "3100/3600 [========================>.....] - ETA: 0s - loss: 0.8343 - acc: 0.6997\n",
            "Epoch 00175: val_loss did not improve from 0.86849\n",
            "3600/3600 [==============================] - 1s 171us/sample - loss: 0.8420 - acc: 0.6939 - val_loss: 0.9076 - val_acc: 0.6833\n",
            "Epoch 176/200\n",
            "3500/3600 [============================>.] - ETA: 0s - loss: 0.8428 - acc: 0.6954\n",
            "Epoch 00176: val_loss did not improve from 0.86849\n",
            "3600/3600 [==============================] - 1s 174us/sample - loss: 0.8420 - acc: 0.6956 - val_loss: 0.9018 - val_acc: 0.6783\n",
            "Epoch 177/200\n",
            "3200/3600 [=========================>....] - ETA: 0s - loss: 0.8671 - acc: 0.6991\n",
            "Epoch 00177: val_loss did not improve from 0.86849\n",
            "3600/3600 [==============================] - 1s 172us/sample - loss: 0.8606 - acc: 0.7003 - val_loss: 0.9698 - val_acc: 0.6383\n",
            "Epoch 178/200\n",
            "3300/3600 [==========================>...] - ETA: 0s - loss: 0.8346 - acc: 0.7018\n",
            "Epoch 00178: val_loss improved from 0.86849 to 0.85493, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
            "3600/3600 [==============================] - 1s 193us/sample - loss: 0.8370 - acc: 0.7011 - val_loss: 0.8549 - val_acc: 0.7142\n",
            "Epoch 179/200\n",
            "3300/3600 [==========================>...] - ETA: 0s - loss: 0.8476 - acc: 0.6967\n",
            "Epoch 00179: val_loss did not improve from 0.85493\n",
            "3600/3600 [==============================] - 1s 166us/sample - loss: 0.8415 - acc: 0.6997 - val_loss: 0.9337 - val_acc: 0.6608\n",
            "Epoch 180/200\n",
            "3500/3600 [============================>.] - ETA: 0s - loss: 0.8434 - acc: 0.7040\n",
            "Epoch 00180: val_loss did not improve from 0.85493\n",
            "3600/3600 [==============================] - 1s 178us/sample - loss: 0.8416 - acc: 0.7042 - val_loss: 0.8578 - val_acc: 0.7100\n",
            "Epoch 181/200\n",
            "3300/3600 [==========================>...] - ETA: 0s - loss: 0.8499 - acc: 0.6945\n",
            "Epoch 00181: val_loss did not improve from 0.85493\n",
            "3600/3600 [==============================] - 1s 168us/sample - loss: 0.8429 - acc: 0.6969 - val_loss: 0.9182 - val_acc: 0.6767\n",
            "Epoch 182/200\n",
            "3300/3600 [==========================>...] - ETA: 0s - loss: 0.8263 - acc: 0.7052\n",
            "Epoch 00182: val_loss did not improve from 0.85493\n",
            "3600/3600 [==============================] - 1s 182us/sample - loss: 0.8299 - acc: 0.7053 - val_loss: 0.8859 - val_acc: 0.6917\n",
            "Epoch 183/200\n",
            "3400/3600 [===========================>..] - ETA: 0s - loss: 0.8513 - acc: 0.7000\n",
            "Epoch 00183: val_loss did not improve from 0.85493\n",
            "3600/3600 [==============================] - 1s 164us/sample - loss: 0.8564 - acc: 0.7003 - val_loss: 0.8827 - val_acc: 0.6983\n",
            "Epoch 184/200\n",
            "3400/3600 [===========================>..] - ETA: 0s - loss: 0.8373 - acc: 0.7029\n",
            "Epoch 00184: val_loss did not improve from 0.85493\n",
            "3600/3600 [==============================] - 1s 172us/sample - loss: 0.8364 - acc: 0.7033 - val_loss: 0.9860 - val_acc: 0.6458\n",
            "Epoch 185/200\n",
            "3500/3600 [============================>.] - ETA: 0s - loss: 0.8261 - acc: 0.6931\n",
            "Epoch 00185: val_loss did not improve from 0.85493\n",
            "3600/3600 [==============================] - 1s 168us/sample - loss: 0.8264 - acc: 0.6933 - val_loss: 0.8898 - val_acc: 0.6908\n",
            "Epoch 186/200\n",
            "3200/3600 [=========================>....] - ETA: 0s - loss: 0.8262 - acc: 0.6944\n",
            "Epoch 00186: val_loss improved from 0.85493 to 0.83949, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
            "3600/3600 [==============================] - 1s 187us/sample - loss: 0.8422 - acc: 0.6883 - val_loss: 0.8395 - val_acc: 0.7100\n",
            "Epoch 187/200\n",
            "3500/3600 [============================>.] - ETA: 0s - loss: 0.8227 - acc: 0.7097\n",
            "Epoch 00187: val_loss did not improve from 0.83949\n",
            "3600/3600 [==============================] - 1s 184us/sample - loss: 0.8259 - acc: 0.7083 - val_loss: 0.9154 - val_acc: 0.6783\n",
            "Epoch 188/200\n",
            "3400/3600 [===========================>..] - ETA: 0s - loss: 0.8122 - acc: 0.7156\n",
            "Epoch 00188: val_loss did not improve from 0.83949\n",
            "3600/3600 [==============================] - 1s 161us/sample - loss: 0.8142 - acc: 0.7161 - val_loss: 0.9437 - val_acc: 0.6542\n",
            "Epoch 189/200\n",
            "3500/3600 [============================>.] - ETA: 0s - loss: 0.8090 - acc: 0.7009\n",
            "Epoch 00189: val_loss did not improve from 0.83949\n",
            "3600/3600 [==============================] - 1s 175us/sample - loss: 0.8146 - acc: 0.6986 - val_loss: 0.9785 - val_acc: 0.6450\n",
            "Epoch 190/200\n",
            "3200/3600 [=========================>....] - ETA: 0s - loss: 0.8653 - acc: 0.6859\n",
            "Epoch 00190: val_loss did not improve from 0.83949\n",
            "3600/3600 [==============================] - 1s 162us/sample - loss: 0.8641 - acc: 0.6858 - val_loss: 0.8402 - val_acc: 0.7067\n",
            "Epoch 191/200\n",
            "3300/3600 [==========================>...] - ETA: 0s - loss: 0.8640 - acc: 0.6918\n",
            "Epoch 00191: val_loss did not improve from 0.83949\n",
            "3600/3600 [==============================] - 1s 156us/sample - loss: 0.8597 - acc: 0.6922 - val_loss: 0.8695 - val_acc: 0.6967\n",
            "Epoch 192/200\n",
            "3500/3600 [============================>.] - ETA: 0s - loss: 0.8367 - acc: 0.7094\n",
            "Epoch 00192: val_loss did not improve from 0.83949\n",
            "3600/3600 [==============================] - 1s 169us/sample - loss: 0.8357 - acc: 0.7100 - val_loss: 0.8631 - val_acc: 0.6983\n",
            "Epoch 193/200\n",
            "3400/3600 [===========================>..] - ETA: 0s - loss: 0.8036 - acc: 0.7141\n",
            "Epoch 00193: val_loss did not improve from 0.83949\n",
            "3600/3600 [==============================] - 1s 163us/sample - loss: 0.8056 - acc: 0.7128 - val_loss: 0.9031 - val_acc: 0.6683\n",
            "Epoch 194/200\n",
            "3300/3600 [==========================>...] - ETA: 0s - loss: 0.7952 - acc: 0.7200\n",
            "Epoch 00194: val_loss improved from 0.83949 to 0.83754, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
            "3600/3600 [==============================] - 1s 191us/sample - loss: 0.8019 - acc: 0.7169 - val_loss: 0.8375 - val_acc: 0.7133\n",
            "Epoch 195/200\n",
            "3400/3600 [===========================>..] - ETA: 0s - loss: 0.7842 - acc: 0.7106\n",
            "Epoch 00195: val_loss did not improve from 0.83754\n",
            "3600/3600 [==============================] - 1s 176us/sample - loss: 0.7895 - acc: 0.7092 - val_loss: 0.9580 - val_acc: 0.6508\n",
            "Epoch 196/200\n",
            "3400/3600 [===========================>..] - ETA: 0s - loss: 0.8057 - acc: 0.7191\n",
            "Epoch 00196: val_loss did not improve from 0.83754\n",
            "3600/3600 [==============================] - 1s 167us/sample - loss: 0.8058 - acc: 0.7217 - val_loss: 0.9240 - val_acc: 0.6667\n",
            "Epoch 197/200\n",
            "3300/3600 [==========================>...] - ETA: 0s - loss: 0.8009 - acc: 0.7112\n",
            "Epoch 00197: val_loss did not improve from 0.83754\n",
            "3600/3600 [==============================] - 1s 185us/sample - loss: 0.8032 - acc: 0.7094 - val_loss: 0.8758 - val_acc: 0.6925\n",
            "Epoch 198/200\n",
            "3400/3600 [===========================>..] - ETA: 0s - loss: 0.7871 - acc: 0.7129\n",
            "Epoch 00198: val_loss did not improve from 0.83754\n",
            "3600/3600 [==============================] - 1s 165us/sample - loss: 0.7813 - acc: 0.7153 - val_loss: 0.8712 - val_acc: 0.6817\n",
            "Epoch 199/200\n",
            "3500/3600 [============================>.] - ETA: 0s - loss: 0.8365 - acc: 0.7000\n",
            "Epoch 00199: val_loss improved from 0.83754 to 0.80481, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
            "3600/3600 [==============================] - 1s 174us/sample - loss: 0.8382 - acc: 0.6981 - val_loss: 0.8048 - val_acc: 0.7267\n",
            "Epoch 200/200\n",
            "3300/3600 [==========================>...] - ETA: 0s - loss: 0.8337 - acc: 0.6976\n",
            "Epoch 00200: val_loss did not improve from 0.80481\n",
            "3600/3600 [==============================] - 1s 166us/sample - loss: 0.8345 - acc: 0.6978 - val_loss: 0.9601 - val_acc: 0.6475\n",
            "1200/1200 [==============================] - 0s 243us/sample - loss: 0.9601 - acc: 0.6475\n",
            "[0.9601170667012533, 0.6475]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FxW8fPu6wlY-",
        "colab_type": "code",
        "outputId": "135792f6-714a-4127-abce-c3ee79cf4f2b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        }
      },
      "source": [
        "# Иницијализација на променливите каде ќе бидат вчитани тест податоците\n",
        "test_data = []\n",
        "test_events = []\n",
        "test_runs_per_block = [[i for i in range(3)] for j in range(15)] # Covek, Sesija\n",
        "\n",
        "start_i = 3\n",
        "for i in range(3, 4): # Итерација низ секој испитен примерок\n",
        "  print(f\"====================== Примерок ({i}) ======================\")\n",
        "  print(\"Вчитување тест податоци од испитниот примерок \" + str(i) + \"...\")\n",
        "  \n",
        "  file_name = 'SBJ' + format(i, '02')\n",
        "  \n",
        "  # Иницијализација на помошни променливи\n",
        "  temp_test_data = np.empty(0)\n",
        "  temp_test_events = np.empty(0)\n",
        "  \n",
        "  for j in range(1, 4): # Итерација низ секоја сесија\n",
        "    file_test_set = 'S' + format(j, '02') + '/Test'\n",
        "\n",
        "    # Вчитување на податоците\n",
        "    full_path = 'drive/My Drive/Интелигентни Системи/Data/' + file_name + \"/\" + file_test_set + \"/testData.mat\"\n",
        "    temp = loadmat(full_path)['testData']\n",
        "    if temp_test_data.size != 0:\n",
        "      temp_test_data = np.concatenate((temp_test_data, temp), axis=2)\n",
        "    else: \n",
        "      temp_test_data = np.array(temp)\n",
        "\n",
        "    # Вчитување на редоследот на светкање\n",
        "    full_path = 'drive/My Drive/Интелигентни Системи/Data/' + file_name + \"/\" + file_test_set + \"/testEvents.txt\"\n",
        "    with open(full_path, \"r\") as file_events:\n",
        "      temp = file_events.read().splitlines()\n",
        "      if temp_test_events.size != 0:\n",
        "        temp_test_events = np.append(temp_test_events, temp)\n",
        "      else:\n",
        "        temp_test_events = np.array(temp)\n",
        "\n",
        "    # Вчитување на бројот на runs \n",
        "    full_path = 'drive/My Drive/Интелигентни Системи/Data/' + file_name + \"/\" + file_test_set + \"/runs_per_block.txt\"\n",
        "    with open(full_path, \"r\") as runs_per_block:\n",
        "      test_runs_per_block[i-1][j-1] = int(runs_per_block.read())\n",
        "\n",
        "    print(\"\\t - Тест податоците од сесија \" + str(j) + \" се вчитани.\")\n",
        "  # Зачувај ги тест податоците вчитани од испитниот примерок во низа\n",
        "  test_data.append(temp_test_data)\n",
        "  test_events.append(temp_test_events)\n",
        "  print(\"Тест податоците од испитниот примерок \" + str(i) + \" се вчитани.\\n\")\n",
        "\n",
        "  array_i = i - start_i\n",
        "      \n",
        "  \n",
        "  # =========================================================================\n",
        "\n",
        "  print(\"SBJ\" + str(format(i-1, '02')) + \"| Test_data: \" + str(test_data[array_i].shape)) # test_data to predict\n",
        "  print(\"SBJ\" + str(format(i-1, '02')) + \"| Test_events: \" + str(len(test_events[array_i]))) # test_events\n",
        "  for j in range (1,4):\n",
        "    print(\"SBJ\" + str(format(i-1, '02')) + \" / S\" + str(format(j-1, '02')) + \"| Runs per block: \" + str(test_runs_per_block[i-1][j-1])) # runs per block in SJB01, SJ00 \n",
        "\n",
        "  to_predict_data = reshape_data_to_mne_format(test_data[array_i])\n",
        "  predictions = models[array_i].predict(to_predict_data)\n",
        "  print(\"SBJ\" + str(format(i-1, '02')) + \"| Predictions: \" + str(len(predictions)))\n",
        "  # np.savetxt(\"predictions.csv\", predictions, delimiter=\",\")\n",
        "\n",
        "\n",
        "  # ========= FALI USTE DA SE ISPARSIRA PREDICTIONOT... NE E SREDEN OVOJ KOD DOLE =======\n",
        "\n",
        "  int_pred = np.argmax(predictions, axis=1)\n",
        "  int_ytest = np.argmax(y_test, axis=1)\n",
        "\n",
        "  session_start = 0\n",
        "  start_prediction_index = 0\n",
        "  end_prediction_index = 0\n",
        "  for session in range(0, 3):\n",
        "    print(f\"============== Сесија ({session}) ==============\")\n",
        "    for block in range(0, 50):    \n",
        "      events_per_block = test_runs_per_block[i-1][session]\n",
        "\n",
        "      start_prediction_index = session_start + (block*events_per_block)*8\n",
        "      end_prediction_index = session_start + ((block+1)*events_per_block)*8\n",
        "\n",
        "      block_prediction = int_pred[start_prediction_index:end_prediction_index]\n",
        "      prediction = np.bincount(block_prediction).argmax()\n",
        "\n",
        "      # UNCOMMENT ZA PODOBAR PRIKAZ :)\n",
        "      # print(f\"Session {session} | Block: {block} | Prediction: {prediction} | Address: {end_prediction_index}\")\n",
        "\n",
        "      print(str(prediction) + \",\", end=\"\")\n",
        "    session_start = end_prediction_index\n",
        "    print(\"\")\n",
        "  print(\"Stigna li do kraj: \" + str(session_start == len(predictions)))\n",
        "  print(f\"====================== Примерок ({i}) ======================\\n\\n\")"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "====================== Примерок (3) ======================\n",
            "Вчитување тест податоци од испитниот примерок 3...\n",
            "\t - Тест податоците од сесија 1 се вчитани.\n",
            "\t - Тест податоците од сесија 2 се вчитани.\n",
            "\t - Тест податоците од сесија 3 се вчитани.\n",
            "Тест податоците од испитниот примерок 3 се вчитани.\n",
            "\n",
            "SBJ02| Test_data: (8, 350, 7600)\n",
            "SBJ02| Test_events: 7600\n",
            "SBJ02 / S00| Runs per block: 6\n",
            "SBJ02 / S01| Runs per block: 6\n",
            "SBJ02 / S02| Runs per block: 7\n",
            "SBJ02| Predictions: 7600\n",
            "============== Сесија (0) ==============\n",
            "2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,5,2,2,2,2,2,2,2,2,4,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,\n",
            "============== Сесија (1) ==============\n",
            "5,0,5,5,0,5,5,5,5,0,5,5,5,5,5,5,5,5,5,5,5,5,0,0,5,5,5,5,5,5,5,5,5,5,5,5,5,5,6,5,5,5,5,0,5,5,5,5,5,5,\n",
            "============== Сесија (2) ==============\n",
            "5,0,6,5,5,5,7,0,7,0,0,6,0,7,5,5,0,5,3,0,0,7,0,3,0,0,6,3,0,5,0,7,3,0,3,6,7,6,0,3,0,6,3,4,5,0,0,4,0,6,\n",
            "Stigna li do kraj: True\n",
            "====================== Примерок (3) ======================\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_854cF8A9NHD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# test_data = reshape_data_to_mne_format(test_data)\n",
        "# print(test_data.shape)\n",
        "# predictions = model.predict(X_test)\n",
        "# np.savetxt(\"predictions.csv\", predictions, delimiter=\",\")\n",
        "# np.savetxt(\"y_test.csv\", y_test, delimiter=\",\")\n",
        "\n",
        "\n",
        "# predictions = model.predict(X_test)\n",
        "# np.savetxt(\"predictions.csv\", predictions, delimiter=\",\")\n",
        "# np.savetxt(\"y_test.csv\", y_test, delimiter=\",\")\n",
        "\n",
        "# from collections import Counter\n",
        "# int_pred = np.argmax(predictions, axis=1)\n",
        "# int_ytest = np.argmax(y_test, axis=1)\n",
        "\n",
        "# correct = 0\n",
        "# for i in range(20):\n",
        "#   block_y = int_ytest[i*80:(i+1)*80]\n",
        "#   block_y_pred = int_pred[i*80:(i+1)*80]\n",
        "\n",
        "#   class_y = np.bincount(block_y).argmax()\n",
        "#   class_y_pred = np.bincount(block_y_pred).argmax()\n",
        "\n",
        "#   print(f\"Class Y: {class_y}, prediciton: {class_y_pred}\")\n",
        "#   if class_y == class_y_pred:\n",
        "#     correct = correct+1\n",
        "\n",
        "# correct"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}